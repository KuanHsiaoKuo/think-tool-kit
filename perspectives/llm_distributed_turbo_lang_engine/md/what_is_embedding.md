在自然语言处理（NLP）中，"embedding"
通常是指把词、句子或文档表示为数值向量的过程。这些向量（通常在一个高维空间中）可以反映语言的某些方面，如词义、语法角色等。将文本转化为数值向量可以让我们对文本进行数学操作，这是许多NLP任务的基础，比如文档分类、文档相似性比较、文档问答等。

在文档问答系统中，通常会对输入的问题和候选答案文档进行embedding。然后，可以通过比较问题和文档的向量表示来寻找最匹配的答案。例如，可以计算问题和每个文档之间的cosine相似度，然后选择相似度最高的文档作为答案。

有许多方法可以用来进行embedding，包括Word2Vec、GloVe、FastText、BERT、GPT等模型。这些模型都可以学习到词、句子或文档的语义和语法信息，并以此创建有效的向量表示。