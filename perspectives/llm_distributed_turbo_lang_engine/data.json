[{"id": 1, "name": " \u57fa\u4e8eLLM\u7684\u8bad\u7ec3\u5e73\u53f0(Rust)\n"}, {"id": 2, "name": "\u7ed3\u6784\n", "parent": 1, "note": "![](../pic/embedding_vector_knowledge_seq.png)"}, {"id": 3, "name": "Embedding\n", "parent": 2, "note": "\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u4e2d\uff0c\"embedding\"\n\u901a\u5e38\u662f\u6307\u628a\u8bcd\u3001\u53e5\u5b50\u6216\u6587\u6863\u8868\u793a\u4e3a\u6570\u503c\u5411\u91cf\u7684\u8fc7\u7a0b\u3002\u8fd9\u4e9b\u5411\u91cf\uff08\u901a\u5e38\u5728\u4e00\u4e2a\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\uff09\u53ef\u4ee5\u53cd\u6620\u8bed\u8a00\u7684\u67d0\u4e9b\u65b9\u9762\uff0c\u5982\u8bcd\u4e49\u3001\u8bed\u6cd5\u89d2\u8272\u7b49\u3002\u5c06\u6587\u672c\u8f6c\u5316\u4e3a\u6570\u503c\u5411\u91cf\u53ef\u4ee5\u8ba9\u6211\u4eec\u5bf9\u6587\u672c\u8fdb\u884c\u6570\u5b66\u64cd\u4f5c\uff0c\u8fd9\u662f\u8bb8\u591aNLP\u4efb\u52a1\u7684\u57fa\u7840\uff0c\u6bd4\u5982\u6587\u6863\u5206\u7c7b\u3001\u6587\u6863\u76f8\u4f3c\u6027\u6bd4\u8f83\u3001\u6587\u6863\u95ee\u7b54\u7b49\u3002\n\n\u5728\u6587\u6863\u95ee\u7b54\u7cfb\u7edf\u4e2d\uff0c\u901a\u5e38\u4f1a\u5bf9\u8f93\u5165\u7684\u95ee\u9898\u548c\u5019\u9009\u7b54\u6848\u6587\u6863\u8fdb\u884cembedding\u3002\u7136\u540e\uff0c\u53ef\u4ee5\u901a\u8fc7\u6bd4\u8f83\u95ee\u9898\u548c\u6587\u6863\u7684\u5411\u91cf\u8868\u793a\u6765\u5bfb\u627e\u6700\u5339\u914d\u7684\u7b54\u6848\u3002\u4f8b\u5982\uff0c\u53ef\u4ee5\u8ba1\u7b97\u95ee\u9898\u548c\u6bcf\u4e2a\u6587\u6863\u4e4b\u95f4\u7684cosine\u76f8\u4f3c\u5ea6\uff0c\u7136\u540e\u9009\u62e9\u76f8\u4f3c\u5ea6\u6700\u9ad8\u7684\u6587\u6863\u4f5c\u4e3a\u7b54\u6848\u3002\n\n\u6709\u8bb8\u591a\u65b9\u6cd5\u53ef\u4ee5\u7528\u6765\u8fdb\u884cembedding\uff0c\u5305\u62ecWord2Vec\u3001GloVe\u3001FastText\u3001BERT\u3001GPT\u7b49\u6a21\u578b\u3002\u8fd9\u4e9b\u6a21\u578b\u90fd\u53ef\u4ee5\u5b66\u4e60\u5230\u8bcd\u3001\u53e5\u5b50\u6216\u6587\u6863\u7684\u8bed\u4e49\u548c\u8bed\u6cd5\u4fe1\u606f\uff0c\u5e76\u4ee5\u6b64\u521b\u5efa\u6709\u6548\u7684\u5411\u91cf\u8868\u793a\u3002"}, {"id": 4, "name": "\u5904\u7406\u8fc7\u7a0b\n", "parent": 3, "note": "\u5d4c\u5165\uff08embedding\uff09\u7684\u5904\u7406\u8fc7\u7a0b\u4e3b\u8981\u5305\u62ec\u4ee5\u4e0b\u6b65\u9aa4\uff1a\n\n1. **\u6587\u672c\u9884\u5904\u7406**\uff1a\u8fd9\u662f\u5c06\u6587\u672c\u6570\u636e\u6e05\u6d17\u548c\u6807\u51c6\u5316\u7684\u6b65\u9aa4\u3002\u5b83\u53ef\u80fd\u5305\u62ec\u53bb\u9664\u7279\u6b8a\u5b57\u7b26\u3001\u6807\u70b9\u7b26\u53f7\u3001\u505c\u7528\u8bcd\uff0c\u4ee5\u53ca\u8fdb\u884c\u8bcd\u5e72\u63d0\u53d6\u6216\u8bcd\u5f62\u8fd8\u539f\u7b49\u64cd\u4f5c\u3002\u5728\u8fd9\u4e2a\u9636\u6bb5\uff0c\u6587\u672c\u88ab\u5206\u5272\u6210\u5355\u8bcd\u6216\u77ed\u8bed\u3002\n\n2. **\u8bcd\u6c47\u8868\u521b\u5efa**\uff1a\u4ece\u9884\u5904\u7406\u540e\u7684\u6587\u672c\u4e2d\u521b\u5efa\u8bcd\u6c47\u8868\uff0c\u901a\u5e38\u662f\u5c06\u6bcf\u4e2a\u552f\u4e00\u7684\u5355\u8bcd\u6216\u77ed\u8bed\u5206\u914d\u4e00\u4e2a\u552f\u4e00\u7684\u7d22\u5f15\u3002\n\n3. **\u5d4c\u5165\u8bad\u7ec3**\uff1a\u4f7f\u7528\u5d4c\u5165\u6a21\u578b\uff08\u5982Word2Vec\uff0cGloVe\uff0cFastText\uff0cBERT\u7b49\uff09\u8bad\u7ec3\u8bcd\u5d4c\u5165\u3002\u8fd9\u4e2a\u6b65\u9aa4\u4f1a\u8f93\u51fa\u4e00\u4e2a\u5d4c\u5165\u77e9\u9635\uff0c\u5176\u4e2d\u6bcf\u4e00\u884c\u4ee3\u8868\u8bcd\u6c47\u8868\u4e2d\u4e00\u4e2a\u5355\u8bcd\u7684\u5411\u91cf\u8868\u793a\u3002\n\n4. **\u5d4c\u5165\u67e5\u8be2**\uff1a\u7ed9\u5b9a\u4e00\u4e2a\u5355\u8bcd\u6216\u4e00\u7ec4\u5355\u8bcd\uff0c\u901a\u8fc7\u67e5\u627e\u5d4c\u5165\u77e9\u9635\uff0c\u5c06\u5b83\u4eec\u8f6c\u5316\u4e3a\u76f8\u5e94\u7684\u5411\u91cf\u3002\n\n\u4ee5\u4e0b\u662f\u4e00\u4e2a\u5c1d\u8bd5\u4ee5ASCII\u65b9\u5f0f\u8868\u793a\u8fd9\u4e2a\u8fc7\u7a0b\u7684\u6d41\u7a0b\u56fe\uff1a\n\n```\n  Text Data\n     |\n     v\n Text Preprocessing\n     |\n     v\n Vocabulary Creation\n     |\n     v\nEmbedding Training\n     |\n     v\n Embedding Lookup\n```\n\n\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u4e0a\u8ff0\u6d41\u7a0b\u4e3b\u8981\u9002\u7528\u4e8e\u8bad\u7ec3\u81ea\u5df1\u7684\u5d4c\u5165\u3002\u5982\u679c\u4f60\u6b63\u5728\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u5d4c\u5165\uff08\u5982GloVe\u6216BERT\u7684\u9884\u8bad\u7ec3\u5d4c\u5165\uff09\uff0c\u90a3\u4e48\u6b65\u9aa43\uff08\u5d4c\u5165\u8bad\u7ec3\uff09\u5c06\u4e0d\u9002\u7528\uff0c\u4f60\u53ea\u9700\u8981\u52a0\u8f7d\u9884\u8bad\u7ec3\u7684\u5d4c\u5165\uff0c\u5e76\u5728\u6b65\u9aa44\uff08\u5d4c\u5165\u67e5\u8be2\uff09\u4e2d\u4f7f\u7528\u5b83\u4eec\u3002"}, {"id": 5, "name": "Vector Database\n", "parent": 2, "note": "\u5411\u91cf\u6570\u636e\u5e93\uff08\u4e5f\u79f0\u4e3a\u5411\u91cf\u641c\u7d22\u5f15\u64ce\uff09\u662f\u4e00\u79cd\u4e13\u95e8\u7528\u4e8e\u5904\u7406\u548c\u67e5\u8be2\u5927\u91cf\u9ad8\u7ef4\u5411\u91cf\u6570\u636e\u7684\u6570\u636e\u5e93\u3002\u8fd9\u79cd\u6570\u636e\u5e93\u4e0e\u4f20\u7edf\u7684\u5173\u7cfb\u578b\u6216NoSQL\u6570\u636e\u5e93\u4e0d\u540c\uff0c\u5b83\u4eec\u91c7\u7528\u7279\u5b9a\u7684\u7d22\u5f15\u7ed3\u6784\u548c\u641c\u7d22\u7b56\u7565\uff0c\u4ee5\u4f18\u5316\u9ad8\u7ef4\u5411\u91cf\u6570\u636e\u7684\u5b58\u50a8\u548c\u76f8\u4f3c\u5ea6\u67e5\u8be2\u3002\n\n\u5411\u91cf\u6570\u636e\u5e93\u5728\u5f88\u591a\u4f7f\u7528\u5d4c\u5165\uff08embedding\uff09\u7684\u673a\u5668\u5b66\u4e60\u548c\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u4e2d\u90fd\u975e\u5e38\u6709\u7528\u3002\u4f8b\u5982\uff0c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7684\u8bcd\u5d4c\u5165\u3001\u53e5\u5d4c\u5165\uff0c\u4ee5\u53ca\u56fe\u50cf\u8bc6\u522b\u4e2d\u7684\u56fe\u50cf\u5d4c\u5165\u7b49\uff0c\u8fd9\u4e9b\u90fd\u662f\u5c06\u539f\u59cb\u6570\u636e\u8f6c\u5316\u4e3a\u9ad8\u7ef4\u5411\u91cf\uff0c\u8fd9\u4e9b\u5411\u91cf\u5c31\u53ef\u4ee5\u5b58\u50a8\u5728\u5411\u91cf\u6570\u636e\u5e93\u4e2d\u3002\n\n\u5728\u8fd9\u6837\u7684\u5e94\u7528\u4e2d\uff0c\u5d4c\u5165\u662f\u5c06\u539f\u59cb\u6570\u636e\uff08\u5982\u6587\u672c\u3001\u56fe\u50cf\u7b49\uff09\u8f6c\u5316\u4e3a\u53ef\u4ee5\u88ab\u673a\u5668\u7406\u89e3\u548c\u5904\u7406\u7684\u5f62\u5f0f\uff08\u5373\u5411\u91cf\uff09\u3002\u800c\u5411\u91cf\u6570\u636e\u5e93\u5219\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u5f0f\u6765\u5b58\u50a8\u548c\u67e5\u8be2\u8fd9\u4e9b\u5411\u91cf\u3002\u6bd4\u5982\uff0c\u5728\u4e00\u4e2a\u57fa\u4e8e\u6587\u6863\u7684\u95ee\u7b54\u7cfb\u7edf\u4e2d\uff0c\u53ef\u4ee5\u5148\u5c06\u6240\u6709\u6587\u6863\u7684\u5d4c\u5165\u5b58\u50a8\u5728\u4e00\u4e2a\u5411\u91cf\u6570\u636e\u5e93\u4e2d\u3002\u7136\u540e\uff0c\u5f53\u6709\u4e00\u4e2a\u65b0\u7684\u95ee\u9898\u6765\u65f6\uff0c\u53ef\u4ee5\u5148\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u4e00\u4e2a\u5411\u91cf\uff0c\u7136\u540e\u5728\u6570\u636e\u5e93\u4e2d\u67e5\u627e\u4e0e\u8fd9\u4e2a\u5411\u91cf\u6700\u76f8\u4f3c\u7684\u6587\u6863\u5411\u91cf\uff0c\u8fd4\u56de\u8fd9\u4e9b\u76f8\u4f3c\u6587\u6863\u4f5c\u4e3a\u7b54\u6848\u3002\n\n\u5728\u5b9e\u8df5\u4e2d\uff0c\u6709\u4e9b\u4e13\u95e8\u7684\u5411\u91cf\u6570\u636e\u5e93\uff0c\u5982Faiss\uff08\u7531Facebook AI\u5f00\u53d1\uff09\u3001Annoy\uff08\u7531Spotify\u5f00\u53d1\uff09\u548cMilvus\u7b49\uff0c\u88ab\u5e7f\u6cdb\u7528\u4e8e\u5904\u7406\u5927\u89c4\u6a21\u7684\u5d4c\u5165\u67e5\u8be2\u95ee\u9898\u3002"}, {"id": 6, "name": "\u5305\u542b\u5185\u5bb9\n", "parent": 5, "note": "\u5411\u91cf\u6570\u636e\u5e93\u4e3b\u8981\u7528\u4e8e\u5b58\u50a8\u548c\u67e5\u8be2\u9ad8\u7ef4\u5ea6\u5411\u91cf\u3002\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u3001\u8ba1\u7b97\u673a\u89c6\u89c9\u6216\u63a8\u8350\u7cfb\u7edf\u7b49\u9886\u57df\uff0c\u6570\u636e\uff08\u4f8b\u5982\u6587\u672c\u3001\u56fe\u50cf\u6216\u7528\u6237\u884c\u4e3a\uff09\u5e38\u5e38\u4f1a\u88ab\u8f6c\u5316\u4e3a\u9ad8\u7ef4\u5ea6\u5411\u91cf\uff08\u5373embedding\uff09\uff0c\u8fd9\u4e9b\u5411\u91cf\u5c31\u88ab\u5b58\u50a8\u5728\u5411\u91cf\u6570\u636e\u5e93\u4e2d\u3002\u6240\u4ee5\uff0c\u5411\u91cf\u6570\u636e\u5e93\u4e3b\u8981\u5305\u542b\u4ee5\u4e0b\u51e0\u4e2a\u90e8\u5206\uff1a\n\n1. **\u5411\u91cf\u6570\u636e**\uff1a\u6570\u636e\u5e93\u4e2d\u6700\u4e3b\u8981\u7684\u90e8\u5206\u5c31\u662f\u5411\u91cf\u6570\u636e\uff0c\u5b83\u4eec\u901a\u5e38\u662f\u7531embedding\u6a21\u578b\u751f\u6210\u7684\u9ad8\u7ef4\u5411\u91cf\u3002\n\n2. **\u5411\u91cf\u7d22\u5f15**\uff1a\u7531\u4e8e\u5411\u91cf\u6570\u636e\u7684\u9ad8\u7ef4\u6027\u548c\u5927\u89c4\u6a21\u6027\uff0c\u76f4\u63a5\u5728\u6240\u6709\u5411\u91cf\u4e0a\u8fdb\u884c\u641c\u7d22\u662f\u975e\u5e38\u8017\u65f6\u7684\u3002\u56e0\u6b64\uff0c\u5411\u91cf\u6570\u636e\u5e93\u901a\u5e38\u4f1a\u5efa\u7acb\u4e00\u4e2a\u7279\u5b9a\u7684\u7d22\u5f15\u7ed3\u6784\uff08\u5982K-D\u6811\u3001\u7403\u6811\u3001\u54c8\u5e0c\u7b49\uff09\uff0c\u4ee5\u52a0\u901f\u5411\u91cf\u7684\u67e5\u627e\u548c\u6bd4\u8f83\u3002\n\n3. **\u5143\u6570\u636e**\uff1a\u5143\u6570\u636e\u662f\u4e0e\u5411\u91cf\u76f8\u5173\u7684\u989d\u5916\u4fe1\u606f\u3002\u4f8b\u5982\uff0c\u5728\u4e00\u4e2a\u6587\u672c\u641c\u7d22\u7cfb\u7edf\u4e2d\uff0c\u6bcf\u4e2a\u5411\u91cf\u53ef\u80fd\u5bf9\u5e94\u4e00\u4e2a\u6587\u6863\uff0c\u90a3\u4e48\u8fd9\u4e2a\u6587\u6863\u7684\u6807\u9898\u3001\u4f5c\u8005\u3001\u53d1\u5e03\u65e5\u671f\u7b49\u4fe1\u606f\u5c31\u662f\u5143\u6570\u636e\u3002\n\n4. **\u67e5\u8be2\u63a5\u53e3**\uff1a\u5411\u91cf\u6570\u636e\u5e93\u8fd8\u4f1a\u63d0\u4f9b\u4e00\u4e9b\u67e5\u8be2\u63a5\u53e3\uff0c\u5141\u8bb8\u7528\u6237\u6839\u636e\u6307\u5b9a\u7684\u76f8\u4f3c\u5ea6\u5ea6\u91cf\uff08\u5982\u4f59\u5f26\u76f8\u4f3c\u6027\u3001\u6b27\u6c0f\u8ddd\u79bb\u7b49\uff09\u6765\u67e5\u8be2\u6700\u76f8\u4f3c\u7684\u5411\u91cf\u3002\n\n5. **\u6570\u636e\u7ba1\u7406\u63a5\u53e3**\uff1a\u6b64\u5916\uff0c\u5411\u91cf\u6570\u636e\u5e93\u8fd8\u4f1a\u63d0\u4f9b\u63a5\u53e3\u6765\u63d2\u5165\u65b0\u7684\u5411\u91cf\u3001\u5220\u9664\u73b0\u6709\u5411\u91cf\u3001\u66f4\u65b0\u5411\u91cf\u7b49\u3002\n\n\u5e38\u89c1\u7684\u5411\u91cf\u6570\u636e\u5e93\u5305\u62ecFaiss\uff08Facebook AI\u5f00\u53d1\uff09\u3001Milvus\u3001Annoy\uff08Spotify\u5f00\u53d1\uff09\u7b49\u3002\u8fd9\u4e9b\u6570\u636e\u5e93\u5728\u5904\u7406\u5927\u89c4\u6a21\u7684\u5d4c\u5165\u67e5\u8be2\u95ee\u9898\u4e0a\u90fd\u975e\u5e38\u9ad8\u6548\uff0c\u88ab\u5e7f\u6cdb\u7528\u4e8e\u5404\u79cdAI\u5e94\u7528\u3002"}, {"id": 8, "name": "\u94fe\u63a51: qdrant/qdrant", "link": "https://github.com/qdrant/qdrant", "parent": 7, "note": "[\u6765\u81ea  qdrant/qdrant\n\u7684\u94fe\u63a5](https://github.com/qdrant/qdrant)"}, {"id": 7, "name": "  qdrant/qdrant\n", "parent": 5}, {"id": 9, "name": "README\n", "parent": 7, "note": "<p align=\"center\">\n  <img height=\"100\" src=\"https://github.com/qdrant/qdrant/raw/master/docs/logo.svg\" alt=\"Qdrant\">\n</p>\n\n<p align=\"center\">\n    <b>Vector Search Engine for the next generation of AI applications</b>\n</p>\n\n<p align=center>\n    <a href=\"https://github.com/qdrant/qdrant/actions/workflows/rust.yml\"><img src=\"https://img.shields.io/github/actions/workflow/status/qdrant/qdrant/rust.yml?style=flat-square\" alt=\"Tests status\"></a>\n    <a href=\"https://qdrant.github.io/qdrant/redoc/index.html\"><img src=\"https://img.shields.io/badge/Docs-OpenAPI%203.0-success?style=flat-square\" alt=\"OpenAPI Docs\"></a>\n    <a href=\"https://github.com/qdrant/qdrant/blob/master/LICENSE\"><img src=\"https://img.shields.io/github/license/qdrant/qdrant?style=flat-square\" alt=\"Apache 2.0 License\"></a>\n    <a href=\"https://qdrant.to/discord\"><img src=\"https://img.shields.io/discord/907569970500743200?logo=Discord&style=flat-square&color=7289da\" alt=\"Discord\"></a>\n    <a href=\"https://qdrant.to/roadmap\"><img src=\"https://img.shields.io/badge/Roadmap-2023-bc1439.svg?style=flat-square\" alt=\"Roadmap 2023\"></a>\n    <a href=\"https://cloud.qdrant.io/\"><img src=\"https://img.shields.io/badge/Qdrant-Cloud-24386C.svg?logo=cloud&style=flat-square\" alt=\"Qdrant Cloud\"></a>\n</p>\n\n**Qdrant** (read: _quadrant_) is a vector similarity search engine and vector database.\nIt provides a production-ready service with a convenient API to store, search, and manage points\u2014vectors with an additional payload\nQdrant is tailored to extended filtering support. It makes it useful for all sorts of neural-network or semantic-based matching, faceted search, and other applications.\n\nQdrant is written in Rust \ud83e\udd80, which makes it fast and reliable even under high load. See [benchmarks](https://qdrant.tech/benchmarks/).\n\nWith Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!\n\nQdrant is also available as a fully managed **[Qdrant Cloud](https://cloud.qdrant.io/)** \u26c5 including a **free tier**.\n\n<p align=\"center\">\n<strong><a href=\"./QUICK_START.md\">Quick Start</a> \u2022 <a href=\"#clients\">Client Libraries</a> \u2022 <a href=\"#demo-projects\">Demo Projects</a> \u2022 <a href=\"#integrations\">Integrations</a> \u2022 <a href=\"#contacts\">Contact</a>\n\n</strong>\n</p>\n\n## Getting Started\n\n### Python\n\n```\npip install qdrant-client\n```\n\nThe python client offers a convenient way to start with Qdrant locally:\n\n```python\nfrom qdrant_client import QdrantClient\nqdrant = QdrantClient(\":memory:\") # Create in-memory Qdrant instance, for testing, CI/CD\n# OR\nclient = QdrantClient(path=\"path/to/db\")  # Persists changes to disk, fast prototyping\n```\n\n### Client-Server\n\nThis is the recommended method for production usage. To run the container, use the command:\n\n```bash\ndocker run -p 6333:6333 qdrant/qdrant\n```\n\nNow you can connect to this with any client, including Python:\n\n```python\nqdrant = QdrantClient(\"http://localhost:6333\") # Connect to existing Qdrant instance, for production\n```\n\n### Clients\n\nQdrant offers the following client libraries to help you integrate it into your application stack with ease:\n\n- Official: [Go client](https://github.com/qdrant/go-client)\n- Official: [Rust client](https://github.com/qdrant/rust-client)\n- Official: [JavaScript/TypeScript client](https://github.com/qdrant/qdrant-js)\n- Official: [Python client](https://github.com/qdrant/qdrant-client)\n- Community: [Elixir](https://hexdocs.pm/qdrant/readme.html)\n- Community: [PHP](https://github.com/hkulekci/qdrant-php)\n- Community: [Ruby](https://github.com/andreibondarev/qdrant-ruby)\n- Community: [Java](https://github.com/metaloom/qdrant-java-client)\n\n### Where do I go from here?\n\n- [Quick Start Guide](https://github.com/qdrant/qdrant/blob/master/QUICK_START.md)\n- End to End [Colab Notebook](https://colab.research.google.com/drive/1Bz8RSVHwnNDaNtDwotfPj0w7AYzsdXZ-?usp=sharing) demo with SentenceBERT and Qdrant\n- Detailed [Documentation](https://qdrant.tech/documentation/) are great starting points\n- [Step-by-Step Tutorial](https://qdrant.to/qdrant-tutorial) to create your first neural network project with Qdrant\n\n## Demo Projects\n\n### Discover Semantic Text Search \ud83d\udd0d\n\nUnlock the power of semantic embeddings with Qdrant, transcending keyword-based search to find meaningful connections in short texts. Deploy a neural search in minutes using a pre-trained neural network, and experience the future of text search. [Try it online!](https://qdrant.to/semantic-search-demo)\n\n### Explore Similar Image Search - Food Discovery \ud83c\udf55\n\nThere's more to discovery than text search, especially when it comes to food. People often choose meals based on appearance rather than descriptions and ingredients. Let Qdrant help your users find their next delicious meal using visual search, even if they don't know the dish's name. [Check it out!](https://qdrant.to/food-discovery)\n\n### Master Extreme Classification - E-commerce Product Categorization \ud83d\udcfa\n\nEnter the cutting-edge realm of extreme classification, an emerging machine learning field tackling multi-class and multi-label problems with millions of labels. Harness the potential of similarity learning models, and see how a pre-trained transformer model and Qdrant can revolutionize e-commerce product categorization. [Play with it online!](https://qdrant.to/extreme-classification-demo)\n\n<details>\n<summary> More solutions </summary>\n\n<table>\n    <tr>\n        <td width=\"30%\">\n            <img src=\"https://qdrant.tech/content/images/text_search.png\">\n        </td>\n        <td width=\"30%\">\n            <img src=\"https://qdrant.tech/content/images/image_search.png\">\n        </td>\n        <td width=\"30%\">\n            <img src=\"https://qdrant.tech/content/images/recommendations.png\">\n        </td>\n    </tr>\n    <tr>\n        <td>\n            Semantic Text Search\n        </td>\n        <td>\n            Similar Image Search\n        </td>\n        <td>\n            Recommendations\n        </td>\n    </tr>\n</table>\n\n<table>\n    <tr>\n        <td>\n            <img width=\"300px\" src=\"https://qdrant.tech/content/images/chat_bots.png\">\n        </td>\n        <td>\n            <img width=\"300px\" src=\"https://qdrant.tech/content/images/matching_engines.png\">\n        </td>\n        <td>\n            <img width=\"300px\" src=\"https://qdrant.tech/content/images/anomalies_detection.png\">\n        </td>\n    </tr>\n    <tr>\n        <td>\n            Chat Bots\n        </td>\n        <td>\n            Matching Engines\n        </td>\n        <td>\n            Anomaly Detection\n        </td>\n    </tr>\n</table>\n\n</details>\n\n## API\n\n### REST\n\nOnline OpenAPI 3.0 documentation is available [here](https://qdrant.github.io/qdrant/redoc/index.html).\nOpenAPI makes it easy to generate a client for virtually any framework or programming language.\n\nYou can also download raw OpenAPI [definitions](https://github.com/qdrant/qdrant/blob/master/docs/redoc/master/openapi.json).\n\n### gRPC\n\nFor faster production-tier searches, Qdrant also provides a gRPC interface. You can find gRPC documentation [here](https://qdrant.tech/documentation/quick-start/#grpc).\n\n## Features\n\n### Filtering and Payload\n\nQdrant enables JSON payloads to be associated with vectors, providing both storage and filtering based on payload values. It supports various combinations of `should`, `must`, and `must_not` conditions, ensuring retrieval of all relevant vectors unlike `ElasticSearch` post-filtering.\n\n### Rich Data Types\n\nThe vector payload accommodates diverse data types and query conditions, including string matching, numerical ranges, geo-locations, and more. These filtering conditions empower you to create custom business logic on top of similarity matching.\n\n### Query Planning and Payload Indexes\n\nThe _query planner_ leverages stored payload information to optimize query execution. For instance, smaller search spaces limited by filters might benefit from full brute force over an index.\n\n### SIMD Hardware Acceleration\n\nUtilizing modern CPU x86-x64 architectures, Qdrant delivers faster search performance on modern hardware.\n\n### Write-Ahead Logging\n\nQdrant ensures data persistence with update confirmation, even during power outages. The update journal stores all operations, enabling effortless reconstruction of the latest database state.\n\n### Distributed Deployment\n\nAs of [v0.8.0](https://github.com/qdrant/qdrant/releases/tag/v0.8.0), Qdrant supports distributed deployment. Multiple Qdrant machines form a cluster for horizontal scaling, coordinated through the [Raft](https://raft.github.io/) protocol.\n\n### Stand-alone\n\nQdrant operates independently, without reliance on external databases or orchestration controllers, simplifying configuration.\n\n# Integrations\n\nExamples and/or documentation of Qdrant integrations:\n\n- [Cohere](https://docs.cohere.com/docs/integrations#qdrant) ([blogpost on building a QA app with Cohere and Qdrant](https://qdrant.tech/articles/qa-with-cohere-and-qdrant/)) - Use Cohere embeddings with Qdrant\n- [DocArray](https://docarray.jina.ai/advanced/document-store/qdrant/) - Use Qdrant as a document store in DocArray\n- [LangChain](https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/qdrant.html) ([blogpost](https://qdrant.tech/articles/langchain-integration/)) - Use Qdrant as a memory backend for LangChain.\n- [LlamaIndex](https://gpt-index.readthedocs.io/en/latest/how_to/integrations/vector_stores.html) - Use Qdrant as a Vector Store with LlamaIndex.\n- [OpenAI - ChatGPT retrieval plugin](https://github.com/openai/chatgpt-retrieval-plugin/blob/main/docs/providers/qdrant/setup.md) - Use Qdrant as a memory backend for ChatGPT\n- [Microsoft Semantic Kernel](https://devblogs.microsoft.com/semantic-kernel/the-power-of-persistent-memory-with-semantic-kernel-and-qdrant-vector-database/) - Use Qdrant as persistent memory with Semantic Kernel\n\n## Contacts\n\n- Have questions? Join our [Discord channel](https://qdrant.to/discord) or mention [@qdrant_engine on Twitter](https://qdrant.to/twitter)\n- Want to stay in touch with latest releases? Subscribe to our [Newsletters](https://qdrant.to/newsletter)\n- Looking for a managed cloud? Check [pricing](https://qdrant.tech/pricing/), need something personalised? We're at [info@qdrant.tech](mailto:info@qdrant.tech)\n\n## Contributors \u2728\n\nThanks to the people who contributed to Qdrant:\n\n<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://t.me/neural_network_engineering\"><img src=\"https://avatars.githubusercontent.com/u/1935623?v=4?s=50\" width=\"50px;\" alt=\"Andrey Vasnetsov\"/><br /><sub><b>Andrey Vasnetsov</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=generall\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/azayarni\"><img src=\"https://avatars.githubusercontent.com/u/926368?v=4?s=50\" width=\"50px;\" alt=\"Andre Zayarni\"/><br /><sub><b>Andre Zayarni</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=azayarni\" title=\"Documentation\">\ud83d\udcd6</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.linkedin.com/in/joanfontanalsmartinez/\"><img src=\"https://avatars.githubusercontent.com/u/19825685?v=4?s=50\" width=\"50px;\" alt=\"Joan Fontanals\"/><br /><sub><b>Joan Fontanals</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=JoanFM\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/trean\"><img src=\"https://avatars.githubusercontent.com/u/7085263?v=4?s=50\" width=\"50px;\" alt=\"trean\"/><br /><sub><b>trean</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=trean\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kgrech\"><img src=\"https://avatars.githubusercontent.com/u/9020133?v=4?s=50\" width=\"50px;\" alt=\"Konstantin\"/><br /><sub><b>Konstantin</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=kgrech\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/kekonen\"><img src=\"https://avatars.githubusercontent.com/u/11177808?v=4?s=50\" width=\"50px;\" alt=\"Daniil Naumetc\"/><br /><sub><b>Daniil Naumetc</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=kekonen\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://dev.to/vearutop\"><img src=\"https://avatars.githubusercontent.com/u/1381436?v=4?s=50\" width=\"50px;\" alt=\"Viacheslav Poturaev\"/><br /><sub><b>Viacheslav Poturaev</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=vearutop\" title=\"Documentation\">\ud83d\udcd6</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/galibey\"><img src=\"https://avatars.githubusercontent.com/u/48586936?v=4?s=50\" width=\"50px;\" alt=\"Alexander Galibey\"/><br /><sub><b>Alexander Galibey</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=galibey\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/HaiCheViet\"><img src=\"https://avatars.githubusercontent.com/u/37202591?v=4?s=50\" width=\"50px;\" alt=\"HaiCheViet\"/><br /><sub><b>HaiCheViet</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=HaiCheViet\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://tranzystorek-io.github.io/\"><img src=\"https://avatars.githubusercontent.com/u/5671049?v=4?s=50\" width=\"50px;\" alt=\"Marcin Puc\"/><br /><sub><b>Marcin Puc</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=tranzystorek-io\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/anveq\"><img src=\"https://avatars.githubusercontent.com/u/94402218?v=4?s=50\" width=\"50px;\" alt=\"Anton V.\"/><br /><sub><b>Anton V.</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=anveq\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://agourlay.github.io\"><img src=\"https://avatars.githubusercontent.com/u/606963?v=4?s=50\" width=\"50px;\" alt=\"Arnaud Gourlay\"/><br /><sub><b>Arnaud Gourlay</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=agourlay\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://t.me/type_driven_thoughts\"><img src=\"https://avatars.githubusercontent.com/u/17401538?v=4?s=50\" width=\"50px;\" alt=\"Egor Ivkov\"/><br /><sub><b>Egor Ivkov</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=eadventurous\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/IvanPleshkov\"><img src=\"https://avatars.githubusercontent.com/u/20946825?v=4?s=50\" width=\"50px;\" alt=\"Ivan Pleshkov\"/><br /><sub><b>Ivan Pleshkov</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=IvanPleshkov\" title=\"Code\">\ud83d\udcbb</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/daniilsunyaev\"><img src=\"https://avatars.githubusercontent.com/u/3955599?v=4?s=50\" width=\"50px;\" alt=\"Daniil\"/><br /><sub><b>Daniil</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=daniilsunyaev\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://homeonrails.com\"><img src=\"https://avatars.githubusercontent.com/u/1282182?v=4?s=50\" width=\"50px;\" alt=\"Anton Kaliaev\"/><br /><sub><b>Anton Kaliaev</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=melekes\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://soundcloud.com/norom\"><img src=\"https://avatars.githubusercontent.com/u/7762532?v=4?s=50\" width=\"50px;\" alt=\"Andre Julius\"/><br /><sub><b>Andre Julius</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=NotNorom\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/prok20\"><img src=\"https://avatars.githubusercontent.com/u/20628026?v=4?s=50\" width=\"50px;\" alt=\"Prokudin Alexander\"/><br /><sub><b>Prokudin Alexander</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=prok20\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/elbart\"><img src=\"https://avatars.githubusercontent.com/u/48974?v=4?s=50\" width=\"50px;\" alt=\"Tim Eggert\"/><br /><sub><b>Tim Eggert</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=elbart\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/gvelo\"><img src=\"https://avatars.githubusercontent.com/u/943360?v=4?s=50\" width=\"50px;\" alt=\"Gabriel Velo\"/><br /><sub><b>Gabriel Velo</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=gvelo\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://burtonqin.github.io\"><img src=\"https://avatars.githubusercontent.com/u/11943383?v=4?s=50\" width=\"50px;\" alt=\"Boqin Qin(\u79e6 \u4f2f\u94a6)\"/><br /><sub><b>Boqin Qin(\u79e6 \u4f2f\u94a6)</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/issues?q=author%3ABurtonQin\" title=\"Bug reports\">\ud83d\udc1b</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://forloop.co.uk/blog\"><img src=\"https://avatars.githubusercontent.com/u/208231?v=4?s=50\" width=\"50px;\" alt=\"Russ Cam\"/><br /><sub><b>Russ Cam</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=russcam\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/erare-humanum\"><img src=\"https://avatars.githubusercontent.com/u/116254494?v=4?s=50\" width=\"50px;\" alt=\"erare-humanum\"/><br /><sub><b>erare-humanum</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=erare-humanum\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ffuugoo\"><img src=\"https://avatars.githubusercontent.com/u/2725918?v=4?s=50\" width=\"50px;\" alt=\"Roman Titov\"/><br /><sub><b>Roman Titov</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=ffuugoo\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://hozan23.com\"><img src=\"https://avatars.githubusercontent.com/u/119854621?v=4?s=50\" width=\"50px;\" alt=\"Hozan\"/><br /><sub><b>Hozan</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=hozan23\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/joein\"><img src=\"https://avatars.githubusercontent.com/u/22641570?v=4?s=50\" width=\"50px;\" alt=\"George\"/><br /><sub><b>George</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=joein\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/csko\"><img src=\"https://avatars.githubusercontent.com/u/749306?v=4?s=50\" width=\"50px;\" alt=\"Korn\u00e9l Csernai\"/><br /><sub><b>Korn\u00e9l Csernai</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=csko\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://coszio.github.io\"><img src=\"https://avatars.githubusercontent.com/u/62079184?v=4?s=50\" width=\"50px;\" alt=\"Luis Coss\u00edo\"/><br /><sub><b>Luis Coss\u00edo</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=coszio\" title=\"Documentation\">\ud83d\udcd6</a></td>\n    </tr>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://timvisee.com/\"><img src=\"https://avatars.githubusercontent.com/u/856222?v=4?s=50\" width=\"50px;\" alt=\"Tim Vis\u00e9e\"/><br /><sub><b>Tim Vis\u00e9e</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=timvisee\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://www.timonv.nl\"><img src=\"https://avatars.githubusercontent.com/u/49373?v=4?s=50\" width=\"50px;\" alt=\"Timon Vonk\"/><br /><sub><b>Timon Vonk</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=timonv\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"http://loudcoder.com\"><img src=\"https://avatars.githubusercontent.com/u/12176046?v=4?s=50\" width=\"50px;\" alt=\"Yiping Deng\"/><br /><sub><b>Yiping Deng</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=DengYiping\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://weijun-h.github.io/\"><img src=\"https://avatars.githubusercontent.com/u/20267695?v=4?s=50\" width=\"50px;\" alt=\"Alex Huang\"/><br /><sub><b>Alex Huang</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=Weijun-H\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/ibrahim-akrab\"><img src=\"https://avatars.githubusercontent.com/u/30220322?v=4?s=50\" width=\"50px;\" alt=\"Ibrahim M. Akrab\"/><br /><sub><b>Ibrahim M. Akrab</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=ibrahim-akrab\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/stencillogic\"><img src=\"https://avatars.githubusercontent.com/u/59373360?v=4?s=50\" width=\"50px;\" alt=\"stencillogic\"/><br /><sub><b>stencillogic</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=stencillogic\" title=\"Code\">\ud83d\udcbb</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/moaz-mokhtar\"><img src=\"https://avatars.githubusercontent.com/u/5870208?v=4?s=50\" width=\"50px;\" alt=\"Moaz bin Mokhtar\"/><br /><sub><b>Moaz bin Mokhtar</b></sub></a><br /><a href=\"https://github.com/qdrant/qdrant/commits?author=moaz-mokhtar\" title=\"Documentation\">\ud83d\udcd6</a></td>\n    </tr>\n  </tbody>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->\n\n## License\n\nQdrant is licensed under the Apache License, Version 2.0. View a copy of the [License file](https://github.com/qdrant/qdrant/blob/master/LICENSE).\n"}, {"id": 10, "name": " \u591a\u89d2\u5ea6\n", "parent": 1}, {"id": 11, "name": "\u4e09\u4e2a\u6307\u6807\n", "parent": 10, "note": "## Q: \u9ad8\u6027\u80fd\u3001\u9ad8\u5e76\u53d1\u3001\u9ad8\u541e\u5410\u8fd9\u4e09\u4e2a\u8bcd\u5c5e\u4e8e\u6027\u80fd\u6307\u6807\u5417\uff1f\u4e3b\u8981\u7528\u4e8e\u54ea\u4e9b\u573a\u666f\uff1f\n\n\u9ad8\u6027\u80fd\u3001\u9ad8\u5e76\u53d1\u3001\u9ad8\u541e\u5410\u786e\u5b9e\u662f\u8861\u91cf\u7cfb\u7edf\u6027\u80fd\u7684\u91cd\u8981\u6307\u6807\uff1a\n\n1. \u9ad8\u6027\u80fd\uff08High Performance\uff09\uff1a\u901a\u5e38\u6307\u7684\u662f\u8ba1\u7b97\u901f\u5ea6\u5feb\u3001\u54cd\u5e94\u901f\u5ea6\u5feb\u3001\u8d44\u6e90\u5229\u7528\u7387\u9ad8\u7b49\u7279\u6027\u3002\u4f8b\u5982\uff0c\u4e00\u4e2a\u7b97\u6cd5\u7684\u6267\u884c\u901f\u5ea6\u3001\u4e00\u4e2a\u7f51\u7edc\u7684\u6570\u636e\u4f20\u8f93\u901f\u5ea6\u3001\u6216\u8005\u4e00\u4e2a\u670d\u52a1\u5668\u7684\u8bf7\u6c42\u54cd\u5e94\u901f\u5ea6\u3002\n\n2. \u9ad8\u5e76\u53d1\uff08High Concurrency\uff09\uff1a\u6307\u7684\u662f\u5728\u540c\u4e00\u65f6\u95f4\u5185\uff0c\u7cfb\u7edf\u80fd\u591f\u5904\u7406\u5927\u91cf\u7684\u5e76\u884c\u4efb\u52a1\u3002\u4f8b\u5982\uff0c\u4e00\u4e2a\u7f51\u7ad9\u80fd\u540c\u65f6\u670d\u52a1\u5927\u91cf\u7528\u6237\u6d4f\u89c8\u3001\u63d0\u4ea4\u8868\u5355\u3001\u4e0b\u8f7d\u6587\u4ef6\u7b49\u3002\n\n3. \u9ad8\u541e\u5410\uff08High Throughput\uff09\uff1a\u6307\u7684\u662f\u5728\u5355\u4f4d\u65f6\u95f4\u5185\uff0c\u7cfb\u7edf\u80fd\u591f\u5904\u7406\u7684\u4efb\u52a1\u6570\u6216\u8005\u4f20\u8f93\u7684\u6570\u636e\u91cf\u3002\u4f8b\u5982\uff0c\u6570\u636e\u5e93\u6bcf\u79d2\u80fd\u5904\u7406\u7684\u67e5\u8be2\u6b21\u6570\uff0c\u6216\u8005\u7f51\u7edc\u6bcf\u79d2\u80fd\u4f20\u8f93\u7684\u6570\u636e\u91cf\u3002\n\n\u8fd9\u4e09\u4e2a\u6027\u80fd\u6307\u6807\u7ecf\u5e38\u7528\u4e8e\u8bc4\u4f30\u548c\u6bd4\u8f83\u4e0d\u540c\u7684\u7cfb\u7edf\u548c\u6280\u672f\u65b9\u6848\u3002\u5b83\u4eec\u5728\u5f88\u591a\u573a\u666f\u4e2d\u90fd\u5341\u5206\u91cd\u8981\uff0c\u5305\u62ec\u4f46\u4e0d\u9650\u4e8e\uff1aWeb\u670d\u52a1\u5668\u3001\u6570\u636e\u5e93\u3001\u5b9e\u65f6\u8ba1\u7b97\u3001\u6570\u636e\u4e2d\u5fc3\u3001\u5206\u5e03\u5f0f\u7cfb\u7edf\u3001\u5927\u6570\u636e\u5904\u7406\u3001\u7f51\u7edc\u4f20\u8f93\u3001\u6e38\u620f\u670d\u52a1\u5668\u7b49\u3002\n\n## Q: \u8bf7\u95eetokio\u5c5e\u4e8e\u9ad8\u5e76\u53d1\u3001\u9ad8\u6027\u80fd\u8fd8\u662f\u9ad8\u541e\u5410\u65f6\u4f7f\u7528\n\n\u5173\u4e8e\u4f60\u7684\u95ee\u9898\uff0cTokio\u662f\u4e00\u4e2a\u7528\u4e8eRust\u7684\u5f02\u6b65\u7f16\u7a0b\u6846\u67b6\uff0c\u63d0\u4f9b\u4e86\u4e8b\u4ef6\u9a71\u52a8\u7684\u5e73\u53f0\u6765\u5904\u7406\u5f02\u6b65I/O\uff0c\u5305\u62ecTCP\u3001UDP\u3001\u65f6\u95f4\u5ef6\u8fdf\u548c\u5176\u4ed6\u4f4e\u7ea7\u522b\u7684\u5f02\u6b65\u5904\u7406\u3002\n\n1. \u9ad8\u5e76\u53d1\uff1a Tokio\u53ef\u4ee5\u652f\u6301\u9ad8\u5e76\u53d1\uff0c\u56e0\u4e3a\u5b83\u7684\u6838\u5fc3\u662f\u4e00\u4e2a\u4e8b\u4ef6\u5faa\u73af\uff0c\u53ef\u4ee5\u5728\u5355\u7ebf\u7a0b\u5185\u5f02\u6b65\u5904\u7406\u5927\u91cf\u7684I/O\u64cd\u4f5c\uff0c\u5927\u5927\u63d0\u9ad8\u4e86\u5e76\u53d1\u80fd\u529b\u3002\n2. \u9ad8\u6027\u80fd\uff1a\u800c\u4e14\uff0c\u56e0\u4e3aRust\u8bed\u8a00\u7684\u9ad8\u6548\u6027\uff0cTokio\u4e5f\u80fd\u5b9e\u73b0\u9ad8\u6027\u80fd\u3002\n3. \u9ad8\u541e\u5410\uff1a \u81f3\u4e8e\u541e\u5410\uff0c\u90a3\u8981\u770b\u5177\u4f53\u7684\u5e94\u7528\u573a\u666f\u548c\u4efb\u52a1\u7c7b\u578b\uff0c\u4f46\u662fTokio\u7684\u8bbe\u8ba1\u76ee\u6807\u4e4b\u4e00\u5c31\u662f\u5c3d\u53ef\u80fd\u5730\u63d0\u9ad8\u541e\u5410\u7387\u3002\n\n> \u56e0\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u8bf4Tokio\u662f\u4e3a\u652f\u6301\u9ad8\u5e76\u53d1\u3001\u9ad8\u6027\u80fd\u548c\uff08\u5728\u53ef\u80fd\u7684\u60c5\u51b5\u4e0b\uff09\u9ad8\u541e\u5410\u800c\u8bbe\u8ba1\u7684\u3002"}, {"id": 12, "name": " \u9ad8\u6027\u80fd\n", "parent": 11}, {"id": 13, "name": " \u9ad8\u5e76\u53d1\n", "parent": 11}, {"id": 14, "name": " \u9ad8\u541e\u5410\n", "parent": 11}, {"id": 15, "name": " \u4f53\u73b0\u9879\u76ee\n", "parent": 11}, {"id": 17, "name": "\u94fe\u63a51: Tokio\u751f\u6001", "link": "https://github.com/orgs/tokio-rs/repositories?type=source", "parent": 16, "note": "[\u6765\u81ea Tokio\u751f\u6001\n\u7684\u94fe\u63a5](https://github.com/orgs/tokio-rs/repositories?type=source)"}, {"id": 16, "name": " Tokio\u751f\u6001\n", "parent": 15, "note": "## Q: \u6211\u770btokio\u90fd\u6210\u4e00\u4e2a\u751f\u6001\u4e86\uff0c\u5305\u542b\u8bb8\u591a\u5185\u5bb9\uff0c\u80fd\u4e0d\u80fd\u5e2e\u6211\u7406\u4e00\u4e0b\u8fd9\u4e2a\u751f\u6001\u5305\u542b\u7684\u5185\u5bb9\uff0c\u5e76\u628a\u4e3b\u8981\u7684\u9879\u76ee\u505a\u4e00\u4e0b\u8bf4\u660e\n\n\u662f\u7684\uff0c\u4f60\u7684\u7406\u89e3\u662f\u5bf9\u7684\u3002Tokio\u5df2\u7ecf\u53d1\u5c55\u6210\u4e3a\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u751f\u6001\u7cfb\u7edf\uff0c\u5305\u542b\u8bb8\u591a\u7528\u4e8e\u5b9e\u73b0\u9ad8\u6548\u3001\u53ef\u9760\u7684\u5f02\u6b65Rust\u5e94\u7528\u7a0b\u5e8f\u7684\u7ec4\u4ef6\u3002\u4ee5\u4e0b\u662f\u4e00\u4e9bTokio\u751f\u6001\u4e2d\u7684\u5173\u952e\u9879\u76ee\uff1a\n\n1. Tokio\uff1aTokio\u662f\u6574\u4e2a\u751f\u6001\u7cfb\u7edf\u7684\u57fa\u7840\uff0c\u63d0\u4f9b\u4e86\u5f02\u6b65\u8fd0\u884c\u65f6\u73af\u5883\uff0c\u5305\u62ec\u4e8b\u4ef6\u9a71\u52a8\u7684I/O\uff0c\u5b9a\u65f6\u5668\uff0c\u4efb\u52a1\u8c03\u5ea6\u7b49\u529f\u80fd\u3002\u8fd9\u4e9b\u90fd\u4e3a\u6784\u5efa\u9ad8\u6027\u80fd\u3001\u9ad8\u5e76\u53d1\u7684\u5e94\u7528\u7a0b\u5e8f\u63d0\u4f9b\u4e86\u57fa\u7840\u8bbe\u65bd\u3002\n\n2. Hyper\uff1aHyper\u662f\u57fa\u4e8eTokio\u6784\u5efa\u7684\u4e00\u4e2a\u9ad8\u6027\u80fd\u7684HTTP\u5ba2\u6237\u7aef\u548c\u670d\u52a1\u5668\u5e93\u3002\u7531\u4e8e\u4f7f\u7528\u4e86Tokio\uff0cHyper\u53ef\u4ee5\u5904\u7406\u5927\u91cf\u5e76\u53d1\u7684HTTP\u8bf7\u6c42\uff0c\u975e\u5e38\u9002\u5408\u6784\u5efaWeb\u670d\u52a1\u548cAPI\u3002\n\n3. Tower\uff1aTower\u662f\u4e00\u4e2a\u6784\u5efa\u5728Tokio\u4e4b\u4e0a\u7684\u670d\u52a1\u62bd\u8c61\u5e93\uff0c\u53ef\u4ee5\u8ba9\u5f00\u53d1\u8005\u66f4\u65b9\u4fbf\u5730\u6784\u5efa\u5f02\u6b65\u7684\u3001\u53ef\u590d\u7528\u7684\u7f51\u7edc\u670d\u52a1\u3002\n\n4. h2\u548ch3\uff1a\u8fd9\u4e24\u4e2a\u9879\u76ee\u662fHTTP/2\u548cHTTP/3\u7684\u5b9e\u73b0\uff0c\u4f7f\u7528Tokio\u6765\u63d0\u4f9b\u5f02\u6b65\u7684\u3001\u9ad8\u6027\u80fd\u7684HTTP/2\u548cHTTP/3\u652f\u6301\u3002\n\n5. Tonic\uff1aTonic\u662f\u4e00\u4e2a\u57fa\u4e8eTokio\u7684gRPC\u6846\u67b6\uff0c\u4e3a\u6784\u5efa\u9ad8\u6548\u7684\u3001\u7c7b\u578b\u5b89\u5168\u7684\u3001\u5b9e\u65f6\u7684\u7f51\u7edc\u5e94\u7528\u63d0\u4f9b\u4e86\u652f\u6301\u3002\n\n6. Warp\uff1aWarp\u662f\u4e00\u4e2a\u57fa\u4e8eHyper\u7684Web\u670d\u52a1\u5668\u6846\u67b6\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u58f0\u660e\u5f0f\u7684\u65b9\u5f0f\u6765\u5b9a\u4e49\u8def\u7531\u548c\u8fc7\u6ee4\u5668\uff0c\u4f7f\u5f97\u5f00\u53d1Web\u670d\u52a1\u66f4\u4e3a\u7b80\u6d01\u3002\n\n7. Mio\uff1aMio\u662fTokio\u5e95\u5c42\u4f7f\u7528\u7684\u4f4e\u7ea7I/O\u5e93\uff0c\u5bf9\u5e94\u7528\u7a0b\u5e8f\u5f00\u53d1\u8005\u6765\u8bf4\u4e00\u822c\u4e0d\u9700\u8981\u76f4\u63a5\u4f7f\u7528\u3002\n\n\u4ee5\u4e0a\u8fd9\u4e9b\u9879\u76ee\u90fd\u662fTokio\u751f\u6001\u4e2d\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\uff0c\u5b83\u4eec\u4e4b\u95f4\u9ad8\u5ea6\u534f\u540c\uff0c\u5171\u540c\u6784\u6210\u4e86\u4e00\u5957\u5b8c\u6574\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u4ee5\u652f\u6301\u5f00\u53d1\u8005\u4f7f\u7528Rust\u6784\u5efa\u51fa\u5404\u79cd\u9ad8\u6027\u80fd\u3001\u9ad8\u5e76\u53d1\u7684\u7f51\u7edc\u5e94\u7528\u3002"}, {"id": 19, "name": "\u94fe\u63a51: Tokio Runtime", "link": "https://github.com/tokio-rs/tokio", "parent": 18, "note": "[\u6765\u81ea Tokio Runtime\n\u7684\u94fe\u63a5](https://github.com/tokio-rs/tokio)"}, {"id": 18, "name": " Tokio Runtime\n", "parent": 16, "note": "A runtime for writing reliable asynchronous applications with Rust. Provides I/O, networking, scheduling, timers, ..."}, {"id": 20, "name": "README\n", "parent": 18, "note": "# Tokio\n\nA runtime for writing reliable, asynchronous, and slim applications with\nthe Rust programming language. It is:\n\n* **Fast**: Tokio's zero-cost abstractions give you bare-metal\n  performance.\n\n* **Reliable**: Tokio leverages Rust's ownership, type system, and\n  concurrency model to reduce bugs and ensure thread safety.\n\n* **Scalable**: Tokio has a minimal footprint, and handles backpressure\n  and cancellation naturally.\n\n[![Crates.io][crates-badge]][crates-url]\n[![MIT licensed][mit-badge]][mit-url]\n[![Build Status][actions-badge]][actions-url]\n[![Discord chat][discord-badge]][discord-url]\n\n[crates-badge]: https://img.shields.io/crates/v/tokio.svg\n[crates-url]: https://crates.io/crates/tokio\n[mit-badge]: https://img.shields.io/badge/license-MIT-blue.svg\n[mit-url]: https://github.com/tokio-rs/tokio/blob/master/LICENSE\n[actions-badge]: https://github.com/tokio-rs/tokio/workflows/CI/badge.svg\n[actions-url]: https://github.com/tokio-rs/tokio/actions?query=workflow%3ACI+branch%3Amaster\n[discord-badge]: https://img.shields.io/discord/500028886025895936.svg?logo=discord&style=flat-square\n[discord-url]: https://discord.gg/tokio\n\n[Website](https://tokio.rs) |\n[Guides](https://tokio.rs/tokio/tutorial) |\n[API Docs](https://docs.rs/tokio/latest/tokio) |\n[Chat](https://discord.gg/tokio)\n\n## Overview\n\nTokio is an event-driven, non-blocking I/O platform for writing\nasynchronous applications with the Rust programming language. At a high\nlevel, it provides a few major components:\n\n* A multithreaded, work-stealing based task [scheduler].\n* A reactor backed by the operating system's event queue (epoll, kqueue,\n  IOCP, etc...).\n* Asynchronous [TCP and UDP][net] sockets.\n\nThese components provide the runtime components necessary for building\nan asynchronous application.\n\n[net]: https://docs.rs/tokio/latest/tokio/net/index.html\n[scheduler]: https://docs.rs/tokio/latest/tokio/runtime/index.html\n\n## Example\n\nA basic TCP echo server with Tokio.\n\nMake sure you activated the full features of the tokio crate on Cargo.toml:\n\n```toml\n[dependencies]\ntokio = { version = \"1.29.1\", features = [\"full\"] }\n```\nThen, on your main.rs:\n\n```rust,no_run\nuse tokio::net::TcpListener;\nuse tokio::io::{AsyncReadExt, AsyncWriteExt};\n\n#[tokio::main]\nasync fn main() -> Result<(), Box<dyn std::error::Error>> {\n    let listener = TcpListener::bind(\"127.0.0.1:8080\").await?;\n\n    loop {\n        let (mut socket, _) = listener.accept().await?;\n\n        tokio::spawn(async move {\n            let mut buf = [0; 1024];\n\n            // In a loop, read data from the socket and write the data back.\n            loop {\n                let n = match socket.read(&mut buf).await {\n                    // socket closed\n                    Ok(n) if n == 0 => return,\n                    Ok(n) => n,\n                    Err(e) => {\n                        eprintln!(\"failed to read from socket; err = {:?}\", e);\n                        return;\n                    }\n                };\n\n                // Write the data back\n                if let Err(e) = socket.write_all(&buf[0..n]).await {\n                    eprintln!(\"failed to write to socket; err = {:?}\", e);\n                    return;\n                }\n            }\n        });\n    }\n}\n```\n\nMore examples can be found [here][examples]. For a larger \"real world\" example, see the\n[mini-redis] repository.\n\n[examples]: https://github.com/tokio-rs/tokio/tree/master/examples\n[mini-redis]: https://github.com/tokio-rs/mini-redis/\n\nTo see a list of the available features flags that can be enabled, check our\n[docs][feature-flag-docs].\n\n## Getting Help\n\nFirst, see if the answer to your question can be found in the [Guides] or the\n[API documentation]. If the answer is not there, there is an active community in\nthe [Tokio Discord server][chat]. We would be happy to try to answer your\nquestion. You can also ask your question on [the discussions page][discussions].\n\n[Guides]: https://tokio.rs/tokio/tutorial\n[API documentation]: https://docs.rs/tokio/latest/tokio\n[chat]: https://discord.gg/tokio\n[discussions]: https://github.com/tokio-rs/tokio/discussions\n[feature-flag-docs]: https://docs.rs/tokio/#feature-flags\n\n## Contributing\n\n:balloon: Thanks for your help improving the project! We are so happy to have\nyou! We have a [contributing guide][guide] to help you get involved in the Tokio\nproject.\n\n[guide]: https://github.com/tokio-rs/tokio/blob/master/CONTRIBUTING.md\n\n## Related Projects\n\nIn addition to the crates in this repository, the Tokio project also maintains\nseveral other libraries, including:\n\n* [`hyper`]: A fast and correct HTTP/1.1 and HTTP/2 implementation for Rust.\n\n* [`tonic`]: A gRPC over HTTP/2 implementation focused on high performance, interoperability, and flexibility.\n\n* [`warp`]: A super-easy, composable, web server framework for warp speeds.\n\n* [`tower`]: A library of modular and reusable components for building robust networking clients and servers.\n\n* [`tracing`] (formerly `tokio-trace`): A framework for application-level tracing and async-aware diagnostics.\n\n* [`rdbc`]: A Rust database connectivity library for MySQL, Postgres and SQLite.\n\n* [`mio`]: A low-level, cross-platform abstraction over OS I/O APIs that powers\n  `tokio`.\n\n* [`bytes`]: Utilities for working with bytes, including efficient byte buffers.\n\n* [`loom`]: A testing tool for concurrent Rust code\n\n[`warp`]: https://github.com/seanmonstar/warp\n[`hyper`]: https://github.com/hyperium/hyper\n[`tonic`]: https://github.com/hyperium/tonic\n[`tower`]: https://github.com/tower-rs/tower\n[`loom`]: https://github.com/tokio-rs/loom\n[`rdbc`]: https://github.com/tokio-rs/rdbc\n[`tracing`]: https://github.com/tokio-rs/tracing\n[`mio`]: https://github.com/tokio-rs/mio\n[`bytes`]: https://github.com/tokio-rs/bytes\n\n## Changelog\n\nThe Tokio repository contains multiple crates. Each crate has its own changelog.\n\n * `tokio` - [view changelog](https://github.com/tokio-rs/tokio/blob/master/tokio/CHANGELOG.md)\n * `tokio-util` - [view changelog](https://github.com/tokio-rs/tokio/blob/master/tokio-util/CHANGELOG.md)\n * `tokio-stream` - [view changelog](https://github.com/tokio-rs/tokio/blob/master/tokio-stream/CHANGELOG.md)\n * `tokio-macros` - [view changelog](https://github.com/tokio-rs/tokio/blob/master/tokio-macros/CHANGELOG.md)\n * `tokio-test` - [view changelog](https://github.com/tokio-rs/tokio/blob/master/tokio-test/CHANGELOG.md)\n\n## Supported Rust Versions\n\n<!--\nWhen updating this, also update:\n- .github/workflows/ci.yml\n- CONTRIBUTING.md\n- README.md\n- tokio/README.md\n- tokio/Cargo.toml\n- tokio-util/Cargo.toml\n- tokio-test/Cargo.toml\n- tokio-stream/Cargo.toml\n-->\n\nTokio will keep a rolling MSRV (minimum supported rust version) policy of **at\nleast** 6 months. When increasing the MSRV, the new Rust version must have been\nreleased at least six months ago. The current MSRV is 1.56.0.\n\nNote that the MSRV is not increased automatically, and only as part of a minor\nrelease. The MSRV history for past minor releases can be found below:\n\n * 1.27 to now - Rust 1.56\n * 1.17 to 1.26 - Rust 1.49\n * 1.15 to 1.16 - Rust 1.46\n * 1.0 to 1.14 - Rust 1.45\n\nNote that although we try to avoid the situation where a dependency transitively\nincreases the MSRV of Tokio, we do not guarantee that this does not happen.\nHowever, every minor release will have some set of versions of dependencies that\nworks with the MSRV of that minor release.\n\n## Release schedule\n\nTokio doesn't follow a fixed release schedule, but we typically make one to two\nnew minor releases each month. We make patch releases for bugfixes as necessary.\n\n## Bug patching policy\n\nFor the purposes of making patch releases with bugfixes, we have designated\ncertain minor releases as LTS (long term support) releases. Whenever a bug\nwarrants a patch release with a fix for the bug, it will be backported and\nreleased as a new patch release for each LTS minor version. Our current LTS\nreleases are:\n\n * `1.18.x` - LTS release until June 2023. (MSRV 1.49)\n * `1.20.x` - LTS release until September 2023. (MSRV 1.49)\n * `1.25.x` - LTS release until March 2024. (MSRV 1.49)\n\nEach LTS release will continue to receive backported fixes for at least a year.\nIf you wish to use a fixed minor release in your project, we recommend that you\nuse an LTS release.\n\nTo use a fixed minor version, you can specify the version with a tilde. For\nexample, to specify that you wish to use the newest `1.18.x` patch release, you\ncan use the following dependency specification:\n```text\ntokio = { version = \"~1.18\", features = [...] }\n```\n\n## License\n\nThis project is licensed under the [MIT license].\n\n[MIT license]: https://github.com/tokio-rs/tokio/blob/master/LICENSE\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in Tokio by you, shall be licensed as MIT, without any additional\nterms or conditions.\n"}, {"id": 22, "name": "\u94fe\u63a51: tokio-console", "link": "https://github.com/tokio-rs/console", "parent": 21, "note": "[\u6765\u81ea tokio-console\n\u7684\u94fe\u63a5](https://github.com/tokio-rs/console)"}, {"id": 21, "name": " tokio-console\n", "parent": 16, "note": "a debugger for async rust!"}, {"id": 23, "name": "README\n", "parent": 21, "note": "# tokio-console\n\n[![API Documentation(`main`)](https://img.shields.io/netlify/0e5ffd50-e1fa-416e-b147-a04dab28cfb1?label=docs%20%28main%29)][main-docs]\n[![MIT licensed][mit-badge]][mit-url]\n[![Build Status][actions-badge]][actions-url]\n[![Discord chat][discord-badge]][discord-url]\n\n[Chat][discord-url] | [API Documentation (`main` branch)][main-docs]\n\n[main-docs]: https://tokio-console.netlify.app\n[mit-badge]: https://img.shields.io/badge/license-MIT-blue.svg\n[mit-url]: LICENSE\n[actions-badge]: https://github.com/tokio-rs/console/workflows/CI/badge.svg\n[actions-url]:https://github.com/tokio-rs/console/actions?query=workflow%3ACI\n[discord-badge]: https://img.shields.io/discord/500028886025895936?logo=discord&label=discord&logoColor=white\n[discord-url]: https://discord.gg/EeF3cQw\n\n## what's all this, then?\n\nthis repository contains an implementation of TurboWish/tokio-console,\na diagnostics and debugging tool for asynchronous Rust programs. the diagnostic\ntoolkit consists of multiple components:\n\n* a **wire protocol for streaming diagnostic data** from instrumented applications\n  to diagnostic tools. the wire format is defined using [gRPC] and [protocol\n  buffers], for efficient transport on the wire and interoperability between\n  different implementations of data producers and consumers.\n\n  the [`console-api`] crate contains generated code for this wire format for\n  projects using the [`tonic`] gRPC implementation. additionally, projects using\n  other gRPC code generators (including those in other languages!) can depend on\n  [the protobuf definitions] themselves.\n\n* **instrumentation for collecting diagnostic data** from a process and exposing\n  it over the wire format. the [`console-subscriber`] crate in this repository\n  contains **an implementation of the instrumentation-side API as a\n  [`tracing-subscriber`] [`Layer`]**, for projects using [Tokio] and\n  [`tracing`].\n\n* tools for **displaying and exploring diagnostic data**, implemented as gRPC\n  clients using the console wire protocol. the [`tokio-console`] crate\n  implements an **an interactive command-line tool** that consumes this data,\n  but **other implementations**, such as graphical or web-based tools, are\n  also possible.\n\n[gRPC]: https://grpc.io/\n[protocol buffers]: https://developers.google.com/protocol-buffers\n[the protobuf definitions]: https://github.com/tokio-rs/console/tree/main/console-api/proto\n[`tonic`]: https://lib.rs/crates/tonic\n[Tokio]: https://tokio.rs\n\n## extremely cool and amazing screenshots\n\nwow! whoa! it's like `top(1)` for tasks!\n\n![task list view](assets/readme/top-for-tasks.png)\n\nviewing details for a single task:\n\n![task details view](assets/readme/task-details.png)\n\n## on the shoulders of giants\n\nthe console is **part of a much larger effort** to improve debugging tooling for\nasync Rust. **a [2019 Google Summer of Code project][gsoc] by Matthias Prechtl**\n([**@matprec**]) implemented an initial prototype, with a focus on interactive log\nviewing. more recently, both **the [Tokio team][tokio-blog] and the [async\nfoundations working group][shiny-future]** have made diagnostics and debugging\ntools a priority for async Rust in 2021 and beyond. in particular, a\n[series][tw-1] of [blog][tw-2] [posts][tw-3] by [**@pnkfelix**] lay out much of\nthe vision that this project seeks to eventually implement.\n\nfurthermore, we're indebted to our antecedents in other programming languages\nand environments for inspiration. this includes tools and systems such as\n[`pprof`], Unix [`top(1)`] and [`htop(1)`], XCode's [Instruments], and many\nothers.\n\n[gsoc]: https://github.com/tokio-rs/console-gsoc\n[tokio-blog]: https://tokio.rs/blog/2020-12-tokio-1-0#tracing\n[shiny-future]: https://rust-lang.github.io/wg-async/vision/submitted_stories/shiny_future/barbara_makes_a_wish.html\n[tw-1]: http://blog.pnkfx.org/blog/2021/04/26/road-to-turbowish-part-1-goals/\n[tw-2]: http://blog.pnkfx.org/blog/2021/04/27/road-to-turbowish-part-2-stories/\n[tw-3]: http://blog.pnkfx.org/blog/2021/05/03/road-to-turbowish-part-3-design/\n[`pprof`]: https://github.com/google/pprof\n[`top(1)`]: https://man7.org/linux/man-pages/man1/top.1.html\n[`htop(1)`]: https://htop.dev/\n[Instruments]: https://developer.apple.com/library/archive/documentation/ToolsLanguages/Conceptual/Xcode_Overview/MeasuringPerformance.html\n[**@matprec**]: https://github.com/matprec\n[**@pnkfelix**]: https://github.com/pnkfelix\n\n## using it\n\n### instrumenting your program\n\nto **instrument an application using Tokio**, add a dependency on the\n[`console-subscriber`] crate, and **add this one-liner** to the top of your\n`main` function:\n\n```rust\nconsole_subscriber::init();\n```\n\nnotes:\n\n* in order to collect task data from Tokio, **the `tokio_unstable` cfg must be\n  enabled**. for example, you could build your project with\n\n  ```shell\n  RUSTFLAGS=\"--cfg tokio_unstable\" cargo build\n  ```\n\n  or add the following to your `.cargo/config.toml` file:\n\n  ```toml\n  [build]\n  rustflags = [\"--cfg\", \"tokio_unstable\"]\n  ```\n\n  For more information on the appropriate location of your `.cargo/config.toml` file,\n  especially when using workspaces, see the\n  [console-subscriber readme](console-subscriber/README.md#enabling-tokio-instrumentation).\n* the `tokio` and `runtime` [`tracing` targets] must be enabled at the [`TRACE`\n  level].\n\n  * if you're using the [`console_subscriber::init()`][init] or\n  [`console_subscriber::Builder`][builder] APIs, these targets are enabled\n  automatically.\n\n  * if you are manually configuring the `tracing` subscriber using the\n  [`EnvFilter`] or [`Targets`] filters from [`tracing-subscriber`], add\n  `\"tokio=trace,runtime=trace\"` to your filter configuration.\n\n  * also, ensure you have not enabled any of the [compile time filter\n    features][compile_time_filters] in your `Cargo.toml`.\n\n### running the console\n\nto **run the console command-line tool**, install `tokio-console` from [crates.io](https://crates.io/crates/tokio-console)\n\n```shell\ncargo install --locked tokio-console\n```\n\nand run locally\n\n```shell\ntokio-console\n```\n\n> **alternative method:** run the tool from a local checkout of this repository\n>\n> ```shell\n> $ cargo run\n> ```\n\nby default, this will attempt to connect to an instrumented application running\non localhost on port 6669. if the application is running somewhere else, or is\nserving the console endpoint on a different port, a target address can be passed\nas an argument to the console (either as an `<IP>:<PORT>` or\n`<DNS_NAME>:<PORT>`). for example:\n\n```shell\ncargo run -- http://my.great.console.app.local:5555\n```\n\nThe console command-line tool supports a number of additional flags to configure\nits behavior. The `help` command will print a list of supported command-line\nflags and arguments:\n\n```text\nUSAGE:\n    tokio-console [OPTIONS] [TARGET_ADDR] [SUBCOMMAND]\n\nARGS:\n    <TARGET_ADDR>\n            The address of a console-enabled process to connect to.\n\n            This may be an IP address and port, or a DNS name.\n\n            On Unix platforms, this may also be a URI with the `file` scheme that specifies the path\n            to a Unix domain socket, as in `file://localhost/path/to/socket`.\n\n            [default: http://127.0.0.1:6669]\n\nOPTIONS:\n        --ascii-only <ASCII_ONLY>\n            Explicitly use only ASCII characters\n\n        --colorterm <truecolor>\n            Overrides the value of the `COLORTERM` environment variable.\n\n            If this is set to `24bit` or `truecolor`, 24-bit RGB color support will be enabled.\n\n            [env: COLORTERM=truecolor]\n            [possible values: 24bit, truecolor]\n\n    -h, --help\n            Print help information\n\n        --lang <LANG>\n            Overrides the terminal's default language\n\n            [env: LANG=]\n\n        --log <ENV_FILTER>\n            Log level filter for the console's internal diagnostics.\n\n            Logs are written to a new file at the path given by the `--log-dir` argument (or its\n            default value), or to the system journal if `systemd-journald` support is enabled.\n\n            If this is set to 'off' or is not set, no logs will be written.\n\n            [default: off]\n\n            [env: RUST_LOG=]\n\n        --log-dir <LOG_DIRECTORY>\n            Path to a directory to write the console's internal logs to.\n\n            [default: /tmp/tokio-console/logs]\n\n        --no-colors\n            Disable ANSI colors entirely\n\n        --no-duration-colors <COLOR_DURATIONS>\n            Disable color-coding for duration units\n\n        --no-terminated-colors <COLOR_TERMINATED>\n            Disable color-coding for terminated tasks\n\n        --palette <PALETTE>\n            Explicitly set which color palette to use\n\n            [possible values: 8, 16, 256, all, off]\n\n        --retain-for <RETAIN_FOR>\n            How long to continue displaying completed tasks and dropped resources after they have\n            been closed.\n\n            This accepts either a duration, parsed as a combination of time spans (such as `5days\n            2min 2s`), or `none` to disable removing completed tasks and dropped resources.\n\n            Each time span is an integer number followed by a suffix. Supported suffixes are:\n\n            * `nsec`, `ns` -- nanoseconds\n\n            * `usec`, `us` -- microseconds\n\n            * `msec`, `ms` -- milliseconds\n\n            * `seconds`, `second`, `sec`, `s`\n\n            * `minutes`, `minute`, `min`, `m`\n\n            * `hours`, `hour`, `hr`, `h`\n\n            * `days`, `day`, `d`\n\n            * `weeks`, `week`, `w`\n\n            * `months`, `month`, `M` -- defined as 30.44 days\n\n            * `years`, `year`, `y` -- defined as 365.25 days\n\n            [default: 6s]\n\n    -V, --version\n            Print version information\n\nSUBCOMMANDS:\n    gen-completion\n            Generate shell completions\n    gen-config\n            Generate a `console.toml` config file with the default configuration values, overridden\n            by any provided command-line arguments\n    help\n            Print this message or the help of the given subcommand(s)\n```\n\n## for development\n\nthe `console-subscriber/examples` directory contains **some potentially useful\ntools**:\n\n* `app.rs`: a very simple example program that spawns a bunch of tasks in a loop\n  forever\n* `dump.rs`: a simple CLI program that dumps the data stream from a `Tasks`\n  server\n\nExamples can be executed with:\n\n```shell\ncargo run --example $name\n```\n\n[`tracing`]: https://lib.rs/crates/tracing\n[`tracing-subscriber`]: https://lib.rs/crates/tracing-subscriber\n[`console-api`]: ./console-api\n[`console-subscriber`]: ./console-subscriber\n[`tokio-console`]: ./tokio-console\n[`Layer`]: https://docs.rs/tracing-subscriber/latest/tracing_subscriber/layer/trait.Layer.html\n[`tracing` targets]: https://docs.rs/tracing/latest/tracing/struct.Metadata.html\n[`TRACE` level]: https://docs.rs/tracing/latest/tracing/struct.Level.html#associatedconstant.TRACE\n[builder]: https://docs.rs/console-subscriber/latest/console_subscriber/struct.builder.html\n[init]: https://docs.rs/console-subscriber/latest/console_subscriber/fn.init.html\n[`EnvFilter`]: https://docs.rs/tracing-subscriber/latest/tracing_subscriber/filter/struct.EnvFilter.html\n[`Targets`]: https://docs.rs/tracing-subscriber/latest/tracing_subscriber/filter/targets/struct.Targets.html\n[compile_time_filters]: https://docs.rs/tracing/latest/tracing/level_filters/index.html#compile-time-filters\n"}, {"id": 25, "name": "\u94fe\u63a51: tokio-rs/axum", "link": "https://github.com/tokio-rs/axum", "parent": 24, "note": "[\u6765\u81ea tokio-rs/axum\n\u7684\u94fe\u63a5](https://github.com/tokio-rs/axum)"}, {"id": 24, "name": " tokio-rs/axum\n", "parent": 16, "note": "Ergonomic and modular web framework built with Tokio, Tower, and Hyper"}, {"id": 26, "name": "README\n", "parent": 24, "note": "# axum\n\n`axum` is a web application framework that focuses on ergonomics and modularity.\n\n[![Build status](https://github.com/tokio-rs/axum/actions/workflows/CI.yml/badge.svg?branch=main)](https://github.com/tokio-rs/axum/actions/workflows/CI.yml)\n[![Crates.io](https://img.shields.io/crates/v/axum)](https://crates.io/crates/axum)\n[![Documentation](https://docs.rs/axum/badge.svg)](https://docs.rs/axum)\n\nMore information about this crate can be found in the [crate documentation][docs].\n\n## \ud83d\udea8 The `main` branch has unpublished, breaking changes \ud83d\udea8\n\nIn preparation for `axum` 0.7 the `main` branch currently has unpublished,\nbreaking changes. Please see the [v0.6.x](https://github.com/tokio-rs/axum/tree/v0.6.x)\nbranch for the versions of `axum` published to crates.io.\n\n## High level features\n\n- Route requests to handlers with a macro free API.\n- Declaratively parse requests using extractors.\n- Simple and predictable error handling model.\n- Generate responses with minimal boilerplate.\n- Take full advantage of the [`tower`] and [`tower-http`] ecosystem of\n  middleware, services, and utilities.\n\nIn particular the last point is what sets `axum` apart from other frameworks.\n`axum` doesn't have its own middleware system but instead uses\n[`tower::Service`]. This means `axum` gets timeouts, tracing, compression,\nauthorization, and more, for free. It also enables you to share middleware with\napplications written using [`hyper`] or [`tonic`].\n\n## Usage example\n\n```rust\nuse axum::{\n    routing::{get, post},\n    http::StatusCode,\n    response::IntoResponse,\n    Json, Router,\n};\nuse serde::{Deserialize, Serialize};\nuse std::net::SocketAddr;\n\n#[tokio::main]\nasync fn main() {\n    // initialize tracing\n    tracing_subscriber::fmt::init();\n\n    // build our application with a route\n    let app = Router::new()\n        // `GET /` goes to `root`\n        .route(\"/\", get(root))\n        // `POST /users` goes to `create_user`\n        .route(\"/users\", post(create_user));\n\n    // run our app with hyper, listening globally on port 3000\n    let listener = tokio::net::TcpListener::bind(\"0.0.0.0:3000\").await.unwrap();\n    axum::serve(listener, app).await.unwrap();\n}\n\n// basic handler that responds with a static string\nasync fn root() -> &'static str {\n    \"Hello, World!\"\n}\n\nasync fn create_user(\n    // this argument tells axum to parse the request body\n    // as JSON into a `CreateUser` type\n    Json(payload): Json<CreateUser>,\n) -> (StatusCode, Json<User>) {\n    // insert your application logic here\n    let user = User {\n        id: 1337,\n        username: payload.username,\n    };\n\n    // this will be converted into a JSON response\n    // with a status code of `201 Created`\n    (StatusCode::CREATED, Json(user))\n}\n\n// the input to our `create_user` handler\n#[derive(Deserialize)]\nstruct CreateUser {\n    username: String,\n}\n\n// the output to our `create_user` handler\n#[derive(Serialize)]\nstruct User {\n    id: u64,\n    username: String,\n}\n```\n\nYou can find this [example][readme-example] as well as other example projects in\nthe [example directory][examples].\n\nSee the [crate documentation][docs] for way more examples.\n\n## Performance\n\n`axum` is a relatively thin layer on top of [`hyper`] and adds very little\noverhead. So `axum`'s performance is comparable to [`hyper`]. You can find\nbenchmarks [here](https://github.com/programatik29/rust-web-benchmarks) and\n[here](https://web-frameworks-benchmark.netlify.app/result?l=rust).\n\n## Safety\n\nThis crate uses `#![forbid(unsafe_code)]` to ensure everything is implemented in\n100% safe Rust.\n\n## Minimum supported Rust version\n\naxum's MSRV is 1.63.\n\n## Examples\n\nThe [examples] folder contains various examples of how to use `axum`. The\n[docs] also provide lots of code snippets and examples. For full-fledged examples, check out community-maintained [showcases] or [tutorials].\n\n## Getting Help\n\nIn the `axum`'s repo we also have a [number of examples][examples] showing how\nto put everything together. Community-maintained [showcases] and [tutorials] also demonstrate how to use `axum` for real-world applications. You're also welcome to ask in the [Discord channel][chat] or open a [discussion] with your question.\n\n## Community projects\n\nSee [here][ecosystem] for a list of community maintained crates and projects\nbuilt with `axum`.\n\n## Contributing\n\n:balloon: Thanks for your help improving the project! We are so happy to have\nyou! We have a [contributing guide][contributing] to help you get involved in the\n`axum` project.\n\n## License\n\nThis project is licensed under the [MIT license][license].\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in `axum` by you, shall be licensed as MIT, without any\nadditional terms or conditions.\n\n[readme-example]: https://github.com/tokio-rs/axum/tree/main/examples/readme\n[examples]: https://github.com/tokio-rs/axum/tree/main/examples\n[docs]: https://docs.rs/axum\n[`tower`]: https://crates.io/crates/tower\n[`hyper`]: https://crates.io/crates/hyper\n[`tower-http`]: https://crates.io/crates/tower-http\n[`tonic`]: https://crates.io/crates/tonic\n[contributing]: https://github.com/tokio-rs/axum/blob/main/CONTRIBUTING.md\n[chat]: https://discord.gg/tokio\n[discussion]: https://github.com/tokio-rs/axum/discussions/new?category=q-a\n[`tower::Service`]: https://docs.rs/tower/latest/tower/trait.Service.html\n[ecosystem]: https://github.com/tokio-rs/axum/blob/main/ECOSYSTEM.md\n[showcases]: https://github.com/tokio-rs/axum/blob/main/ECOSYSTEM.md#project-showcase\n[tutorials]: https://github.com/tokio-rs/axum/blob/main/ECOSYSTEM.md#tutorials\n[license]: https://github.com/tokio-rs/axum/blob/main/axum/LICENSE\n"}, {"id": 28, "name": "\u94fe\u63a51: tokio-rs/tracing", "link": "https://github.com/tokio-rs/tracing", "parent": 27, "note": "[\u6765\u81ea tokio-rs/tracing\n\u7684\u94fe\u63a5](https://github.com/tokio-rs/tracing)"}, {"id": 27, "name": " tokio-rs/tracing\n", "parent": 16, "note": "Application level tracing for Rust."}, {"id": 29, "name": "README\n", "parent": 27, "note": "![Tracing \u2014 Structured, application-level diagnostics][splash]\n\n[splash]: https://raw.githubusercontent.com/tokio-rs/tracing/master/assets/splash.svg\n\n[![Crates.io][crates-badge]][crates-url]\n[![Documentation][docs-badge]][docs-url]\n[![Documentation (master)][docs-master-badge]][docs-master-url]\n[![MIT licensed][mit-badge]][mit-url]\n[![Build Status][actions-badge]][actions-url]\n[![Discord chat][discord-badge]][discord-url]\n\n[crates-badge]: https://img.shields.io/crates/v/tracing.svg\n[crates-url]: https://crates.io/crates/tracing\n[docs-badge]: https://docs.rs/tracing/badge.svg\n[docs-url]: https://docs.rs/tracing\n[docs-master-badge]: https://img.shields.io/badge/docs-master-blue\n[docs-master-url]: https://tracing-rs.netlify.com\n[mit-badge]: https://img.shields.io/badge/license-MIT-blue.svg\n[mit-url]: LICENSE\n[actions-badge]: https://github.com/tokio-rs/tracing/workflows/CI/badge.svg\n[actions-url]:https://github.com/tokio-rs/tracing/actions?query=workflow%3ACI\n[discord-badge]: https://img.shields.io/discord/500028886025895936?logo=discord&label=discord&logoColor=white\n[discord-url]: https://discord.gg/EeF3cQw\n\n[Website](https://tokio.rs) |\n[Chat](https://discord.gg/EeF3cQw) | [Documentation (master branch)](https://tracing-rs.netlify.com/)\n\n# The master branch is the pre-release, development version of `tracing`. Please see the [v0.1.x](https://github.com/tokio-rs/tracing/tree/v0.1.x) branch for the versions of `tracing` released to crates.io.\n\n## Overview\n\n`tracing` is a framework for instrumenting Rust programs to collect\nstructured, event-based diagnostic information. `tracing` is maintained by the\nTokio project, but does _not_ require the `tokio` runtime to be used.\n\n## Usage\n\n### In Applications\n\nIn order to record trace events, executables have to use a collector\nimplementation compatible with `tracing`. A collector implements a way of\ncollecting trace data, such as by logging it to standard output.\n[`tracing-subscriber`][tracing-subscriber-docs]'s [`fmt` module][fmt] provides\na collector for logging traces with reasonable defaults. Additionally,\n`tracing-subscriber` is able to consume messages emitted by `log`-instrumented\nlibraries and modules.\n\nTo use `tracing-subscriber`, add the following to your `Cargo.toml`:\n\n```toml\n[dependencies]\ntracing = \"0.1\"\ntracing-subscriber = \"0.3\"\n```\n\nThen create and install a collector, for example using [`init()`]:\n\n```rust\nuse tracing::info;\nuse tracing_subscriber;\n\nfn main() {\n    // install global collector configured based on RUST_LOG env var.\n    tracing_subscriber::fmt::init();\n\n    let number_of_yaks = 3;\n    // this creates a new event, outside of any spans.\n    info!(number_of_yaks, \"preparing to shave yaks\");\n\n    let number_shaved = yak_shave::shave_all(number_of_yaks);\n    info!(\n        all_yaks_shaved = number_shaved == number_of_yaks,\n        \"yak shaving completed.\"\n    );\n}\n```\n\nUsing `init()` calls [`set_global_default()`] so this collector will be used\nas the default in all threads for the remainder of the duration of the\nprogram, similar to how loggers work in the `log` crate.\n\n[tracing-subscriber-docs]: https://docs.rs/tracing-subscriber/\n[fmt]: https://docs.rs/tracing-subscriber/latest/tracing_subscriber/fmt/index.html\n[`set_global_default`]: https://docs.rs/tracing/latest/tracing/subscriber/fn.set_global_default.html\n\n\nFor more control, a collector can be built in stages and not set globally,\nbut instead used to locally override the default collector. For example:\n\n```rust\nuse tracing::{info, Level};\nuse tracing_subscriber;\n\nfn main() {\n    let collector = tracing_subscriber::fmt()\n        // filter spans/events with level TRACE or higher.\n        .with_max_level(Level::TRACE)\n        // build but do not install the subscriber.\n        .finish();\n\n    tracing::collect::with_default(collector, || {\n        info!(\"This will be logged to stdout\");\n    });\n    info!(\"This will _not_ be logged to stdout\");\n}\n```\n\nAny trace events generated outside the context of a collector will not be collected.\n\nThis approach allows trace data to be collected by multiple collectors\nwithin different contexts in the program. Note that the override only applies to the\ncurrently executing thread; other threads will not see the change from with_default.\n\nOnce a collector has been set, instrumentation points may be added to the\nexecutable using the `tracing` crate's macros.\n\n[`tracing-subscriber`]: https://docs.rs/tracing-subscriber/\n[fmt]: https://docs.rs/tracing-subscriber/latest/tracing_subscriber/fmt/index.html\n[`init()`]: https://docs.rs/tracing-subscriber/latest/tracing_subscriber/fmt/fn.init.html\n[`set_global_default()`]: https://docs.rs/tracing/latest/tracing/subscriber/fn.set_global_default.html\n\n### In Libraries\n\nLibraries should only rely on the `tracing` crate and use the provided macros\nand types to collect whatever information might be useful to downstream consumers.\n\n```rust\nuse std::{error::Error, io};\nuse tracing::{debug, error, info, span, warn, Level};\n\n// the `#[tracing::instrument]` attribute creates and enters a span\n// every time the instrumented function is called. The span is named after\n// the function or method. Parameters passed to the function are recorded as fields.\n#[tracing::instrument]\npub fn shave(yak: usize) -> Result<(), Box<dyn Error + 'static>> {\n    // this creates an event at the DEBUG level with two fields:\n    // - `excitement`, with the key \"excitement\" and the value \"yay!\"\n    // - `message`, with the key \"message\" and the value \"hello! I'm gonna shave a yak.\"\n    //\n    // unlike other fields, `message`'s shorthand initialization is just the string itself.\n    debug!(excitement = \"yay!\", \"hello! I'm gonna shave a yak.\");\n    if yak == 3 {\n        warn!(\"could not locate yak!\");\n        // note that this is intended to demonstrate `tracing`'s features, not idiomatic\n        // error handling! in a library or application, you should consider returning\n        // a dedicated `YakError`. libraries like snafu or thiserror make this easy.\n        return Err(io::Error::new(io::ErrorKind::Other, \"shaving yak failed!\").into());\n    } else {\n        debug!(\"yak shaved successfully\");\n    }\n    Ok(())\n}\n\npub fn shave_all(yaks: usize) -> usize {\n    // Constructs a new span named \"shaving_yaks\" at the TRACE level,\n    // and a field whose key is \"yaks\". This is equivalent to writing:\n    //\n    // let span = span!(Level::TRACE, \"shaving_yaks\", yaks = yaks);\n    //\n    // local variables (`yaks`) can be used as field values\n    // without an assignment, similar to struct initializers.\n    let span = span!(Level::TRACE, \"shaving_yaks\", yaks);\n    let _enter = span.enter();\n\n    info!(\"shaving yaks\");\n\n    let mut yaks_shaved = 0;\n    for yak in 1..=yaks {\n        let res = shave(yak);\n        debug!(yak, shaved = res.is_ok());\n\n        if let Err(ref error) = res {\n            // Like spans, events can also use the field initialization shorthand.\n            // In this instance, `yak` is the field being initialized.\n            error!(yak, error = error.as_ref(), \"failed to shave yak!\");\n        } else {\n            yaks_shaved += 1;\n        }\n        debug!(yaks_shaved);\n    }\n\n    yaks_shaved\n}\n```\n\n```toml\n[dependencies]\ntracing = \"0.1\"\n```\n\nNote: Libraries should *NOT* install a collector by using a method that calls\n[`set_global_default()`], as this will cause conflicts when executables try to\nset the default later.\n\n### In Asynchronous Code\n\nTo trace `async fn`s, the preferred method is using the [`#[instrument]`][instrument] attribute:\n\n```rust\nuse tracing::{info, instrument};\nuse tokio::{io::AsyncWriteExt, net::TcpStream};\nuse std::io;\n\n#[instrument]\nasync fn write(stream: &mut TcpStream) -> io::Result<usize> {\n    let result = stream.write(b\"hello world\\n\").await;\n    info!(\"wrote to stream; success={:?}\", result.is_ok());\n    result\n}\n```\n\nSpecial handling is needed for the general case of code using\n[`std::future::Future`][std-future] or blocks with `async`/`await`, as the\nfollowing example _will not_ work:\n\n```rust\nasync {\n    let _s = span.enter();\n    // ...\n}\n```\n\nThe span guard `_s` will not exit until the future generated by the `async` block is complete.\nSince futures and spans can be entered and exited _multiple_ times without them completing,\nthe span remains entered for as long as the future exists, rather than being entered only when\nit is polled, leading to very confusing and incorrect output.\nFor more details, see [the documentation on closing spans][closing].\n\nThis problem can be solved using the [`Future::instrument`] combinator:\n\n```rust\nuse tracing::Instrument;\n\nlet my_future = async {\n    // ...\n};\n\nmy_future\n    .instrument(tracing::info_span!(\"my_future\"))\n    .await\n```\n\n`Future::instrument` attaches a span to the future, ensuring that the span's lifetime\nis as long as the future's.\n\nUnder the hood, the [`#[instrument]`][instrument] macro performs the same explicit span\nattachment that `Future::instrument` does.\n\n[std-future]: https://doc.rust-lang.org/stable/std/future/trait.Future.html\n[closing]: https://docs.rs/tracing/latest/tracing/span/index.html#closing-spans\n[`Future::instrument`]: https://docs.rs/tracing/latest/tracing/trait.Instrument.html#method.instrument\n[instrument]: https://docs.rs/tracing/latest/tracing/attr.instrument.html\n\n## Supported Rust Versions\n\nTracing is built against the latest stable release. The minimum supported\nversion is 1.56. The current Tracing version is not guaranteed to build on Rust\nversions earlier than the minimum supported version.\n\nTracing follows the same compiler support policies as the rest of the Tokio\nproject. The current stable Rust compiler and the three most recent minor\nversions before it will always be supported. For example, if the current stable\ncompiler version is 1.69, the minimum supported version will not be increased\npast 1.66, three minor versions prior. Increasing the minimum supported compiler\nversion is not considered a semver breaking change as long as doing so complies\nwith this policy.\n\n## Getting Help\n\nFirst, see if the answer to your question can be found in the API documentation.\nIf the answer is not there, there is an active community in\nthe [Tracing Discord channel][chat]. We would be happy to try to answer your\nquestion. Last, if that doesn't work, try opening an [issue] with the question.\n\n[chat]: https://discord.gg/EeF3cQw\n[issue]: https://github.com/tokio-rs/tracing/issues/new\n\n## Contributing\n\n:balloon: Thanks for your help improving the project! We are so happy to have\nyou! We have a [contributing guide][guide] to help you get involved in the Tracing\nproject.\n\n[guide]: CONTRIBUTING.md\n\n## Project layout\n\nThe [`tracing`] crate contains the primary _instrumentation_ API, used for\ninstrumenting libraries and applications to emit trace data. The [`tracing-core`]\ncrate contains the _core_ API primitives on which the rest of `tracing` is\ninstrumented. Authors of trace subscribers may depend on `tracing-core`, which\nguarantees a higher level of stability.\n\nAdditionally, this repository contains several compatibility and utility\nlibraries built on top of `tracing`. Some of these crates are in a pre-release\nstate, and are less stable than the `tracing` and `tracing-core` crates.\n\nThe crates included as part of Tracing are:\n\n* [`tracing-futures`]: Utilities for instrumenting `futures`.\n  ([crates.io][fut-crates]|[docs][fut-docs])\n\n* [`tracing-macros`]: Experimental macros for emitting trace events (unstable).\n\n* [`tracing-attributes`]: Procedural macro attributes for automatically\n    instrumenting functions. ([crates.io][attr-crates]|[docs][attr-docs])\n\n* [`tracing-log`]: Compatibility with the `log` crate (unstable).\n\n* [`tracing-serde`]: A compatibility layer for serializing trace data with\n    `serde` (unstable).\n\n* [`tracing-subscriber`]: Collector implementations, and utilities for\n  implementing and composing `Collector`s.\n  ([crates.io][sub-crates]|[docs][sub-docs])\n\n* [`tracing-tower`]: Compatibility with the `tower` ecosystem (unstable).\n\n* [`tracing-appender`]: Utilities for outputting tracing data, including a file appender\n   and non-blocking writer. ([crates.io][app-crates]|[docs][app-docs])\n\n* [`tracing-error`]: Provides `SpanTrace`, a type for instrumenting errors with\n  tracing spans\n\n* [`tracing-flame`]; Provides a layer for generating flame graphs based on\n  tracing span entry / exit events.\n\n* [`tracing-journald`]: Provides a layer for recording events to the\n  Linux `journald` service, preserving structured data.\n\n[`tracing`]: tracing\n[`tracing-core`]: tracing-core\n[`tracing-futures`]: tracing-futures\n[`tracing-macros`]: tracing-macros\n[`tracing-attributes`]: tracing-attributes\n[`tracing-log`]: tracing-log\n[`tracing-serde`]: tracing-serde\n[`tracing-subscriber`]: tracing-subscriber\n[`tracing-tower`]: tracing-tower\n[`tracing-appender`]: tracing-appender\n[`tracing-error`]: tracing-error\n[`tracing-flame`]: tracing-flame\n[`tracing-journald`]: tracing-journald\n\n[fut-crates]: https://crates.io/crates/tracing-futures\n[fut-docs]: https://docs.rs/tracing-futures\n\n[attr-crates]: https://crates.io/crates/tracing-attributes\n[attr-docs]: https://docs.rs/tracing-attributes\n\n[sub-crates]: https://crates.io/crates/tracing-subscriber\n[sub-docs]: https://docs.rs/tracing-subscriber\n\n[otel-crates]: https://crates.io/crates/tracing-opentelemetry\n[otel-docs]: https://docs.rs/tracing-opentelemetry\n[OpenTelemetry]: https://opentelemetry.io/\n\n[app-crates]: https://crates.io/crates/tracing-appender\n[app-docs]: https://docs.rs/tracing-appender\n\n## Related Crates\n\nIn addition to this repository, here are also several third-party crates which\nare not maintained by the `tokio` project. These include:\n\n- [`tracing-timing`] implements inter-event timing metrics on top of `tracing`.\n  It provides a subscriber that records the time elapsed between pairs of\n  `tracing` events and generates histograms.\n- [`tracing-honeycomb`] Provides a layer that reports traces spanning multiple machines to [honeycomb.io]. Backed by [`tracing-distributed`].\n- [`tracing-distributed`] Provides a generic implementation of a layer that reports traces spanning multiple machines to some backend.\n- [`tracing-actix-web`] provides `tracing` integration for the `actix-web` web framework.\n- [`tracing-actix`] provides `tracing` integration for the `actix` actor\n  framework.\n- [`tracing-gelf`] implements a subscriber for exporting traces in Greylog\n  GELF format.\n- [`tracing-coz`] provides integration with the [coz] causal profiler\n  (Linux-only).\n- [`tracing-bunyan-formatter`] provides a layer implementation that reports events and spans in [bunyan] format, enriched with timing information.\n- [`tide-tracing`] provides a [tide] middleware to trace all incoming requests and responses.\n- [`color-spantrace`] provides a formatter for rendering span traces in the\n  style of `color-backtrace`\n- [`color-eyre`] provides customized panic and eyre report handlers for\n  `eyre::Report` for capturing span traces and backtraces with new errors and\n  pretty printing them.\n- [`spandoc`] provides a proc macro for constructing spans from doc comments\n  _inside_ of functions.\n- [`tracing-wasm`] provides a `Collector`/`Subscriber` implementation that reports\n  events and spans via browser `console.log` and [User Timing API (`window.performance`)].\n- [`tracing-web`] provides a layer implementation of level-aware logging of events\n  to web browsers' `console.*` and span events to the [User Timing API (`window.performance`)].\n- [`test-log`] takes care of initializing `tracing` for tests, based on\n  environment variables with an `env_logger` compatible syntax.\n- [`tracing-unwrap`] provides convenience methods to report failed unwraps on `Result` or `Option` types to a `Collector`.\n- [`diesel-tracing`] provides integration with [`diesel`] database connections.\n- [`tracing-tracy`] provides a way to collect [Tracy] profiles in instrumented\n  applications.\n- [`tracing-elastic-apm`] provides a layer for reporting traces to [Elastic APM].\n- [`tracing-etw`] provides a layer for emitting Windows [ETW] events.\n- [`sentry-tracing`] provides a layer for reporting events and traces to [Sentry].\n- [`tracing-forest`] provides a subscriber that preserves contextual coherence by \n  grouping together logs from the same spans during writing.\n- [`tracing-loki`] provides a layer for shipping logs to [Grafana Loki].\n- [`tracing-logfmt`] provides a layer that formats events and spans into the logfmt format.\n- [`tracing-chrome`] provides a layer that exports trace data that can be viewed in `chrome://tracing`.\n- [`reqwest-tracing`] provides a middleware to trace [`reqwest`] HTTP requests.\n\n(if you're the maintainer of a `tracing` ecosystem crate not in this list,\nplease let us know!)\n\n[`tracing-timing`]: https://crates.io/crates/tracing-timing\n[`tracing-honeycomb`]: https://crates.io/crates/tracing-honeycomb\n[`tracing-distributed`]: https://crates.io/crates/tracing-distributed\n[honeycomb.io]: https://www.honeycomb.io/\n[`tracing-actix`]: https://crates.io/crates/tracing-actix\n[`tracing-actix-web`]: https://crates.io/crates/tracing-actix-web\n[`tracing-gelf`]: https://crates.io/crates/tracing-gelf\n[`tracing-coz`]: https://crates.io/crates/tracing-coz\n[coz]: https://github.com/plasma-umass/coz\n[`tracing-bunyan-formatter`]: https://crates.io/crates/tracing-bunyan-formatter\n[`tide-tracing`]: https://crates.io/crates/tide-tracing\n[tide]: https://crates.io/crates/tide\n[bunyan]: https://github.com/trentm/node-bunyan\n[`color-spantrace`]: https://docs.rs/color-spantrace\n[`color-eyre`]: https://docs.rs/color-eyre\n[`spandoc`]: https://docs.rs/spandoc\n[`tracing-wasm`]: https://docs.rs/tracing-wasm\n[`tracing-web`]: https://crates.io/crates/tracing-web\n[`test-log`]: https://crates.io/crates/test-log\n[User Timing API (`window.performance`)]: https://developer.mozilla.org/en-US/docs/Web/API/User_Timing_API\n[`tracing-unwrap`]: https://docs.rs/tracing-unwrap\n[`diesel`]: https://crates.io/crates/diesel\n[`diesel-tracing`]: https://crates.io/crates/diesel-tracing\n[`tracing-tracy`]: https://crates.io/crates/tracing-tracy\n[Tracy]: https://github.com/wolfpld/tracy\n[`tracing-elastic-apm`]: https://crates.io/crates/tracing-elastic-apm\n[Elastic APM]: https://www.elastic.co/apm\n[`tracing-etw`]: https://github.com/microsoft/tracing-etw\n[ETW]: https://docs.microsoft.com/en-us/windows/win32/etw/about-event-tracing\n[`sentry-tracing`]: https://crates.io/crates/sentry-tracing\n[Sentry]: https://sentry.io/welcome/\n[`tracing-forest`]: https://crates.io/crates/tracing-forest\n[`tracing-loki`]: https://crates.io/crates/tracing-loki\n[Grafana Loki]: https://grafana.com/oss/loki/\n[`tracing-logfmt`]: https://crates.io/crates/tracing-logfmt\n[`tracing-chrome`]: https://crates.io/crates/tracing-chrome\n[`reqwest-tracing`]: https://crates.io/crates/reqwest-tracing\n[`reqwest`]: https://crates.io/crates/reqwest\n\n**Note:** that some of the ecosystem crates are currently unreleased and\nundergoing active development. They may be less stable than `tracing` and\n`tracing-core`.\n\n## External Resources\n\nThis is a list of links to blog posts, conference talks, and tutorials about\nTracing.\n\n#### Blog Posts\n\n* [Diagnostics with Tracing][tokio-blog-2019-08] on the Tokio blog, August 2019\n* [Production-Grade Logging in Rust Applications][production-logging-2020], November 2020\n* [Custom Logging in Rust using `tracing` and `tracing-subscriber`, part 1][custom-logging-part-1] and [part 2][custom-logging-part-2], October 2021\n\n[tokio-blog-2019-08]: https://tokio.rs/blog/2019-08-tracing/\n\n#### Talks\n\n* [Bay Area Rust Meetup talk and Q&A][bay-rust-2019-03], March 2019\n* [RustConf 2019 talk][rust-conf-2019-08-video] and [slides][rust-conf-2019-08-slides], August 2019\n* [Are we observable yet? @ RustyDays talk][rusty-days-2020-08-video] and [slides][rusty-days-2020-08-slides], August 2020\n\n[bay-rust-2019-03]: https://www.youtube.com/watch?v=j_kXRg3zlec\n[rust-conf-2019-08-video]: https://www.youtube.com/watch?v=JjItsfqFIdo\n[rust-conf-2019-08-slides]: https://www.elizas.website/slides/rustconf-8-2019.pdf\n[rusty-days-2020-08-video]: https://youtu.be/HtKnLiFwHJM\n[rusty-days-2020-08-slides]: https://docs.google.com/presentation/d/1zrxJs7fJgQ29bKfnAll1bYTo9cYZxsCZUwDDtyp5Fak/edit?usp=sharing\n[production-logging-2020]: https://medium.com/better-programming/production-grade-logging-in-rust-applications-2c7fffd108a6\n[custom-logging-part-1]: https://burgers.io/custom-logging-in-rust-using-tracing\n[custom-logging-part-2]: https://burgers.io/custom-logging-in-rust-using-tracing-part-2\n\nHelp us expand this list! If you've written or spoken about Tracing, or\nknow of resources that aren't listed, please open a pull request adding them.\n\n## License\n\nThis project is licensed under the [MIT license](LICENSE).\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in Tracing by you, shall be licensed as MIT, without any additional\nterms or conditions.\n"}, {"id": 31, "name": "\u94fe\u63a51: tokio-rs/tracing-opentelemetry", "link": "https://github.com/tokio-rs/tracing-opentelemetry", "parent": 30, "note": "[\u6765\u81ea tokio-rs/tracing-opentelemetry\n\u7684\u94fe\u63a5](https://github.com/tokio-rs/tracing-opentelemetry)"}, {"id": 30, "name": " tokio-rs/tracing-opentelemetry\n", "parent": 27, "note": "Utilities for adding OpenTelemetry interoperability to tracing."}, {"id": 32, "name": "README\n", "parent": 30, "note": "![Tracing \u2014 Structured, application-level diagnostics][splash]\n\n[splash]: https://raw.githubusercontent.com/tokio-rs/tracing/master/assets/splash.svg\n\n# Tracing OpenTelemetry\n\nUtilities for adding [OpenTelemetry] interoperability to [`tracing`].\n\n[![Crates.io][crates-badge]][crates-url]\n[![Documentation][docs-badge]][docs-url]\n[![Documentation (master)][docs-master-badge]][docs-master-url]\n[![MIT licensed][mit-badge]][mit-url]\n[![Build Status][actions-badge]][actions-url]\n[![Discord chat][discord-badge]][discord-url]\n![maintenance status][maint-badge]\n\n[Documentation][docs-url] | [Chat][discord-url]\n\n[crates-badge]: https://img.shields.io/crates/v/tracing-opentelemetry.svg\n[crates-url]: https://crates.io/crates/tracing-opentelemetry/0.19.0\n[docs-badge]: https://docs.rs/tracing-opentelemetry/badge.svg\n[docs-url]: https://docs.rs/tracing-opentelemetry/0.19.0/tracing_opentelemetry\n[docs-master-badge]: https://img.shields.io/badge/docs-master-blue\n[docs-master-url]: https://tracing-rs.netlify.com/tracing_opentelemetry\n[mit-badge]: https://img.shields.io/badge/license-MIT-blue.svg\n[mit-url]: LICENSE\n[actions-badge]: https://github.com/tokio-rs/tracing-opentelemetry/workflows/CI/badge.svg\n[actions-url]:https://github.com/tokio-rs/tracing-opentelemetry/actions?query=workflow%3ACI\n[discord-badge]: https://img.shields.io/discord/500028886025895936?logo=discord&label=discord&logoColor=white\n[discord-url]: https://discord.gg/EeF3cQw\n[maint-badge]: https://img.shields.io/badge/maintenance-actively--developed-brightgreen.svg\n\n## Overview\n\n[`tracing`] is a framework for instrumenting Rust programs to collect\nstructured, event-based diagnostic information. This crate provides a\nsubscriber that connects spans from multiple systems into a trace and\nemits them to [OpenTelemetry]-compatible distributed tracing systems\nfor processing and visualization.\n\nThe crate provides the following types:\n\n* [`OpenTelemetryLayer`] adds OpenTelemetry context to all `tracing` [span]s.\n* [`OpenTelemetrySpanExt`] allows OpenTelemetry parent trace information to be\n  injected and extracted from a `tracing` [span].\n\n[`OpenTelemetryLayer`]: https://docs.rs/tracing-opentelemetry/latest/tracing_opentelemetry/struct.OpenTelemetryLayer.html\n[`OpenTelemetrySpanExt`]: https://docs.rs/tracing-opentelemetry/latest/tracing_opentelemetry/trait.OpenTelemetrySpanExt.html\n[span]: https://docs.rs/tracing/latest/tracing/span/index.html\n[`tracing`]: https://crates.io/crates/tracing\n[OpenTelemetry]: https://opentelemetry.io/\n\n*Compiler support: [requires `rustc` 1.60+][msrv]*\n\n[msrv]: #supported-rust-versions\n\n## Examples\n\n### Basic Usage\n\n```rust\nuse opentelemetry::sdk::export::trace::stdout;\nuse tracing::{error, span};\nuse tracing_subscriber::layer::SubscriberExt;\nuse tracing_subscriber::Registry;\n\nfn main() {\n    // Install a new OpenTelemetry trace pipeline\n    let tracer = stdout::new_pipeline().install_simple();\n\n    // Create a tracing layer with the configured tracer\n    let telemetry = tracing_opentelemetry::layer().with_tracer(tracer);\n\n    // Use the tracing subscriber `Registry`, or any other subscriber\n    // that impls `LookupSpan`\n    let subscriber = Registry::default().with(telemetry);\n\n    // Trace executed code\n    tracing::subscriber::with_default(subscriber, || {\n        // Spans will be sent to the configured OpenTelemetry exporter\n        let root = span!(tracing::Level::TRACE, \"app_start\", work_units = 2);\n        let _enter = root.enter();\n\n        error!(\"This event will be logged in the root span.\");\n    });\n}\n```\n\n### Visualization example\n\n```console\n# Run a supported collector like jaeger in the background\n$ docker run -d -p6831:6831/udp -p6832:6832/udp -p16686:16686 jaegertracing/all-in-one:latest\n\n# Run example to produce spans (from parent examples directory)\n$ cargo run --example opentelemetry\n\n# View spans (see the image below)\n$ firefox http://localhost:16686/\n```\n\n![Jaeger UI](trace.png)\n\n## Feature Flags\n\n - `metrics`: Enables the [`MetricsSubscriber`] type, a [subscriber] that\n   exports OpenTelemetry metrics from specifically-named events. This enables\n   the `metrics` feature flag on the `opentelemetry` crate.\n\n## Supported Rust Versions\n\nTracing Opentelemetry is built against the latest stable release. The minimum\nsupported version is 1.60. The current Tracing version is not guaranteed to\nbuild on Rust versions earlier than the minimum supported version.\n\nTracing follows the same compiler support policies as the rest of the Tokio\nproject. The current stable Rust compiler and the three most recent minor\nversions before it will always be supported. For example, if the current stable\ncompiler version is 1.45, the minimum supported version will not be increased\npast 1.42, three minor versions prior. Increasing the minimum supported compiler\nversion is not considered a semver breaking change as long as doing so complies\nwith this policy.\n\n## License\n\nThis project is licensed under the [MIT license](LICENSE).\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in Tracing by you, shall be licensed as MIT, without any additional\nterms or conditions.\n"}, {"id": 34, "name": "\u94fe\u63a51: tokio-rs/loom", "link": "https://github.com/tokio-rs/loom", "parent": 33, "note": "[\u6765\u81ea tokio-rs/loom\n\u7684\u94fe\u63a5](https://github.com/tokio-rs/loom)"}, {"id": 33, "name": " tokio-rs/loom\n", "parent": 16, "note": "Concurrency permutation testing tool for Rust."}, {"id": 35, "name": "README\n", "parent": 33, "note": "# Loom\n\nLoom is a testing tool for concurrent Rust code. It runs a test many\ntimes, permuting the possible concurrent executions of that test under\nthe [C11 memory model][spec]. It uses [state reduction\ntechniques][cdschecker] to avoid combinatorial explosion.\n\n[![Crates.io](https://img.shields.io/crates/v/loom.svg)](https://crates.io/crates/loom)\n[![Documentation](https://docs.rs/loom/badge.svg)][docs]\n[![Build Status](https://github.com/tokio-rs/loom/actions/workflows/ci.yml/badge.svg)](https://github.com/tokio-rs/loom/actions)\n[![Discord chat](https://img.shields.io/discord/500028886025895936.svg?logo=discord&style=flat-square)](https://discord.com/channels/500028886025895936/628283088555737089)\n\n[docs]: https://docs.rs/loom\n[spec]: https://en.cppreference.com/w/cpp/atomic/memory_order\n[cdschecker]: http://plrg.eecs.uci.edu/publications/toplas16.pdf\n\n## Quickstart\n\nThe [loom documentation][docs] has significantly more documentation on\nhow to use loom. But if you just want a jump-start, first add this to\nyour `Cargo.toml`.\n\n```toml\n[target.'cfg(loom)'.dependencies]\nloom = \"0.6\"\n```\n\nNext, create a test file and add a test:\n\n```rust\nuse loom::sync::Arc;\nuse loom::sync::atomic::AtomicUsize;\nuse loom::sync::atomic::Ordering::{Acquire, Release, Relaxed};\nuse loom::thread;\n\n#[test]\n#[should_panic]\nfn buggy_concurrent_inc() {\n    loom::model(|| {\n        let num = Arc::new(AtomicUsize::new(0));\n\n        let ths: Vec<_> = (0..2)\n            .map(|_| {\n                let num = num.clone();\n                thread::spawn(move || {\n                    let curr = num.load(Acquire);\n                    num.store(curr + 1, Release);\n                })\n            })\n            .collect();\n\n        for th in ths {\n            th.join().unwrap();\n        }\n\n        assert_eq!(2, num.load(Relaxed));\n    });\n}\n```\n\nThen, run the test with\n\n```console\nRUSTFLAGS=\"--cfg loom\" cargo test --test buggy_concurrent_inc --release\n```\n\n## Unsupported features\nLoom currently does not implement the full C11 memory model.\nHere is the (incomplete) list of unsupported features.\n* `SeqCst` accesses (e.g. `load`, `store`, ..):\n  They are are regarded as `AcqRel`. That is, they impose weaker\n  synchronization, causing Loom to generate false alarms (not complete). See\n  [#180](https://github.com/tokio-rs/loom/issues/180) for example. On the other\n  hand, `fence(SeqCst)` is supported.\n* Load buffering behavior:\n  Loom does not explore some executions that are possible in the C11 memory\n  model. That is, there can be a bug in the checked code even if Loom says\n  there is no bug (not sound).  See the `load_buffering` test case in\n  `tests/litmus.rs`.\n\n## License\n\nThis project is licensed under the [MIT license](LICENSE).\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally\nsubmitted for inclusion in `loom` by you, shall be licensed as MIT,\nwithout any additional terms or conditions.\n"}, {"id": 37, "name": "\u94fe\u63a51: tokio-rs/tokio-uring", "link": "https://github.com/tokio-rs/tokio-uring", "parent": 36, "note": "[\u6765\u81ea tokio-rs/tokio-uring\n\u7684\u94fe\u63a5](https://github.com/tokio-rs/tokio-uring)"}, {"id": 36, "name": " tokio-rs/tokio-uring\n", "parent": 16, "note": "An io_uring backed runtime for Rust"}, {"id": 38, "name": "README\n", "parent": 36, "note": "# tokio-uring\n\nThis crate provides [`io-uring`] for [Tokio] by exposing a new Runtime that is\ncompatible with Tokio but also can drive [`io-uring`]-backed resources. Any\nlibrary that works with [Tokio] also works with `tokio-uring`. The crate\nprovides new resource types that work with [`io-uring`].\n\n[`io-uring`]: https://unixism.net/loti/\n[Tokio]: https://github.com/tokio-rs/tokio\n[`fs::File`]: https://docs.rs/tokio-uring/latest/tokio_uring/fs/struct.File.html\n\n[API Docs](https://docs.rs/tokio-uring/latest/tokio_uring) |\n[Chat](https://discord.gg/tokio)\n\n# Getting started\n\nUsing `tokio-uring` requires starting a [`tokio-uring`] runtime. This\nruntime internally manages the main Tokio runtime and a `io-uring` driver.\n\nIn your Cargo.toml:\n```toml\n[dependencies]\ntokio-uring = { version = \"0.4.0\" }\n```\nIn your main.rs:\n```rust\nuse tokio_uring::fs::File;\n\nfn main() -> Result<(), Box<dyn std::error::Error>> {\n    tokio_uring::start(async {\n        // Open a file\n        let file = File::open(\"hello.txt\").await?;\n\n        let buf = vec![0; 4096];\n        // Read some data, the buffer is passed by ownership and\n        // submitted to the kernel. When the operation completes,\n        // we get the buffer back.\n        let (res, buf) = file.read_at(buf, 0).await;\n        let n = res?;\n\n        // Display the contents\n        println!(\"{:?}\", &buf[..n]);\n\n        Ok(())\n    })\n}\n```\n## Requirements\n`tokio-uring` requires a very recent linux kernel. (Not even all kernels with io_uring support will work)\nIn particular `5.4.0` does not work (This is standard on Ubuntu 20.4). However `5.11.0` (the ubuntu hwe image) does work.\n \n## Project status\n\nThe `tokio-uring` project is still very young. Currently, we are focusing on\nsupporting filesystem and network operations. Eventually, we will add safe APIs for all\nio-uring compatible operations.\n\n## License\n\nThis project is licensed under the [MIT license].\n\n[MIT license]: LICENSE\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in tokio-uring by you, shall be licensed as MIT, without any\nadditional terms or conditions.\n"}, {"id": 40, "name": "\u94fe\u63a51: tokio-rs/prost", "link": "https://github.com/tokio-rs/prost", "parent": 39, "note": "[\u6765\u81ea tokio-rs/prost\n\u7684\u94fe\u63a5](https://github.com/tokio-rs/prost)"}, {"id": 39, "name": " tokio-rs/prost\n", "parent": 16, "note": "PROST! a Protocol Buffers implementation for the Rust Language"}, {"id": 41, "name": "README\n", "parent": 39, "note": "![continuous integration](https://github.com/tokio-rs/prost/workflows/continuous%20integration/badge.svg)\n[![Documentation](https://docs.rs/prost/badge.svg)](https://docs.rs/prost/)\n[![Crate](https://img.shields.io/crates/v/prost.svg)](https://crates.io/crates/prost)\n[![Dependency Status](https://deps.rs/repo/github/tokio-rs/prost/status.svg)](https://deps.rs/repo/github/tokio-rs/prost)\n[![Discord](https://img.shields.io/discord/500028886025895936)](https://discord.gg/tokio)\n\n# *PROST!*\n\n`prost` is a [Protocol Buffers](https://developers.google.com/protocol-buffers/)\nimplementation for the [Rust Language](https://www.rust-lang.org/). `prost`\ngenerates simple, idiomatic Rust code from `proto2` and `proto3` files.\n\nCompared to other Protocol Buffers implementations, `prost`\n\n* Generates simple, idiomatic, and readable Rust types by taking advantage of\n  Rust `derive` attributes.\n* Retains comments from `.proto` files in generated Rust code.\n* Allows existing Rust types (not generated from a `.proto`) to be serialized\n  and deserialized by adding attributes.\n* Uses the [`bytes::{Buf, BufMut}`](https://github.com/carllerche/bytes)\n  abstractions for serialization instead of `std::io::{Read, Write}`.\n* Respects the Protobuf `package` specifier when organizing generated code\n  into Rust modules.\n* Preserves unknown enum values during deserialization.\n* Does not include support for runtime reflection or message descriptors.\n\n## Using `prost` in a Cargo Project\n\nFirst, add `prost` and its public dependencies to your `Cargo.toml`:\n\n```ignore\n[dependencies]\nprost = \"0.11\"\n# Only necessary if using Protobuf well-known types:\nprost-types = \"0.11\"\n```\n\nThe recommended way to add `.proto` compilation to a Cargo project is to use the\n`prost-build` library. See the [`prost-build` documentation](prost-build) for\nmore details and examples.\n\nSee the [snazzy repository](https://github.com/danburkert/snazzy) for a simple\nstart-to-finish example.\n\n### MSRV\n\n`prost` follows the `tokio-rs` projects MSRV model and supports 1.60. For more\ninformation on the tokio msrv policy you can check it out [here][tokio msrv]\n\n[tokio msrv]: https://github.com/tokio-rs/tokio/#supported-rust-versions\n\n## Generated Code\n\n`prost` generates Rust code from source `.proto` files using the `proto2` or\n`proto3` syntax. `prost`'s goal is to make the generated code as simple as\npossible.\n\n### `protoc`\n\nWith `prost-build` v0.11 release, `protoc` will be required to invoke\n`compile_protos` (unless `skip_protoc` is enabled). Prost will no longer provide\nbundled a `protoc` or attempt to compile `protoc` for users. For install\ninstructions for `protoc` please check out the [protobuf install] instructions.\n\n[protobuf install]: https://github.com/protocolbuffers/protobuf#protocol-compiler-installation\n\n\n### Packages\n\nProst can now generate code for `.proto` files that don't have a package spec.\n`prost` will translate the Protobuf package into\na Rust module. For example, given the `package` specifier:\n\n[package]: https://developers.google.com/protocol-buffers/docs/proto#packages\n\n```protobuf,ignore\npackage foo.bar;\n```\n\nAll Rust types generated from the file will be in the `foo::bar` module.\n\n### Messages\n\nGiven a simple message declaration:\n\n```protobuf,ignore\n// Sample message.\nmessage Foo {\n}\n```\n\n`prost` will generate the following Rust struct:\n\n```rust,ignore\n/// Sample message.\n#[derive(Clone, Debug, PartialEq, Message)]\npub struct Foo {\n}\n```\n\n### Fields\n\nFields in Protobuf messages are translated into Rust as public struct fields of the\ncorresponding type.\n\n#### Scalar Values\n\nScalar value types are converted as follows:\n\n| Protobuf Type | Rust Type |\n| --- | --- |\n| `double` | `f64` |\n| `float` | `f32` |\n| `int32` | `i32` |\n| `int64` | `i64` |\n| `uint32` | `u32` |\n| `uint64` | `u64` |\n| `sint32` | `i32` |\n| `sint64` | `i64` |\n| `fixed32` | `u32` |\n| `fixed64` | `u64` |\n| `sfixed32` | `i32` |\n| `sfixed64` | `i64` |\n| `bool` | `bool` |\n| `string` | `String` |\n| `bytes` | `Vec<u8>` |\n\n#### Enumerations\n\nAll `.proto` enumeration types convert to the Rust `i32` type. Additionally,\neach enumeration type gets a corresponding Rust `enum` type. For example, this\n`proto` enum:\n\n```protobuf,ignore\nenum PhoneType {\n  MOBILE = 0;\n  HOME = 1;\n  WORK = 2;\n}\n```\n\ngets this corresponding Rust enum [^1]:\n\n```rust,ignore\npub enum PhoneType {\n    Mobile = 0,\n    Home = 1,\n    Work = 2,\n}\n```\n\n[^1]: Annotations have been elided for clarity. See below for a full example.\n\nYou can convert a `PhoneType` value to an `i32` by doing:\n\n```rust,ignore\nPhoneType::Mobile as i32\n```\n\nThe `#[derive(::prost::Enumeration)]` annotation added to the generated\n`PhoneType` adds these associated functions to the type:\n\n```rust,ignore\nimpl PhoneType {\n    pub fn is_valid(value: i32) -> bool { ... }\n    pub fn from_i32(value: i32) -> Option<PhoneType> { ... }\n}\n```\n\nso you can convert an `i32` to its corresponding `PhoneType` value by doing,\nfor example:\n\n```rust,ignore\nlet phone_type = 2i32;\n\nmatch PhoneType::from_i32(phone_type) {\n    Some(PhoneType::Mobile) => ...,\n    Some(PhoneType::Home) => ...,\n    Some(PhoneType::Work) => ...,\n    None => ...,\n}\n```\n\nAdditionally, wherever a `proto` enum is used as a field in a `Message`, the\nmessage will have 'accessor' methods to get/set the value of the field as the\nRust enum type. For instance, this proto `PhoneNumber` message that has a field\nnamed `type` of type `PhoneType`:\n\n```protobuf,ignore\nmessage PhoneNumber {\n  string number = 1;\n  PhoneType type = 2;\n}\n```\n\nwill become the following Rust type [^2] with methods `type` and `set_type`:\n\n```rust,ignore\npub struct PhoneNumber {\n    pub number: String,\n    pub r#type: i32, // the `r#` is needed because `type` is a Rust keyword\n}\n\nimpl PhoneNumber {\n    pub fn r#type(&self) -> PhoneType { ... }\n    pub fn set_type(&mut self, value: PhoneType) { ... }\n}\n```\n\nNote that the getter methods will return the Rust enum's default value if the\nfield has an invalid `i32` value.\n\nThe `enum` type isn't used directly as a field, because the Protobuf spec\nmandates that enumerations values are 'open', and decoding unrecognized\nenumeration values must be possible.\n\n[^2]: Annotations have been elided for clarity. See below for a full example.\n\n#### Field Modifiers\n\nProtobuf scalar value and enumeration message fields can have a modifier\ndepending on the Protobuf version. Modifiers change the corresponding type of\nthe Rust field:\n\n| `.proto` Version | Modifier | Rust Type |\n| --- | --- | --- |\n| `proto2` | `optional` | `Option<T>` |\n| `proto2` | `required` | `T` |\n| `proto3` | default | `T` for scalar types, `Option<T>` otherwise |\n| `proto3` | `optional` | `Option<T>` |\n| `proto2`/`proto3` | `repeated` | `Vec<T>` |\n\nNote that in `proto3` the default representation for all user-defined message\ntypes is `Option<T>`, and for scalar types just `T` (during decoding, a missing\nvalue is populated by `T::default()`). If you need a witness of the presence of\na scalar type `T`, use the `optional` modifier to enforce an `Option<T>`\nrepresentation in the generated Rust struct.\n\n#### Map Fields\n\nMap fields are converted to a Rust `HashMap` with key and value type converted\nfrom the Protobuf key and value types.\n\n#### Message Fields\n\nMessage fields are converted to the corresponding struct type. The table of\nfield modifiers above applies to message fields, except that `proto3` message\nfields without a modifier (the default) will be wrapped in an `Option`.\nTypically message fields are unboxed. `prost` will automatically box a message\nfield if the field type and the parent type are recursively nested in order to\navoid an infinite sized struct.\n\n#### Oneof Fields\n\nOneof fields convert to a Rust enum. Protobuf `oneof`s types are not named, so\n`prost` uses the name of the `oneof` field for the resulting Rust enum, and\ndefines the enum in a module under the struct. For example, a `proto3` message\nsuch as:\n\n```protobuf,ignore\nmessage Foo {\n  oneof widget {\n    int32 quux = 1;\n    string bar = 2;\n  }\n}\n```\n\ngenerates the following Rust[^3]:\n\n```rust,ignore\npub struct Foo {\n    pub widget: Option<foo::Widget>,\n}\npub mod foo {\n    pub enum Widget {\n        Quux(i32),\n        Bar(String),\n    }\n}\n```\n\n`oneof` fields are always wrapped in an `Option`.\n\n[^3]: Annotations have been elided for clarity. See below for a full example.\n\n### Services\n\n`prost-build` allows a custom code-generator to be used for processing `service`\ndefinitions. This can be used to output Rust traits according to an\napplication's specific needs.\n\n### Generated Code Example\n\nExample `.proto` file:\n\n```protobuf,ignore\nsyntax = \"proto3\";\npackage tutorial;\n\nmessage Person {\n  string name = 1;\n  int32 id = 2;  // Unique ID number for this person.\n  string email = 3;\n\n  enum PhoneType {\n    MOBILE = 0;\n    HOME = 1;\n    WORK = 2;\n  }\n\n  message PhoneNumber {\n    string number = 1;\n    PhoneType type = 2;\n  }\n\n  repeated PhoneNumber phones = 4;\n}\n\n// Our address book file is just one of these.\nmessage AddressBook {\n  repeated Person people = 1;\n}\n```\n\nand the generated Rust code (`tutorial.rs`):\n\n```rust,ignore\n#[derive(Clone, PartialEq, ::prost::Message)]\npub struct Person {\n    #[prost(string, tag=\"1\")]\n    pub name: ::prost::alloc::string::String,\n    /// Unique ID number for this person.\n    #[prost(int32, tag=\"2\")]\n    pub id: i32,\n    #[prost(string, tag=\"3\")]\n    pub email: ::prost::alloc::string::String,\n    #[prost(message, repeated, tag=\"4\")]\n    pub phones: ::prost::alloc::vec::Vec<person::PhoneNumber>,\n}\n/// Nested message and enum types in `Person`.\npub mod person {\n    #[derive(Clone, PartialEq, ::prost::Message)]\n    pub struct PhoneNumber {\n        #[prost(string, tag=\"1\")]\n        pub number: ::prost::alloc::string::String,\n        #[prost(enumeration=\"PhoneType\", tag=\"2\")]\n        pub r#type: i32,\n    }\n    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]\n    #[repr(i32)]\n    pub enum PhoneType {\n        Mobile = 0,\n        Home = 1,\n        Work = 2,\n    }\n}\n/// Our address book file is just one of these.\n#[derive(Clone, PartialEq, ::prost::Message)]\npub struct AddressBook {\n    #[prost(message, repeated, tag=\"1\")]\n    pub people: ::prost::alloc::vec::Vec<Person>,\n}\n```\n\n## Accessing the `protoc` `FileDescriptorSet`\n\nThe `prost_build::Config::file_descriptor_set_path` option can be used to emit a file descriptor set\nduring the build & code generation step. When used in conjunction with the `std::include_bytes`\nmacro and the `prost_types::FileDescriptorSet` type, applications and libraries using Prost can\nimplement introspection capabilities requiring details from the original `.proto` files.\n\n## Using `prost` in a `no_std` Crate\n\n`prost` is compatible with `no_std` crates. To enable `no_std` support, disable\nthe `std` features in `prost` and `prost-types`:\n\n```ignore\n[dependencies]\nprost = { version = \"0.6\", default-features = false, features = [\"prost-derive\"] }\n# Only necessary if using Protobuf well-known types:\nprost-types = { version = \"0.6\", default-features = false }\n```\n\nAdditionally, configure `prost-build` to output `BTreeMap`s instead of `HashMap`s\nfor all Protobuf `map` fields in your `build.rs`:\n\n```rust,ignore\nlet mut config = prost_build::Config::new();\nconfig.btree_map(&[\".\"]);\n```\n\nWhen using edition 2015, it may be necessary to add an `extern crate core;`\ndirective to the crate which includes `prost`-generated code.\n\n## Serializing Existing Types\n\n`prost` uses a custom derive macro to handle encoding and decoding types, which\nmeans that if your existing Rust type is compatible with Protobuf types, you can\nserialize and deserialize it by adding the appropriate derive and field\nannotations.\n\nCurrently the best documentation on adding annotations is to look at the\ngenerated code examples above.\n\n### Tag Inference for Existing Types\n\nProst automatically infers tags for the struct.\n\nFields are tagged sequentially in the order they\nare specified, starting with `1`.\n\nYou may skip tags which have been reserved, or where there are gaps between\nsequentially occurring tag values by specifying the tag number to skip to with\nthe `tag` attribute on the first field after the gap. The following fields will\nbe tagged sequentially starting from the next number.\n\n```rust,ignore\nuse prost;\nuse prost::{Enumeration, Message};\n\n#[derive(Clone, PartialEq, Message)]\nstruct Person {\n    #[prost(string, tag = \"1\")]\n    pub id: String, // tag=1\n    // NOTE: Old \"name\" field has been removed\n    // pub name: String, // tag=2 (Removed)\n    #[prost(string, tag = \"6\")]\n    pub given_name: String, // tag=6\n    #[prost(string)]\n    pub family_name: String, // tag=7\n    #[prost(string)]\n    pub formatted_name: String, // tag=8\n    #[prost(uint32, tag = \"3\")]\n    pub age: u32, // tag=3\n    #[prost(uint32)]\n    pub height: u32, // tag=4\n    #[prost(enumeration = \"Gender\")]\n    pub gender: i32, // tag=5\n    // NOTE: Skip to less commonly occurring fields\n    #[prost(string, tag = \"16\")]\n    pub name_prefix: String, // tag=16  (eg. mr/mrs/ms)\n    #[prost(string)]\n    pub name_suffix: String, // tag=17  (eg. jr/esq)\n    #[prost(string)]\n    pub maiden_name: String, // tag=18\n}\n\n#[derive(Clone, Copy, Debug, PartialEq, Eq, Enumeration)]\npub enum Gender {\n    Unknown = 0,\n    Female = 1,\n    Male = 2,\n}\n```\n\n## Nix\n\nThe prost project maintains flakes support for local development. Once you have\nnix and nix flakes setup you can just run `nix develop` to get a shell\nconfigured with the required dependencies to compile the whole project.\n\n\n## FAQ\n\n1. **Could `prost` be implemented as a serializer for [Serde](https://serde.rs/)?**\n\n  Probably not, however I would like to hear from a Serde expert on the matter.\n  There are two complications with trying to serialize Protobuf messages with\n  Serde:\n\n  - Protobuf fields require a numbered tag, and currently there appears to be no\n    mechanism suitable for this in `serde`.\n  - The mapping of Protobuf type to Rust type is not 1-to-1. As a result,\n    trait-based approaches to dispatching don't work very well. Example: six\n    different Protobuf field types correspond to a Rust `Vec<i32>`: `repeated\n    int32`, `repeated sint32`, `repeated sfixed32`, and their packed\n    counterparts.\n\n  But it is possible to place `serde` derive tags onto the generated types, so\n  the same structure can support both `prost` and `Serde`.\n\n2. **I get errors when trying to run `cargo test` on MacOS**\n\n  If the errors are about missing `autoreconf` or similar, you can probably fix\n  them by running\n\n  ```ignore\n  brew install automake\n  brew install libtool\n  ```\n\n## License\n\n`prost` is distributed under the terms of the Apache License (Version 2.0).\n\nSee [LICENSE](https://github.com/tokio-rs/prost/blob/master/LICENSE) for details.\n\nCopyright 2022 Dan Burkert & Tokio Contributors\n"}, {"id": 43, "name": "\u94fe\u63a51: tokio-rs/io-uring", "link": "https://github.com/tokio-rs/io-uring", "parent": 42, "note": "[\u6765\u81ea  tokio-rs/io-uring\n\u7684\u94fe\u63a5](https://github.com/tokio-rs/io-uring)"}, {"id": 42, "name": "  tokio-rs/io-uring\n", "parent": 16, "note": "The `io_uring` library for Rust"}, {"id": 44, "name": " README\n", "parent": 42, "note": "# Linux IO Uring\n[![github actions](https://github.com/tokio-rs/io-uring/workflows/ci/badge.svg)](https://github.com/tokio-rs/io-uring/actions)\n[![crates](https://img.shields.io/crates/v/io-uring.svg)](https://crates.io/crates/io-uring)\n[![license](https://img.shields.io/badge/License-MIT-blue.svg)](https://github.com/tokio-rs/io-uring/blob/master/LICENSE-MIT)\n[![license](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://github.com/tokio-rs/io-uring/blob/master/LICENSE-APACHE)\n[![docs.rs](https://docs.rs/io-uring/badge.svg)](https://docs.rs/io-uring/)\n\nThe low-level [`io_uring`](https://kernel.dk/io_uring.pdf) userspace interface for Rust.\n\n## Usage\n\nTo use `io-uring` crate, first add this to your `Cargo.toml`:\n\n```toml\n[dependencies]\nio-uring = \"0.6\"\n```\n\nNext we can start using `io-uring` crate.\nThe following is quick introduction using `Read` for file.\n\n```rust\nuse io_uring::{opcode, types, IoUring};\nuse std::os::unix::io::AsRawFd;\nuse std::{fs, io};\n\nfn main() -> io::Result<()> {\n    let mut ring = IoUring::new(8)?;\n\n    let fd = fs::File::open(\"README.md\")?;\n    let mut buf = vec![0; 1024];\n\n    let read_e = opcode::Read::new(types::Fd(fd.as_raw_fd()), buf.as_mut_ptr(), buf.len() as _)\n        .build()\n        .user_data(0x42);\n\n    // Note that the developer needs to ensure\n    // that the entry pushed into submission queue is valid (e.g. fd, buffer).\n    unsafe {\n        ring.submission()\n            .push(&read_e)\n            .expect(\"submission queue is full\");\n    }\n\n    ring.submit_and_wait(1)?;\n\n    let cqe = ring.completion().next().expect(\"completion queue is empty\");\n\n    assert_eq!(cqe.user_data(), 0x42);\n    assert!(cqe.result() >= 0, \"read error: {}\", cqe.result());\n\n    Ok(())\n}\n```\n\nNote that opcode `Read` is only available after kernel 5.6.\nIf you use a kernel lower than 5.6, this example will fail.\n\n## Test and Benchmarks\n\nYou can run the test and benchmark of the library with the following commands.\n\n```\n$ cargo run --package io-uring-test\n$ cargo bench --package io-uring-bench\n```\n\n\n### License\n\nThis project is licensed under either of\n\n * Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or\n   http://www.apache.org/licenses/LICENSE-2.0)\n * MIT license ([LICENSE-MIT](LICENSE-MIT) or\n   http://opensource.org/licenses/MIT)\n\nat your option.\n\n\n### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in io-uring by you, as defined in the Apache-2.0 license, shall be\ndual licensed as above, without any additional terms or conditions.\n"}, {"id": 46, "name": "\u94fe\u63a51: tokio-rs/turmoil", "link": "https://github.com/tokio-rs/turmoil", "parent": 45, "note": "[\u6765\u81ea tokio-rs/turmoil\n\u7684\u94fe\u63a5](https://github.com/tokio-rs/turmoil)"}, {"id": 45, "name": " tokio-rs/turmoil\n", "parent": 16, "note": "## This is very experimental\n\nAdd hardship to your tests.\n\nTurmoil is a framework for testing distributed systems.\nIt provides deterministic execution by running multiple concurrent hosts within a single thread.\nIt introduces \"hardship\" into the system via changes in the simulated network.\nThe network can be controlled manually or with a seeded rng."}, {"id": 48, "name": "\u94fe\u63a51: tokio-rs/mio", "link": "https://github.com/tokio-rs/mio", "parent": 47, "note": "[\u6765\u81ea tokio-rs/mio\n\u7684\u94fe\u63a5](https://github.com/tokio-rs/mio)"}, {"id": 47, "name": " tokio-rs/mio\n", "parent": 16, "note": "Metal I/O library for Rust.\n> Mio is a fast, low-level I/O library for Rust focusing on non-blocking APIs and\n> event notification for building high performance I/O apps with as little overhead\n> as possible over the OS abstractions."}, {"id": 50, "name": "\u94fe\u63a51: tokio-rs/tokio-metrics", "link": "https://github.com/tokio-rs/tokio-metrics", "parent": 49, "note": "[\u6765\u81ea tokio-rs/tokio-metrics\n\u7684\u94fe\u63a5](https://github.com/tokio-rs/tokio-metrics)"}, {"id": 49, "name": " tokio-rs/tokio-metrics\n", "parent": 16, "note": "Utilities for collecting metrics from a Tokio application\nProvides utilities for collecting metrics from a Tokio application, including runtime and per-task metrics."}, {"id": 51, "name": " \u5904\u7406\u5f15\u64ce\uff08\u6765\u6e90\u4e8e\u5927\u6570\u636e\uff09\n", "parent": 10}, {"id": 52, "name": " \u6279\u5904\u7406\n", "parent": 51}, {"id": 53, "name": " \u6d41\u5904\u7406\n", "parent": 51}, {"id": 54, "name": " Flink(JAVA)\n", "parent": 53}, {"id": 56, "name": "\u94fe\u63a51: ArroyoSystems/arroyo", "link": "https://github.com/ArroyoSystems/arroyo", "parent": 55, "note": "[\u6765\u81ea ArroyoSystems/arroyo\n\u7684\u94fe\u63a5](https://github.com/ArroyoSystems/arroyo)"}, {"id": 55, "name": " ArroyoSystems/arroyo\n", "parent": 53, "note": "Distributed stream processing engine in Rust"}, {"id": 57, "name": " \u4ecb\u7ecd\n", "parent": 55, "note": "> [Rust\u6d41\u5904\u7406\u65b0\u79c0\uff0c\u5373\u5c06\u6297\u8861Flink\u9738\u4e3b\u5730\u4f4d - \u77e5\u4e4e](https://zhuanlan.zhihu.com/p/620335346)\n\n\n\n<img src=\"../../../../../../Migrations/writing_materials/v2-aa2920a8617696cf806d5009c7ad8e7b_1440w.jpg\" style=\"zoom:25%;\" />\n\n`Arroyo`\u662f\u4e00\u4e2a\u4f7f\u7528Rust\u7f16\u5199\u7684\u5206\u5e03\u5f0f\u6d41\u5904\u7406\u5f15\u64ce\uff0c\u65e8\u5728\u9ad8\u6548\u5730\u5bf9\u6570\u636e\u6d41\u8fdb\u884c\u6709\u72b6\u6001\u7684\u8ba1\u7b97\u3002 \u4e0e\u4f20\u7edf\u7684\u6279\u5904\u7406\u4e0d\u540c\uff0c\u6d41\u5904\u7406\u5f15\u64ce\u53ef\u4ee5\u540c\u65f6\u5904\u7406\u6709\u754c\u548c\u65e0\u754c\u7684\u6570\u636e\u6e90\uff0c\u5e76\u5728\u7ed3\u679c\u53ef\u7528\u65f6\u7acb\u5373\u53d1\u51fa\u3002\n\n**\u7b80\u800c\u8a00\u4e4b**\uff1a`Arroyo`\u53ef\u8ba9\u4f60\u5bf9\u5927\u91cf\u5b9e\u65f6\u6570\u636e\u63d0\u51fa\u590d\u6742\u95ee\u9898\uff0c\u5e76\u5728\u4e9a\u79d2\u7ea7\u65f6\u95f4\u5185\u83b7\u5f97\u7ed3\u679c\u3002\n\n> \u8bf4\u5230\u8fd9\u91cc\uff0c\u611f\u89c9\u5c31\u662fFlink\u5728Rust\u4e2d\u7684\u5b8c\u7f8e\u66ff\u4ee3\u54c1\u3002\u5982\u679c\u771f\u7684\u53ef\u4ee5\u7a33\u5b9a\u4f7f\u7528\uff0c\u90a3\u4e48\u5c06\u662fRust\u64bc\u52a8Java\u5728\u5927\u6570\u636e\u6d41\u5f0f\u5904\u7406\u8ba1\u7b97\u7684\u7b2c\u4e00\u67aa\u3002\n\n### **\u5b98\u65b9\u6807\u699c\u4e3b\u8981\u7279\u6027\u6709:**\n\n- \u652f\u6301SQL\u548cRust\u6d41\u6c34\u7ebf\n- \u53ef\u6269\u5c55\u5230\u6bcf\u79d2\u6570\u767e\u4e07\u4e8b\u4ef6\n- \u652f\u6301\u72b6\u6001\u64cd\u4f5c\uff0c\u5982\u7a97\u53e3\u548c\u8fde\u63a5\n- \u652f\u6301\u72b6\u6001\u68c0\u67e5\u70b9\u529f\u80fd\uff0c\u4ee5\u5b9e\u73b0\u6d41\u6c34\u7ebf\u7684\u5bb9\u9519\u548c\u6062\u590d\n- \u901a\u8fc7Dataflow\u6a21\u578b\u8fdb\u884c\u53ca\u65f6\u7684\u6d41\u5904\u7406\n\n### **\u7528\u4f8b**\n\n- \u68c0\u6d4b\u6b3a\u8bc8\u548c\u5b89\u5168\u4e8b\u4ef6\n- \u5b9e\u65f6\u4ea7\u54c1\u548c\u4e1a\u52a1\u5206\u6790\n- \u5b9e\u65f6\u6570\u636e\u6444\u53d6\u5230\u60a8\u7684\u6570\u636e\u4ed3\u5e93\u6216\u6570\u636e\u6e56\u4e2d\n- \u5b9e\u65f6\u673a\u5668\u5b66\u4e60\u7279\u5f81\u751f\u6210\n\n### **\u4e3a\u4ec0\u4e48\u9009\u62e9Arroyo**\n\n\u73b0\u5728\u5df2\u7ecf\u6709\u4e00\u4e9b\u73b0\u6709\u7684\u6d41\u5f15\u64ce\uff0c\u5305\u62ec`Apache Flink`, `Spark streaming`\u548c`Kafka Streams`\u3002\u4e3a\u4ec0\u4e48\u8981\u641e\u4e00\u4e2a\u65b0\u7684\u5462\uff1f\n\n\u5b98\u65b9\u4e5f\u7ed9\u51fa\u4e86\u5177\u4f53\u7684\u8bf4\u660e\uff1a\uff08\u53ef\u4ee5\u8bf4\u975e\u5e38\u70b8\u88c2\uff09\n\n- \u65e0\u670d\u52a1\u5668\u8fd0\u7ef4\uff1a`Arroyo`\u7ba1\u9053\u88ab\u8bbe\u8ba1\u4e3a\u5728\u73b0\u4ee3\u4e91\u73af\u5883\u4e2d\u8fd0\u884c\uff0c\u652f\u6301\u65e0\u7f1d\u6269\u5c55\u3001\u6062\u590d\u548c\u91cd\u65b0\u8c03\u5ea6\u3002\n- \u9ad8\u6027\u80fdSQL\uff1aSQL\u662f\u4e00\u6d41\u7684\u5173\u6ce8\u70b9\uff0c\u5177\u6709\u59cb\u7ec8\u4f18\u79c0\u7684\u6027\u80fd\u3002\n- \u4e13\u4e3a\u975e\u4e13\u5bb6\u8bbe\u8ba1\uff1a`Arroyo`\u4ece\u5176\u5185\u90e8\u5b9e\u73b0\u4e2d\u6e05\u6670\u5730\u5206\u79bb\u4e86\u7ba1\u9053API\u3002\u4f7f\u7528\u8005\u4e0d\u9700\u8981\u6210\u4e3a\u6d41\u5904\u7406\u4e13\u5bb6\u5373\u53ef\u6784\u5efa\u5b9e\u65f6\u6570\u636epipeline\u3002\n\n### **\u5982\u4f55\u5f00\u59cb**\n\n\u53ef\u4ee5\u901a\u8fc7\u8fd0\u884c\u4ee5\u4e0b`Docker`\u547d\u4ee4\u6765\u4f7f\u7528\u53ea\u6709\u5355\u4e2a\u8282\u70b9\u7684`Arroyo`\u7fa4\u96c6\uff1a\n\n```shell\n$ docker run -p 8000:8000 -p 8001:8001 ghcr.io/arroyosystems/arroyo-single:multi-arch\n```\n\n\u7136\u540e\u53ef\u4ee5\u5728\u6d4f\u89c8\u5668\u6253\u5f00\uff1a [http://localhost:8000](https://link.zhihu.com/?target=http%3A//localhost%3A8000/)\n\n### **\u6df1\u5165\u5b66\u4e60**\n\n[\u5b98\u65b9\u6587\u6863](https://link.zhihu.com/?target=https%3A//doc.arroyo.dev/getting-started)\uff1a\u770b\u4e86\u4e0b\uff0c\u6587\u6863\u5199\u7684\u975e\u5e38\u597d\n\n### **\u4f7f\u7528\u590d\u6742SQL\u6784\u5efa\u4f60\u7684\u7b2c\u4e00\u4e2apipeline**\n\n[https://doc.arroyo.dev/tutorial/first-pipeline](https://link.zhihu.com/?target=https%3A//doc.arroyo.dev/tutorial/first-pipeline)\n\n### **\u603b\u7ed3**\n\n\u4e4b\u524d\u4e5f\u6709Rust\u5c1d\u8bd5\u505a\u5927\u6570\u636e\u5957\u4ef6\uff0c\u4f46\u662f\u90fd\u6ca1\u6709\u5f88\u6210\u529f\u7684\u6848\u4f8b\u3002 \u6216\u8bb8`Arroyo`\u5c06\u662f\u7b2c\u4e00\u4e2a\u7528`Rust`\u7f16\u5199\u7684\u5206\u5e03\u5f0f\u6d41\u5904\u7406\u5f15\u64ce\u6210\u529f\u7684\u6848\u4f8b\uff0c\u8fd9\u6837\u5c06\u518d\u6b21\u8bc1\u660eRust\u5728\u5927\u6570\u636e\u57fa\u5efa\u9886\u57df\u7684\u53ef\u884c\u6027\u3002\n\n\u540e\u9762\u6211\u4e5f\u4f1a\u7ee7\u7eed\u5173\u6ce8`Arroyo`\uff0c\u5e76\u5199\u4e00\u7cfb\u5217\u7684\u4f7f\u7528\u6559\u7a0b\u53d1\u5e03\u5230\u672c\u516c\u4f17\u53f7\uff0c\u5e76\u505a\u4e00\u4e9b`Flink`\u548c`Arroyo`\u7684\u6df1\u5165\u5bf9\u6bd4\u3002"}, {"id": 58, "name": " \u53c2\u8003\u9879\u76ee\n", "parent": 10}, {"id": 60, "name": "\u94fe\u63a51: bagua: \u5df2\u9e3d", "link": "https://github.com/BaguaSys/bagua", "parent": 59, "note": "[\u6765\u81ea bagua: \u5df2\u9e3d\n\u7684\u94fe\u63a5](https://github.com/BaguaSys/bagua)"}, {"id": 59, "name": " bagua: \u5df2\u9e3d\n", "parent": 58, "note": "<p align=\"center\">\n<img width=\"500px\" src=\"https://user-images.githubusercontent.com/18649508/141055752-2f429618-2707-4feb-abe3-74767c2b1976.gif\"/>\n</p>\n<hr/>\n\n<div align=\"center\">\n<a href=\"https://tutorials.baguasys.com/\"><img src=\"https://img.shields.io/badge/tutorials-passing-green\" alt=\"tutorials\"></a> <a href=\"http://bagua.readthedocs.io/?badge=latest\"><img src=\"https://readthedocs.org/projects/bagua/badge/?version=latest\" alt=\"Documentation Status\"></a> <a href=\"https://pypi.org/project/bagua/\"><img src=\"https://pepy.tech/badge/bagua/month\" alt=\"Downloads\"></a> <a href=\"https://hub.docker.com/r/baguasys/bagua\"><img src=\"https://img.shields.io/docker/pulls/baguasys/bagua\" alt=\"Docker Pulls\"></a> <a href=\"https://hub.docker.com/r/baguasys/bagua\"><img src=\"https://img.shields.io/docker/cloud/build/baguasys/bagua\" alt=\"Docker Cloud Build Status\"></a> <a href=\"https://github.com/BaguaSys/bagua/blob/master/LICENSE\"><img src=\"https://img.shields.io/github/license/BaguaSys/bagua\" alt=\"GitHub license\"></a>\n</div>\n\n<br/>\n\n*WARNING: THIS PROJECT IS CURRENTLY IN MAINTENANCE MODE, DUE TO COMPANY REORGANIZATION.*\n\nBagua is a deep learning training acceleration framework for PyTorch developed by [AI platform@Kuaishou Technology](https://www.kuaishou.com/en) and [DS3 Lab@ETH Z\u00fcrich](https://ds3lab.inf.ethz.ch/). Bagua currently supports:\n\n- **Advanced Distributed Training Algorithms**: Users can extend the training on a single GPU to multi-GPUs (may across multiple machines) by simply adding a few lines of code (optionally in [elastic mode](https://tutorials.baguasys.com/elastic-training/)). One prominent feature of Bagua is to provide a flexible system abstraction that supports state-of-the-art system relaxation techniques of distributed training. So far, Bagua has integrated communication primitives including\n  - Centralized Synchronous Communication (e.g. [Gradient AllReduce](https://tutorials.baguasys.com/algorithms/gradient-allreduce))\n  - Decentralized Synchronous Communication (e.g. [Decentralized SGD](https://tutorials.baguasys.com/algorithms/decentralized))\n  - Low Precision Communication (e.g. [ByteGrad](https://tutorials.baguasys.com/algorithms/bytegrad))\n  - Asynchronous Communication (e.g. [Async Model Average](https://tutorials.baguasys.com/algorithms/async-model-average))\n- [**Cached Dataset**](https://tutorials.baguasys.com/more-optimizations/cached-dataset): When data loading is slow or data preprocessing is tedious, they could become a major bottleneck of the whole training process. Bagua provides cached dataset to speedup this process by caching data samples in memory, so that reading these samples after the first time becomes much faster.\n- [**TCP Communication Acceleration (Bagua-Net)**](https://tutorials.baguasys.com/more-optimizations/bagua-net): Bagua-Net is a low level communication acceleration feature provided by Bagua. It can greatly improve the throughput of AllReduce on TCP network. You can enable Bagua-Net optimization on any distributed training job that uses NCCL to do GPU communication (this includes PyTorch-DDP, Horovod, DeepSpeed, and more).\n- [**Performance Autotuning**](https://tutorials.baguasys.com/performance-autotuning/): Bagua can automatically tune system parameters to achieve the highest throughput.\n- [**Generic Fused Optimizer**](https://tutorials.baguasys.com/more-optimizations/generic-fused-optimizer): Bagua provides generic fused optimizer which improve the performance of optimizers by fusing the optimizer `.step()` operation on multiple layers. It can be applied to arbitrary PyTorch optimizer, in contrast to [NVIDIA Apex](https://nvidia.github.io/apex/optimizers.html)'s approach, where only some specific optimizers are implemented.\n- [**Load Balanced Data Loader**](https://bagua.readthedocs.io/en/latest/autoapi/bagua/torch_api/contrib/load_balancing_data_loader/index.html): When the computation complexity of samples in training data are different, for example in NLP and speech tasks, where each sample have different lengths, distributed training throughput can be greatly improved by using Bagua's load balanced data loader, which distributes samples in a way that each worker's workload are similar.\n- [**Integration with PyTorch Lightning**](https://pytorch-lightning.readthedocs.io/en/latest/accelerators/gpu.html#bagua): Are you using [PyTorch Lightning](https://www.pytorchlightning.ai/) for your distributed training job? Now you can use Bagua in PyTorch Lightning by simply set `strategy=BaguaStrategy` in your Trainer. This enables you to take advantage of a range of advanced training algorithms, including decentralized methods, asynchronous methods, communication compression, and their combinations!\n  \nIts effectiveness has been evaluated in various scenarios, including VGG and ResNet on ImageNet, BERT Large and many industrial applications at Kuaishou.\n\n## Links\n\n* [Bagua Main Git Repo](https://github.com/BaguaSys/bagua)\n* [Bagua Tutorials](https://tutorials.baguasys.com/)\n* [Bagua Examples](https://github.com/BaguaSys/bagua/tree/master/examples)\n* [Bagua API Documentation](https://bagua.readthedocs.io/)\n\n## Performance\n\n<p align=\"center\">\n    <img src=\"https://tutorials.baguasys.com/benchmark/figures/e2e_vgg16_128.png\" width=\"600\"/>\n</p>\n<p align=\"center\">\n    The performance of different systems and algorithms on VGG16 with 128 GPUs under different network bandwidth.\n</p>\n\n<br/>\n<br/>\n\n<p align=\"center\">\n    <img src=\"https://tutorials.baguasys.com/benchmark/figures/tradeoff_network_bert-large-bandwidth.png\" width=\"250\"/><img src=\"https://tutorials.baguasys.com/benchmark/figures/tradeoff_network_bert-large-latency.png\" width=\"250\"/><img src=\"https://tutorials.baguasys.com/benchmark/figures/tradeoff_network_legend.png\" width=\"260\"/>\n</p>\n<p align=\"center\">\n    Epoch time of BERT-Large Finetune under different network conditions for different systems.\n</p>\n\nFor more comprehensive and up to date results, refer to [Bagua benchmark page](https://tutorials.baguasys.com/benchmark/index.html).\n\n## Installation\n\nWheels (precompiled binary packages) are available for Linux (x86_64). Package names are different depending on your CUDA Toolkit version (CUDA Toolkit version is shown in `nvcc --version`).\n\n| CUDA Toolkit version | Installation command        |\n|----------------------|-----------------------------|\n| >= v10.2             | `pip install bagua-cuda102` |\n| >= v11.1             | `pip install bagua-cuda111` |\n| >= v11.3             | `pip install bagua-cuda113` |\n| >= v11.5\t           | `pip install bagua-cuda115` |\n| >= v11.6\t           | `pip install bagua-cuda116` |\n\nAdd `--pre` to `pip install` commands to install pre-release (development) versions. See [Bagua tutorials](https://tutorials.baguasys.com/getting-started/) for quick start guide and more installation options.\n  \n## Quick Start on AWS\n\nThanks to the [Amazon Machine Images (AMI)](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html), we can provide users an easy way to deploy and run Bagua on AWS EC2 clusters with flexible size of machines and a wide range of GPU types. Users can find our pre-installed Bagua image on EC2 by the unique AMI-ID that we publish here. Note that AMI is a regional resource, so please make sure you are using the machines in same reginon as our AMI.\n\n| Bagua version  | AMI ID |  Region |\n|---|---|---|\n| 0.6.3 | ami-0e719d0e3e42b397e | us-east-1 |\n| 0.9.0 | ami-0f01fd14e9a742624 | us-east-1 |\n  \nTo manage the EC2 cluster more efficiently, we use [Starcluster](http://star.mit.edu/cluster/) as a toolkit to manipulate the cluster. In the `config` file of Starcluster, there are a few configurations that need to be set up by users, including AWS credentials, cluster settings, etc. More information regarding the Starcluster configuration can be found in this [tutorial](http://star.mit.edu/cluster/docs/latest/quickstart.html).\n\nFor example, we create a EC2 cluster with 4 machines, each of which has 8 V100 GPUs (`p3.16xlarge`). The cluster is based on the Bagua AMI we pre-installed in `us-east-1` region. Then the `config` file of Starcluster would be:\n\n```yaml\n# region of EC2 instances, here we choose us_east_1\nAWS_REGION_NAME = us-east-1\nAWS_REGION_HOST = ec2.us-east-1.amazonaws.com\n# AMI ID of Bagua\nNODE_IMAGE_ID = ami-0e719d0e3e42b397e\n# number of instances\nCLUSTER_SIZE = 4\n# instance type\nNODE_INSTANCE_TYPE = p3.16xlarge\n```\n\nWith above setup, we created two identical clusters to benchmark a synthesized image classification task over Bagua and Horovod, respectively. Here is the screen recording video of this experiment. \n\n<p align=\"center\">\n    <a href=\"https://youtu.be/G8o5HVYZJvs\"><img src=\"https://user-images.githubusercontent.com/18649508/136463585-ba911d20-9088-48b7-ab32-fc3e465c31b8.png\" width=\"600\"/></a>\n</p>  \n  \n\n## Cite Bagua\n\n```bibtex\n% System Overview\n@misc{gan2021bagua,\n  title={BAGUA: Scaling up Distributed Learning with System Relaxations}, \n  author={Shaoduo Gan and Xiangru Lian and Rui Wang and Jianbin Chang and Chengjun Liu and Hongmei Shi and Shengzhuo Zhang and Xianghong Li and Tengxu Sun and Jiawei Jiang and Binhang Yuan and Sen Yang and Ji Liu and Ce Zhang},\n  year={2021},\n  eprint={2107.01499},\n  archivePrefix={arXiv},\n  primaryClass={cs.LG}\n}\n\n% Theory on System Relaxation Techniques\n@book{liu2020distributed,\n  title={Distributed Learning Systems with First-Order Methods: An Introduction},\n  author={Liu, J. and Zhang, C.},\n  isbn={9781680837018},\n  series={Foundations and trends in databases},\n  url={https://books.google.com/books?id=vzQmzgEACAAJ},\n  year={2020},\n  publisher={now publishers}\n}\n```\n\n## Contributors\n\n<a href=\"https://github.com/BaguaSys/bagua/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=BaguaSys/bagua\" />\n</a>\n"}, {"id": 62, "name": "\u94fe\u63a51: CollssalAI-python", "link": "https://github.com/hpcaitech/ColossalAI", "parent": 61, "note": "[\u6765\u81ea CollssalAI-python\n\u7684\u94fe\u63a5](https://github.com/hpcaitech/ColossalAI)"}, {"id": 61, "name": " CollssalAI-python\n", "parent": 58, "note": "# Colossal-AI\n<div id=\"top\" align=\"center\">\n Colossal-AI: \u8ba9AI\u5927\u6a21\u578b\u66f4\u4f4e\u6210\u672c\u3001\u65b9\u4fbf\u6613\u7528\u3001\u9ad8\u6548\u6269\u5c55\n\n   <h3> <a href=\"https://arxiv.org/abs/2110.14883\"> \u8bba\u6587 </a> |\n   <a href=\"https://www.colossalai.org/\"> \u6587\u6863 </a> |\n   <a href=\"https://github.com/hpcaitech/ColossalAI/tree/main/examples\"> \u4f8b\u7a0b </a> |\n   <a href=\"https://github.com/hpcaitech/ColossalAI/discussions\"> \u8bba\u575b </a> |\n   <a href=\"https://medium.com/@hpcaitech\"> \u535a\u5ba2 </a></h3>\n\n   [![GitHub Repo stars](https://img.shields.io/github/stars/hpcaitech/ColossalAI?style=social)](https://github.com/hpcaitech/ColossalAI/stargazers)\n   [![Build](https://github.com/hpcaitech/ColossalAI/actions/workflows/build_on_schedule.yml/badge.svg)](https://github.com/hpcaitech/ColossalAI/actions/workflows/build_on_schedule.yml)\n   [![Documentation](https://readthedocs.org/projects/colossalai/badge/?version=latest)](https://colossalai.readthedocs.io/en/latest/?badge=latest)\n   [![CodeFactor](https://www.codefactor.io/repository/github/hpcaitech/colossalai/badge)](https://www.codefactor.io/repository/github/hpcaitech/colossalai)\n   [![HuggingFace badge](https://img.shields.io/badge/%F0%9F%A4%97HuggingFace-Join-yellow)](https://huggingface.co/hpcai-tech)\n   [![slack badge](https://img.shields.io/badge/Slack-join-blueviolet?logo=slack&amp)](https://join.slack.com/t/colossalaiworkspace/shared_invite/zt-z7b26eeb-CBp7jouvu~r0~lcFzX832w)\n   [![WeChat badge](https://img.shields.io/badge/\u5fae\u4fe1-\u52a0\u5165-green?logo=wechat&amp)](https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/WeChat.png)\n\n   | [English](README.md) | [\u4e2d\u6587](README-zh-Hans.md) |\n\n</div>\n\n## \u65b0\u95fb\n* [2023/03] [ColossalChat: An Open-Source Solution for Cloning ChatGPT With a Complete RLHF Pipeline](https://medium.com/@yangyou_berkeley/colossalchat-an-open-source-solution-for-cloning-chatgpt-with-a-complete-rlhf-pipeline-5edf08fb538b)\n* [2023/03] [Intel and Colossal-AI Partner to Deliver Cost-Efficient Open-Source Solution for Protein Folding Structure Prediction](https://www.hpc-ai.tech/blog/intel-habana)\n* [2023/03] [AWS and Google Fund Colossal-AI with Startup Cloud Programs](https://www.hpc-ai.tech/blog/aws-and-google-fund-colossal-ai-with-startup-cloud-programs)\n* [2023/02] [Open Source Solution Replicates ChatGPT Training Process! Ready to go with only 1.6GB GPU Memory](https://www.hpc-ai.tech/blog/colossal-ai-chatgpt)\n* [2023/01] [Hardware Savings Up to 46 Times for AIGC and  Automatic Parallelism](https://medium.com/pytorch/latest-colossal-ai-boasts-novel-automatic-parallelism-and-offers-savings-up-to-46x-for-stable-1453b48f3f02)\n* [2022/11] [Diffusion Pretraining and Hardware Fine-Tuning Can Be Almost 7X Cheaper](https://www.hpc-ai.tech/blog/diffusion-pretraining-and-hardware-fine-tuning-can-be-almost-7x-cheaper)\n* [2022/10] [Use a Laptop to Analyze 90% of Proteins, With a Single-GPU Inference Sequence Exceeding 10,000](https://www.hpc-ai.tech/blog/use-a-laptop-to-analyze-90-of-proteins-with-a-single-gpu-inference-sequence-exceeding)\n* [2022/09] [HPC-AI Tech Completes $6 Million Seed and Angel Round Fundraising](https://www.hpc-ai.tech/blog/hpc-ai-tech-completes-6-million-seed-and-angel-round-fundraising-led-by-bluerun-ventures-in-the)\n\n\n## \u76ee\u5f55\n<ul>\n <li><a href=\"#\u4e3a\u4f55\u9009\u62e9-Colossal-AI\">\u4e3a\u4f55\u9009\u62e9 Colossal-AI</a> </li>\n <li><a href=\"#\u7279\u70b9\">\u7279\u70b9</a> </li>\n <li>\n   <a href=\"#Colossal-AI-in-the-Real-World\">Colossal-AI \u6210\u529f\u6848\u4f8b</a>\n   <ul>\n     <li><a href=\"#ColossalChat\">ColossalChat\uff1a\u5b8c\u6574RLHF\u6d41\u7a0b0\u95e8\u69db\u514b\u9686ChatGPT</a></li>\n     <li><a href=\"#AIGC\">AIGC: \u52a0\u901f Stable Diffusion</a></li>\n     <li><a href=\"#\u751f\u7269\u533b\u836f\">\u751f\u7269\u533b\u836f: \u52a0\u901fAlphaFold\u86cb\u767d\u8d28\u7ed3\u6784\u9884\u6d4b</a></li>\n   </ul>\n </li>\n <li>\n   <a href=\"#\u5e76\u884c\u8bad\u7ec3\u6837\u4f8b\u5c55\u793a\">\u5e76\u884c\u8bad\u7ec3\u6837\u4f8b\u5c55\u793a</a>\n   <ul>\n     <li><a href=\"#GPT-3\">GPT-3</a></li>\n     <li><a href=\"#GPT-2\">GPT-2</a></li>\n     <li><a href=\"#BERT\">BERT</a></li>\n     <li><a href=\"#PaLM\">PaLM</a></li>\n     <li><a href=\"#OPT\">OPT</a></li>\n     <li><a href=\"#ViT\">ViT</a></li>\n     <li><a href=\"#\u63a8\u8350\u7cfb\u7edf\u6a21\u578b\">\u63a8\u8350\u7cfb\u7edf\u6a21\u578b</a></li>\n   </ul>\n </li>\n<li>\n   <a href=\"#\u5355GPU\u8bad\u7ec3\u6837\u4f8b\u5c55\u793a\">\u5355GPU\u8bad\u7ec3\u6837\u4f8b\u5c55\u793a</a>\n   <ul>\n     <li><a href=\"#GPT-2-Single\">GPT-2</a></li>\n     <li><a href=\"#PaLM-Single\">PaLM</a></li>\n   </ul>\n </li>\n<li>\n   <a href=\"#\u63a8\u7406-Energon-AI-\u6837\u4f8b\u5c55\u793a\">\u63a8\u7406 (Energon-AI) \u6837\u4f8b\u5c55\u793a</a>\n   <ul>\n     <li><a href=\"#GPT-3-Inference\">GPT-3</a></li>\n     <li><a href=\"#OPT-Serving\">1750\u4ebf\u53c2\u6570OPT\u5728\u7ebf\u63a8\u7406\u670d\u52a1</a></li>\n     <li><a href=\"#BLOOM-Inference\">1760\u4ebf\u53c2\u6570 BLOOM</a></li>\n   </ul>\n </li>\n <li>\n   <a href=\"#\u5b89\u88c5\">\u5b89\u88c5</a>\n   <ul>\n     <li><a href=\"#PyPI\">PyPI</a></li>\n     <li><a href=\"#\u4ece\u6e90\u4ee3\u7801\u5b89\u88c5\">\u4ece\u6e90\u4ee3\u7801\u5b89\u88c5</a></li>\n   </ul>\n </li>\n <li><a href=\"#\u4f7f\u7528-Docker\">\u4f7f\u7528 Docker</a></li>\n <li><a href=\"#\u793e\u533a\">\u793e\u533a</a></li>\n <li><a href=\"#\u505a\u51fa\u8d21\u732e\">\u505a\u51fa\u8d21\u732e</a></li>\n <li><a href=\"#\u5f15\u7528\u6211\u4eec\">\u5f15\u7528\u6211\u4eec</a></li>\n</ul>\n\n## \u4e3a\u4f55\u9009\u62e9 Colossal-AI\n<div align=\"center\">\n   <a href=\"https://youtu.be/KnXSfjqkKN0\">\n   <img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/JamesDemmel_Colossal-AI.png\" width=\"600\" />\n   </a>\n\n   James Demmel \u6559\u6388 (\u52a0\u5dde\u5927\u5b66\u4f2f\u514b\u5229\u5206\u6821): Colossal-AI \u8ba9\u5206\u5e03\u5f0f\u8bad\u7ec3\u9ad8\u6548\u3001\u6613\u7528\u3001\u53ef\u6269\u5c55\u3002\n</div>\n\n<p align=\"right\">(<a href=\"#top\">\u8fd4\u56de\u9876\u7aef</a>)</p>\n\n## \u7279\u70b9\n\nColossal-AI \u4e3a\u60a8\u63d0\u4f9b\u4e86\u4e00\u7cfb\u5217\u5e76\u884c\u7ec4\u4ef6\u3002\u6211\u4eec\u7684\u76ee\u6807\u662f\u8ba9\u60a8\u7684\u5206\u5e03\u5f0f AI \u6a21\u578b\u50cf\u6784\u5efa\u666e\u901a\u7684\u5355 GPU \u6a21\u578b\u4e00\u6837\u7b80\u5355\u3002\u6211\u4eec\u63d0\u4f9b\u7684\u53cb\u597d\u5de5\u5177\u53ef\u4ee5\u8ba9\u60a8\u5728\u51e0\u884c\u4ee3\u7801\u5185\u5feb\u901f\u5f00\u59cb\u5206\u5e03\u5f0f\u8bad\u7ec3\u548c\u63a8\u7406\u3002\n\n- \u5e76\u884c\u5316\u7b56\u7565\n  - \u6570\u636e\u5e76\u884c\n  - \u6d41\u6c34\u7ebf\u5e76\u884c\n  - 1\u7ef4, [2\u7ef4](https://arxiv.org/abs/2104.05343), [2.5\u7ef4](https://arxiv.org/abs/2105.14500), [3\u7ef4](https://arxiv.org/abs/2105.14450) \u5f20\u91cf\u5e76\u884c\n  - [\u5e8f\u5217\u5e76\u884c](https://arxiv.org/abs/2105.13120)\n  - [\u96f6\u5197\u4f59\u4f18\u5316\u5668 (ZeRO)](https://arxiv.org/abs/1910.02054)\n  - [\u81ea\u52a8\u5e76\u884c](https://arxiv.org/abs/2302.02599)\n- \u5f02\u6784\u5185\u5b58\u7ba1\u7406\n  - [PatrickStar](https://arxiv.org/abs/2108.05818)\n- \u4f7f\u7528\u53cb\u597d\n  - \u57fa\u4e8e\u53c2\u6570\u6587\u4ef6\u7684\u5e76\u884c\u5316\n- \u63a8\u7406\n  - [Energon-AI](https://github.com/hpcaitech/EnergonAI)\n\n<p align=\"right\">(<a href=\"#top\">\u8fd4\u56de\u9876\u7aef</a>)</p>\n\n## Colossal-AI \u6210\u529f\u6848\u4f8b\n### ColossalChat\n\n<div align=\"center\">\n   <a href=\"https://www.youtube.com/watch?v=HcTiHzApHm0\">\n   <img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/applications/chat/ColossalChat%20YouTube.png\" width=\"700\" />\n   </a>\n</div>\n\n[ColossalChat](https://github.com/hpcaitech/ColossalAI/tree/main/applications/Chat): \u5b8c\u6574RLHF\u6d41\u7a0b0\u95e8\u69db\u514b\u9686 [ChatGPT](https://openai.com/blog/chatgpt/)\n[[\u4ee3\u7801]](https://github.com/hpcaitech/ColossalAI/tree/main/applications/Chat)\n[[\u535a\u5ba2]](https://medium.com/@yangyou_berkeley/colossalchat-an-open-source-solution-for-cloning-chatgpt-with-a-complete-rlhf-pipeline-5edf08fb538b)\n[[\u5728\u7ebf\u6837\u4f8b]](https://www.youtube.com/watch?v=HcTiHzApHm0)\n[[\u6559\u7a0b]](https://www.youtube.com/watch?v=-qFBZFmOJfg)\n\n<p id=\"ColossalChat-Speed\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/applications/chat/ColossalChat%20Speed.jpg\" width=450/>\n</p>\n\n- \u6700\u9ad8\u53ef\u63d0\u5347RLHF PPO\u9636\u6bb53\u8bad\u7ec3\u901f\u5ea610\u500d\n\n<p id=\"ColossalChat_scaling\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/applications/chatgpt/ChatGPT%20scaling.png\" width=800/>\n</p>\n\n- \u6700\u9ad8\u53ef\u63d0\u5347\u5355\u673a\u8bad\u7ec3\u901f\u5ea67.73\u500d\uff0c\u5355\u5361\u63a8\u7406\u901f\u5ea61.42\u500d\n\n<p id=\"ColossalChat-1GPU\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/applications/chatgpt/ChatGPT-1GPU.jpg\" width=450/>\n</p>\n\n- \u5355\u5361\u6a21\u578b\u5bb9\u91cf\u6700\u591a\u63d0\u534710.3\u500d\n- \u6700\u5c0fdemo\u8bad\u7ec3\u6d41\u7a0b\u6700\u4f4e\u4ec5\u97001.62GB\u663e\u5b58 (\u4efb\u610f\u6d88\u8d39\u7ea7GPU)\n\n<p id=\"ColossalChat-LoRA\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/applications/chatgpt/LoRA%20data.jpg\" width=600/>\n</p>\n\n- \u63d0\u5347\u5355\u5361\u7684\u5fae\u8c03\u6a21\u578b\u5bb9\u91cf3.7\u500d\n- \u540c\u65f6\u4fdd\u6301\u9ad8\u901f\u8fd0\u884c\n\n<p align=\"right\">(<a href=\"#top\">back to top</a>)</p>\n\n### AIGC\n\u52a0\u901fAIGC(AI\u5185\u5bb9\u751f\u6210)\u6a21\u578b\uff0c\u5982[Stable Diffusion v1](https://github.com/CompVis/stable-diffusion) \u548c [Stable Diffusion v2](https://github.com/Stability-AI/stablediffusion)\n\n<p id=\"diffusion_train\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/Stable%20Diffusion%20v2.png\" width=800/>\n</p>\n\n- [\u8bad\u7ec3](https://github.com/hpcaitech/ColossalAI/tree/main/examples/images/diffusion): \u51cf\u5c115.6\u500d\u663e\u5b58\u6d88\u8017\uff0c\u786c\u4ef6\u6210\u672c\u6700\u9ad8\u964d\u4f4e46\u500d(\u4eceA100\u5230RTX3060)\n\n<p id=\"diffusion_demo\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/DreamBooth.png\" width=800/>\n</p>\n\n- [DreamBooth\u5fae\u8c03](https://github.com/hpcaitech/ColossalAI/tree/main/examples/images/dreambooth): \u4ec5\u97003-5\u5f20\u76ee\u6807\u4e3b\u9898\u56fe\u50cf\u4e2a\u6027\u5316\u5fae\u8c03\n\n<p id=\"inference\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/Stable%20Diffusion%20Inference.jpg\" width=800/>\n</p>\n\n- [\u63a8\u7406](https://github.com/hpcaitech/ColossalAI/tree/main/examples/images/diffusion): GPU\u63a8\u7406\u663e\u5b58\u6d88\u8017\u964d\u4f4e2.5\u500d\n\n\n<p align=\"right\">(<a href=\"#top\">\u8fd4\u56de\u9876\u7aef</a>)</p>\n\n### \u751f\u7269\u533b\u836f\n\n\u52a0\u901f [AlphaFold](https://alphafold.ebi.ac.uk/) \u86cb\u767d\u8d28\u7ed3\u6784\u9884\u6d4b\n\n<p id=\"FastFold\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/FastFold.jpg\" width=800/>\n</p>\n\n- [FastFold](https://github.com/hpcaitech/FastFold): \u52a0\u901fAlphaFold\u8bad\u7ec3\u4e0e\u63a8\u7406\u3001\u6570\u636e\u524d\u5904\u7406\u3001\u63a8\u7406\u5e8f\u5217\u957f\u5ea6\u8d85\u8fc710000\u6b8b\u57fa\n\n<p id=\"FastFold-Intel\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/data%20preprocessing%20with%20Intel.jpg\" width=600/>\n</p>\n\n- [FastFold with Intel](https://github.com/hpcaitech/FastFold): 3\u500d\u63a8\u7406\u52a0\u901f\u548c39%\u6210\u672c\u8282\u7701\n\n<p id=\"xTrimoMultimer\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/xTrimoMultimer_Table.jpg\" width=800/>\n</p>\n\n- [xTrimoMultimer](https://github.com/biomap-research/xTrimoMultimer): 11\u500d\u52a0\u901f\u86cb\u767d\u8d28\u5355\u4f53\u4e0e\u590d\u5408\u7269\u7ed3\u6784\u9884\u6d4b\n\n<p align=\"right\">(<a href=\"#top\">\u8fd4\u56de\u9876\u7aef</a>)</p>\n\n## \u5e76\u884c\u8bad\u7ec3\u6837\u4f8b\u5c55\u793a\n\n### GPT-3\n<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/GPT3-v5.png\" width=700/>\n</p>\n\n- \u91ca\u653e 50% GPU \u8d44\u6e90\u5360\u7528, \u6216 10.7% \u52a0\u901f\n\n### GPT-2\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/GPT2.png\" width=800/>\n\n- \u964d\u4f4e11\u500d GPU \u663e\u5b58\u5360\u7528\uff0c\u6216\u8d85\u7ebf\u6027\u6269\u5c55\uff08\u5f20\u91cf\u5e76\u884c\uff09\n\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/(updated)GPT-2.png\" width=800>\n\n- \u7528\u76f8\u540c\u7684\u786c\u4ef6\u8bad\u7ec324\u500d\u5927\u7684\u6a21\u578b\n- \u8d853\u500d\u7684\u541e\u5410\u91cf\n\n### BERT\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/BERT.png\" width=800/>\n\n- 2\u500d\u8bad\u7ec3\u901f\u5ea6\uff0c\u62161.5\u500d\u5e8f\u5217\u957f\u5ea6\n\n### PaLM\n- [PaLM-colossalai](https://github.com/hpcaitech/PaLM-colossalai): \u53ef\u6269\u5c55\u7684\u8c37\u6b4c Pathways Language Model ([PaLM](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html)) \u5b9e\u73b0\u3002\n\n### OPT\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/OPT_update.png\" width=800/>\n\n- [Open Pretrained Transformer (OPT)](https://github.com/facebookresearch/metaseq), \u7531Meta\u53d1\u5e03\u76841750\u4ebf\u8bed\u8a00\u6a21\u578b\uff0c\u7531\u4e8e\u5b8c\u5168\u516c\u5f00\u4e86\u9884\u8bad\u7ec3\u53c2\u6570\u6743\u91cd\uff0c\u56e0\u6b64\u4fc3\u8fdb\u4e86\u4e0b\u6e38\u4efb\u52a1\u548c\u5e94\u7528\u90e8\u7f72\u7684\u53d1\u5c55\u3002\n- \u52a0\u901f45%\uff0c\u4ec5\u7528\u51e0\u884c\u4ee3\u7801\u4ee5\u4f4e\u6210\u672c\u5fae\u8c03OPT\u3002[[\u6837\u4f8b]](https://github.com/hpcaitech/ColossalAI/tree/main/examples/language/opt) [[\u5728\u7ebf\u63a8\u7406]](https://colossalai.org/docs/advanced_tutorials/opt_service)\n\n\u8bf7\u8bbf\u95ee\u6211\u4eec\u7684 [\u6587\u6863](https://www.colossalai.org/) \u548c [\u4f8b\u7a0b](https://github.com/hpcaitech/ColossalAI/tree/main/examples) \u4ee5\u4e86\u89e3\u8be6\u60c5\u3002\n\n### ViT\n<p align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/ViT.png\" width=\"450\" />\n</p>\n\n- 14\u500d\u6279\u5927\u5c0f\u548c5\u500d\u8bad\u7ec3\u901f\u5ea6\uff08\u5f20\u91cf\u5e76\u884c=64\uff09\n\n### \u63a8\u8350\u7cfb\u7edf\u6a21\u578b\n- [Cached Embedding](https://github.com/hpcaitech/CachedEmbedding), \u4f7f\u7528\u8f6f\u4ef6Cache\u5b9e\u73b0Embeddings\uff0c\u7528\u66f4\u5c11GPU\u663e\u5b58\u8bad\u7ec3\u66f4\u5927\u7684\u6a21\u578b\u3002\n\n\n<p align=\"right\">(<a href=\"#top\">\u8fd4\u56de\u9876\u7aef</a>)</p>\n\n## \u5355GPU\u8bad\u7ec3\u6837\u4f8b\u5c55\u793a\n\n### GPT-2\n<p id=\"GPT-2-Single\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/GPT2-GPU1.png\" width=450/>\n</p>\n\n- \u7528\u76f8\u540c\u7684\u786c\u4ef6\u8bad\u7ec320\u500d\u5927\u7684\u6a21\u578b\n\n<p id=\"GPT-2-NVME\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/GPT2-NVME.png\" width=800/>\n</p>\n\n- \u7528\u76f8\u540c\u7684\u786c\u4ef6\u8bad\u7ec3120\u500d\u5927\u7684\u6a21\u578b (RTX 3080)\n\n### PaLM\n<p id=\"PaLM-Single\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/PaLM-GPU1.png\" width=450/>\n</p>\n\n- \u7528\u76f8\u540c\u7684\u786c\u4ef6\u8bad\u7ec334\u500d\u5927\u7684\u6a21\u578b\n\n<p align=\"right\">(<a href=\"#top\">\u8fd4\u56de\u9876\u7aef</a>)</p>\n\n\n## \u63a8\u7406 (Energon-AI) \u6837\u4f8b\u5c55\u793a\n\n<p id=\"GPT-3-Inference\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/inference_GPT-3.jpg\" width=800/>\n</p>\n\n- [Energon-AI](https://github.com/hpcaitech/EnergonAI) \uff1a\u7528\u76f8\u540c\u7684\u786c\u4ef6\u63a8\u7406\u52a0\u901f50%\n\n<p id=\"OPT-Serving\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/BLOOM%20serving.png\" width=600/>\n</p>\n\n- [OPT\u63a8\u7406\u670d\u52a1](https://colossalai.org/docs/advanced_tutorials/opt_service): \u4f53\u9a8c1750\u4ebf\u53c2\u6570OPT\u5728\u7ebf\u63a8\u7406\u670d\u52a1\n\n<p id=\"BLOOM-Inference\" align=\"center\">\n<img src=\"https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/BLOOM%20Inference.PNG\" width=800/>\n</p>\n\n- [BLOOM](https://github.com/hpcaitech/EnergonAI/tree/main/examples/bloom): \u964d\u4f4e1760\u4ebf\u53c2\u6570BLOOM\u6a21\u578b\u90e8\u7f72\u63a8\u7406\u6210\u672c\u8d8510\u500d\n\n<p align=\"right\">(<a href=\"#top\">\u8fd4\u56de\u9876\u7aef</a>)</p>\n\n## \u5b89\u88c5\n\n\u73af\u5883\u8981\u6c42:\n\n- PyTorch >= 1.11 (PyTorch 2.x \u6b63\u5728\u9002\u914d\u4e2d)\n- Python >= 3.7\n- CUDA >= 11.0\n- [NVIDIA GPU Compute Capability](https://developer.nvidia.com/cuda-gpus) >= 7.0 (V100/RTX20 and higher)\n- Linux OS\n\n\u5982\u679c\u4f60\u9047\u5230\u5b89\u88c5\u95ee\u9898\uff0c\u53ef\u4ee5\u5411\u672c\u9879\u76ee [\u53cd\u9988](https://github.com/hpcaitech/ColossalAI/issues/new/choose)\u3002\n\n\n### \u4ecePyPI\u5b89\u88c5\n\n\u60a8\u53ef\u4ee5\u7528\u4e0b\u9762\u7684\u547d\u4ee4\u76f4\u63a5\u4ecePyPI\u4e0a\u4e0b\u8f7d\u5e76\u5b89\u88c5Colossal-AI\u3002\u6211\u4eec\u9ed8\u8ba4\u4e0d\u4f1a\u5b89\u88c5PyTorch\u6269\u5c55\u5305\u3002\n\n```bash\npip install colossalai\n```\n\n**\u6ce8\uff1a\u76ee\u524d\u53ea\u652f\u6301Linux\u3002**\n\n\u4f46\u662f\uff0c\u5982\u679c\u4f60\u60f3\u5728\u5b89\u88c5\u65f6\u5c31\u76f4\u63a5\u6784\u5efaPyTorch\u6269\u5c55\uff0c\u60a8\u53ef\u4ee5\u8bbe\u7f6e\u73af\u5883\u53d8\u91cf`CUDA_EXT=1`.\n\n```bash\nCUDA_EXT=1 pip install colossalai\n```\n\n**\u5426\u5219\uff0cPyTorch\u6269\u5c55\u53ea\u4f1a\u5728\u4f60\u5b9e\u9645\u9700\u8981\u4f7f\u7528\u4ed6\u4eec\u65f6\u5728\u8fd0\u884c\u65f6\u91cc\u88ab\u6784\u5efa\u3002**\n\n\u4e0e\u6b64\u540c\u65f6\uff0c\u6211\u4eec\u4e5f\u6bcf\u5468\u5b9a\u65f6\u53d1\u5e03Nightly\u7248\u672c\uff0c\u8fd9\u80fd\u8ba9\u4f60\u63d0\u524d\u4f53\u9a8c\u5230\u65b0\u7684feature\u548cbug fix\u3002\u4f60\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u547d\u4ee4\u5b89\u88c5Nightly\u7248\u672c\u3002\n\n```bash\npip install colossalai-nightly\n```\n\n### \u4ece\u6e90\u7801\u5b89\u88c5\n\n> \u6b64\u6587\u6863\u5c06\u4e0e\u7248\u672c\u5e93\u7684\u4e3b\u5206\u652f\u4fdd\u6301\u4e00\u81f4\u3002\u5982\u679c\u60a8\u9047\u5230\u4efb\u4f55\u95ee\u9898\uff0c\u6b22\u8fce\u7ed9\u6211\u4eec\u63d0 issue :)\n\n```shell\ngit clone https://github.com/hpcaitech/ColossalAI.git\ncd ColossalAI\n\n# install dependency\npip install -r requirements/requirements.txt\n\n# install colossalai\npip install .\n```\n\n\u6211\u4eec\u9ed8\u8ba4\u5728`pip install`\u65f6\u4e0d\u5b89\u88c5PyTorch\u6269\u5c55\uff0c\u800c\u662f\u5728\u8fd0\u884c\u65f6\u4e34\u65f6\u7f16\u8bd1\uff0c\u5982\u679c\u4f60\u60f3\u8981\u63d0\u524d\u5b89\u88c5\u8fd9\u4e9b\u6269\u5c55\u7684\u8bdd\uff08\u5728\u4f7f\u7528\u878d\u5408\u4f18\u5316\u5668\u65f6\u4f1a\u7528\u5230\uff09\uff0c\u53ef\u4ee5\u4f7f\u7528\u4e00\u4e0b\u547d\u4ee4\u3002\n\n```shell\nCUDA_EXT=1 pip install .\n```\n\n<p align=\"right\">(<a href=\"#top\">\u8fd4\u56de\u9876\u7aef</a>)</p>\n\n## \u4f7f\u7528 Docker\n\n### \u4eceDockerHub\u83b7\u53d6\u955c\u50cf\n\n\u60a8\u53ef\u4ee5\u76f4\u63a5\u4ece\u6211\u4eec\u7684[DockerHub\u4e3b\u9875](https://hub.docker.com/r/hpcaitech/colossalai)\u83b7\u53d6\u6700\u65b0\u7684\u955c\u50cf\uff0c\u6bcf\u4e00\u6b21\u53d1\u5e03\u6211\u4eec\u90fd\u4f1a\u81ea\u52a8\u4e0a\u4f20\u6700\u65b0\u7684\u955c\u50cf\u3002\n\n### \u672c\u5730\u6784\u5efa\u955c\u50cf\n\n\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\u4ece\u6211\u4eec\u63d0\u4f9b\u7684 docker \u6587\u4ef6\u4e2d\u5efa\u7acb docker \u955c\u50cf\u3002\n\n> \u5728Dockerfile\u91cc\u7f16\u8bd1Colossal-AI\u9700\u8981\u6709GPU\u652f\u6301\uff0c\u60a8\u9700\u8981\u5c06Nvidia Docker Runtime\u8bbe\u7f6e\u4e3a\u9ed8\u8ba4\u7684Runtime\u3002\u66f4\u591a\u4fe1\u606f\u53ef\u4ee5\u70b9\u51fb[\u8fd9\u91cc](https://stackoverflow.com/questions/59691207/docker-build-with-nvidia-runtime)\u3002\n> \u6211\u4eec\u63a8\u8350\u4ece[\u9879\u76ee\u4e3b\u9875](https://www.colossalai.org)\u76f4\u63a5\u4e0b\u8f7dColossal-AI.\n\n```bash\ncd ColossalAI\ndocker build -t colossalai ./docker\n```\n\n\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\u4ece\u4ee5\u4ea4\u4e92\u5f0f\u542f\u52a8 docker \u955c\u50cf.\n\n```bash\ndocker run -ti --gpus all --rm --ipc=host colossalai bash\n```\n\n<p align=\"right\">(<a href=\"#top\">\u8fd4\u56de\u9876\u7aef</a>)</p>\n\n## \u793e\u533a\n\u6b22\u8fce\u901a\u8fc7[\u8bba\u575b](https://github.com/hpcaitech/ColossalAI/discussions),\n[Slack](https://join.slack.com/t/colossalaiworkspace/shared_invite/zt-z7b26eeb-CBp7jouvu~r0~lcFzX832w),\n\u6216[\u5fae\u4fe1](https://raw.githubusercontent.com/hpcaitech/public_assets/main/colossalai/img/WeChat.png \"qrcode\")\u52a0\u5165 Colossal-AI \u793e\u533a\uff0c\u4e0e\u6211\u4eec\u5206\u4eab\u4f60\u7684\u5efa\u8bae\u548c\u95ee\u9898\u3002\n\n\n## \u505a\u51fa\u8d21\u732e\n\n\u53c2\u8003\u793e\u533a\u7684\u6210\u529f\u6848\u4f8b\uff0c\u5982 [BLOOM](https://bigscience.huggingface.co/) and [Stable Diffusion](https://en.wikipedia.org/wiki/Stable_Diffusion) \u7b49,\n\u65e0\u8bba\u662f\u4e2a\u4eba\u5f00\u53d1\u8005\uff0c\u8fd8\u662f\u7b97\u529b\u3001\u6570\u636e\u3001\u6a21\u578b\u7b49\u53ef\u80fd\u5408\u4f5c\u65b9\uff0c\u90fd\u6b22\u8fce\u53c2\u4e0e\u53c2\u4e0e\u5171\u5efa Colossal-AI \u793e\u533a\uff0c\u62e5\u62b1\u5927\u6a21\u578b\u65f6\u4ee3\uff01\n\n\u60a8\u53ef\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u8054\u7cfb\u6216\u53c2\u4e0e\uff1a\n1. [\u7559\u4e0bStar \u2b50](https://github.com/hpcaitech/ColossalAI/stargazers) \u5c55\u73b0\u4f60\u7684\u559c\u7231\u548c\u652f\u6301\uff0c\u975e\u5e38\u611f\u8c22!\n2. \u53d1\u5e03 [issue](https://github.com/hpcaitech/ColossalAI/issues/new/choose), \u6216\u8005\u5728GitHub\u6839\u636e[\u8d21\u732e\u6307\u5357](https://github.com/hpcaitech/ColossalAI/blob/main/CONTRIBUTING.md) \u63d0\u4ea4\u4e00\u4e2a PR\u3002\n3. \u53d1\u9001\u4f60\u7684\u6b63\u5f0f\u5408\u4f5c\u63d0\u6848\u5230 contact@hpcaitech.com\n\n\u771f\u8bda\u611f\u8c22\u6240\u6709\u8d21\u732e\u8005\uff01\n\n<a href=\"https://github.com/hpcaitech/ColossalAI/graphs/contributors\">\n  <img src=\"https://contrib.rocks/image?repo=hpcaitech/ColossalAI\"  width=\"800px\"/>\n</a>\n\n<p align=\"right\">(<a href=\"#top\">\u8fd4\u56de\u9876\u7aef</a>)</p>\n\n\n## CI/CD\n\n\u6211\u4eec\u4f7f\u7528[GitHub Actions](https://github.com/features/actions)\u6765\u81ea\u52a8\u5316\u5927\u90e8\u5206\u5f00\u53d1\u4ee5\u53ca\u90e8\u7f72\u6d41\u7a0b\u3002\u5982\u679c\u60f3\u4e86\u89e3\u8fd9\u4e9b\u5de5\u4f5c\u6d41\u662f\u5982\u4f55\u8fd0\u884c\u7684\uff0c\u8bf7\u67e5\u770b\u8fd9\u4e2a[\u6587\u6863](https://github.com/hpcaitech/ColossalAI/blob/main/.github/workflows/README.md).\n\n\n## \u5f15\u7528\u6211\u4eec\n\nColossal-AI\u9879\u76ee\u53d7\u4e00\u4e9b\u76f8\u5173\u7684\u9879\u76ee\u542f\u53d1\u800c\u6210\u7acb\uff0c\u4e00\u4e9b\u9879\u76ee\u662f\u6211\u4eec\u7684\u5f00\u53d1\u8005\u7684\u79d1\u7814\u9879\u76ee\uff0c\u53e6\u4e00\u4e9b\u6765\u81ea\u4e8e\u5176\u4ed6\u7ec4\u7ec7\u7684\u79d1\u7814\u5de5\u4f5c\u3002\u6211\u4eec\u5e0c\u671b. \u6211\u4eec\u5e0c\u671b\u5728[\u53c2\u8003\u6587\u732e\u5217\u8868](./REFERENCE.md)\u4e2d\u5217\u51fa\u8fd9\u4e9b\u4ee4\u4eba\u79f0\u8d5e\u7684\u9879\u76ee\uff0c\u4ee5\u5411\u5f00\u6e90\u793e\u533a\u548c\u7814\u7a76\u9879\u76ee\u81f4\u8c22\u3002\n\n\u4f60\u53ef\u4ee5\u901a\u8fc7\u4ee5\u4e0b\u683c\u5f0f\u5f15\u7528\u8fd9\u4e2a\u9879\u76ee\u3002\n\n```\n@article{bian2021colossal,\n  title={Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel Training},\n  author={Bian, Zhengda and Liu, Hongxin and Wang, Boxiang and Huang, Haichen and Li, Yongbin and Wang, Chuanrui and Cui, Fan and You, Yang},\n  journal={arXiv preprint arXiv:2110.14883},\n  year={2021}\n}\n```\n\nColossal-AI \u5df2\u88ab [SC](https://sc22.supercomputing.org/), [AAAI](https://aaai.org/Conferences/AAAI-23/), [PPoPP](https://ppopp23.sigplan.org/), [CVPR](https://cvpr2023.thecvf.com/), [ISC](https://www.isc-hpc.com/)\u7b49\u9876\u7ea7\u4f1a\u8bae\u5f55\u53d6\u4e3a\u5b98\u65b9\u6559\u7a0b\u3002\n\n<p align=\"right\">(<a href=\"#top\">\u8fd4\u56de\u9876\u7aef</a>)</p>\n"}, {"id": 64, "name": "\u94fe\u63a51: vaaaaanquish/Awesome-Rust-MachineLearning", "link": "https://github.com/vaaaaanquish/Awesome-Rust-MachineLearning", "parent": 63, "note": "[\u6765\u81ea vaaaaanquish/Awesome-Rust-MachineLearning\n\u7684\u94fe\u63a5](https://github.com/vaaaaanquish/Awesome-Rust-MachineLearning)"}, {"id": 63, "name": " vaaaaanquish/Awesome-Rust-MachineLearning\n", "parent": 58, "note": "This repository is a list of machine learning libraries written in Rust. It's a compilation of GitHub repositories, blogs, books, movies, discussions, papers, etc."}, {"id": 66, "name": "\u94fe\u63a51: BinChengZhao/delicate", "link": "https://github.com/BinChengZhao/delicate", "parent": 65, "note": "[\u6765\u81ea  BinChengZhao/delicate\n\u7684\u94fe\u63a5](https://github.com/BinChengZhao/delicate)"}, {"id": 65, "name": "  BinChengZhao/delicate\n", "parent": 58}, {"id": 67, "name": "README\n", "parent": 65, "note": "# Delicate   \n[![Build](https://github.com/BinChengZhao/delicate/workflows/CI/badge.svg)](\nhttps://github.com/BinChengZhao/delicate/actions)\n[![License](https://img.shields.io/badge/license-MIT%2FApache--2.0-blue.svg)](\nhttps://github.com/BinChengZhao/delicate)\n## [English](./README.md)\n\n- [delicate](#delicate)\n  - [\u4ec0\u4e48\u662fdelicate](#what-is-delicate)\n  - [\u7279\u6027](#\u7279\u6027)\n  - [Benchmark](#benchmark)\n  - [\u4e0a\u624b delicate](#get-started)\n    - [\u90e8\u7f72 delicate](#\u90e8\u7f72-delicate)\n  - [\u5feb\u901f\u5f00\u59cb](#quick-start)\n  - [\u6587\u6863](https://delicate-rs.github.io/Roadmap.html)\n  - [\u8def\u7ebf\u56fe](#roadmap)\n  - [\u8d21\u732e\u6307\u5357](#Contributing)\n  - [License](#license)\n\n## What is delicate\n<a href=\"\">\n    <img src=\"./doc/src/delicate_logo.png\"\n         alt=\"delicate logo\" title=\"delicate\" height=\"125\" width=\"125\"  align=\"right\"/>\n</a>\n\n`delicate` \u4e00\u4e2a\u8f7b\u91cf\u7684\u5206\u5e03\u5f0f\u7684\u4efb\u52a1\u8c03\u5ea6\u5e73\u53f0\u901a\u8fc7rust\u7f16\u5199. :\n\n## \u7279\u6027\n- **\u53cb\u597d\u7684\u7528\u6237\u754c\u9762\uff1a** [\u524d\u7aef]\u65b9\u4fbf\u5730\u7ba1\u7406\u4efb\u52a1\u548c\u6267\u884c\u5668\uff0c\u76d1\u63a7\u5176\u72b6\u6001\uff0c\u652f\u6301\u624b\u52a8\u7ef4\u62a4\u8fd0\u884c\u4e2d\u7684\u4efb\u52a1\u7b49\u3002\n\n- **\u7075\u6d3b\u7684\u64cd\u4f5c\uff1a** \u7075\u6d3b\u7684\u4efb\u52a1\u64cd\u4f5c\uff0c\u652f\u6301\u9650\u5236\u5355\u4e2a\u8282\u70b9\u7684\u6700\u5927\u5e76\u884c\u6570\uff0c\u4e0ecron\u8868\u8fbe\u5f0f\u76f8\u5bf9\u5e94\u7684\u65f6\u533a\u8bbe\u7f6e\uff0c\u8c03\u5ea6\u6a21\u5f0f\uff08\u5355\u4e00\u3001\u56fa\u5b9a\u6570\u91cf\u3001\u4e0d\u65ad\u91cd\u590d\uff09\uff0c\u80fd\u591f\u5728\u4efb\u4f55\u65f6\u5019\u624b\u52a8\u89e6\u53d1\u4efb\u52a1\uff0c\u624b\u52a8\u7ec8\u6b62\u4efb\u52a1\u5b9e\u4f8b\uff0c\u5728\u7ebf\u67e5\u770b\u4efb\u52a1\u65e5\u5fd7\u3002\n\n- **\u9ad8\u53ef\u7528\u6027\uff1a** Delicate\u652f\u6301\u6a2a\u5411\u6269\u5c55\u3002\u901a\u8fc7\u90e8\u7f72\u5c3d\u53ef\u80fd\u591a\u7684Delicate\u670d\u52a1\u5668\u548c\u6267\u884c\u5668\uff0c\u5f88\u5bb9\u6613\u5b9e\u73b0\u9ad8\u53ef\u7528\u6027\u548c\u6027\u80fd\u3002\n\n- **\u9ad8\u6027\u80fd\uff1a** \u8f7b\u91cf\u7ea7\u548c\u57fa\u672c\u529f\u80fd\u52a0\u5feb\u4e86\u6027\u80fd\uff0c`delicate'\u7684\u57fa\u672c\u8d44\u6e90\u5f00\u9500\u5927\u7ea6\u662f\uff08\u5c0f\u4e8e0.1%\u7684cpu\u4f7f\u7528\u7387\uff0c10m\u7684\u5185\u5b58.)\n\n- **\u53ef\u89c2\u5bdf\u6027:** \u6709\u8bb8\u591a\u6709\u610f\u4e49\u7684\u7edf\u8ba1\u6570\u636e\u5b9a\u671f\u4ee5\u56fe\u8868\u7684\u65b9\u5f0f\u5c55\u73b0\u3002\n\n- **\u5347\u7ea7\uff1a** \u7cfb\u7edf\u7684\u52a8\u6001\u5347\u7ea7\uff08\u5347\u7ea7\u662f\u901a\u8fc7\u83b7\u5f97\u6700\u65b0\u7684\u6e90\u4ee3\u7801\u548c\u8fdb\u884c\u6570\u636e\u5e93\u8fc1\u79fb.)\n\n- **\u590d\u7528\u6027\uff1a**  \u6267\u884c\u5668\u63d0\u4f9b`restful-api` \uff0c\u53ef\u4ee5\u8ba9\u7528\u6237\u5e94\u7528\u7ef4\u62a4\u81ea\u5b9a\u4e49\u4efb\u52a1.\n\n- **\u6743\u9650\u7ba1\u7406\uff1a**  \u57fa\u4e8ecasbin\u5b9e\u73b0\u7684\u6743\u9650\u7ba1\u7406\u529f\u80fd\uff0c\u6301\u7eed\u4f18\u5316\u4f53\u9a8c.\n\n\n`Delicate` \u67b6\u6784\u56fe:\n\n![architecture](./doc/src/architecture.svg)\n\n![topology](./doc/src/topology.svg)\n\n\n## \u9879\u76ee\u6548\u679c\u56fe\n<details>\n<summary>\u8bf7\u70b9\u51fb</summary>\n\n![](./doc/src/_media/dashboard.jpg)\n![](./doc/src/_media/executor_create.jpg)\n![](./doc/src/_media/executor_list.jpg)\n![](./doc/src/_media/group_create.jpg)\n![](./doc/src/_media/group_inner_bind.jpg)\n![](./doc/src/_media/login_en.jpg)\n![](./doc/src/_media/task_edit.jpg)\n![](./doc/src/_media/task_list_operation.jpg)\n![](./doc/src/_media/task_log_kill.jpg)\n![](./doc/src/_media/task_log_logs_2.jpg)\n![](./doc/src/_media/task_log_logs.jpg)\n![](./doc/src/_media/user_list.jpg)\n\n</details>\n\n\n## Benchmark\n\u6bcf\u6b21\u8c03\u5ea6\u8017\u65f6 6,424 ns (+/- 52) \u5728 CentOS Linux release 7.6.1810 (Core) (\u4e0d\u540c\u7cfb\u7edf/\u786c\u4ef6\u4f1a\u6709\u4e0d\u540c\u7684\u7ed3\u679c).\n\n\u7cfb\u7edf\uff1aCentOS Linux release 7.6.1810 (Core) - 4\u6838/8G\uff1a\n\n\u5355\u8282\u70b9: delicate-executor \n\n\u4efb\u52a1\u521b\u5efa\uff0c\u5cf0\u503ccpu\u6d88\u8017 3%\uff0cqps\uff1a17000+\n\n\u4efb\u52a1\u53d6\u6d88\uff0c\u5cf0\u503ccpu\u6d88\u8017 3%\uff0cqps\uff1a18000+\n\n\u4efb\u52a1\u624b\u52a8\u8c03\u5ea6\uff0c\u5cf0\u503ccpu\u6d88\u8017 3.5%\uff0cqps\uff1a14000+\n\n\u4efb\u52a1\u79fb\u9664\uff0c\u5cf0\u503ccpu\u6d88\u8017 3%\uff0cqps\uff1a14000+\n\n\u5065\u5eb7\u68c0\u67e5\uff0c\u5cf0\u503ccpu\u6d88\u8017 4%\uff0cqps\uff1a2600+\n\n\u5cf0\u503c\u7684\u5185\u5b58\u6d88\u8017\u90fd\u572860M\u4e4b\u5185\u3002\n\n\u5176\u5b83\u7684\u6307\u6807\u7b49\u5f85\u538b\u6d4b.\n\n## Get Started\n\n\u5982\u4e0b\u662f`Delicate` - `scheduler` & `executor` \u7684\u57fa\u672c\u7528\u9014\u548c\u5feb\u901f\u8bbe\u7f6e\u3002\n\u6211\u4eec\u628a\u5b83\u5206\u6210\u591a\u4e2a\u7b80\u5355\u7684\u6b65\u9aa4\u6765\u8bf4\u660e`Delicate`\u7684\u6982\u5ff5\u548c\u64cd\u4f5c.\n\n\u6e90\u7801\u5b89\u88c5\u7684\u4f9d\u8d56:\n * [rustc](https://www.rust-lang.org/tools/install) (minimum-supported version of `rustc` is **1.54**.) \n * libmysqlclient-dev & libpq-dev & libssl-dev\n\n### \u90e8\u7f72 delicate\n\n<!-- We can download the binary from [release page](https://github.com/BinChengZhao/delicate/releases).  -->\n<!-- \nFor example we use linux version:\n\n```bash\n$ mkdir delicate\n$ wget https://github.com/BinChengZhao/delicate/releases/download/v1.0.0/delicate-v1.0.0-linux-amd64.tar.gz\n$ tar zxvf delicate-v1.0.0-linux-amd64.tar.gz -C delicate && cd delicate -->\n\n\n1. \u5b89\u88c5rust\u5957\u4ef6\u3002` curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh ` \u6216 ` curl --tlsv1.2 -sSf https://sh.rustup.rs | sh ` \u6216 `curl https://sh.rustup.rs -sSf | sh` \u3002 \u6709\u53ef\u80fd\u9047\u5230curl\u9519\u8bef\uff0c\u9700\u8981\u91cd\u8bd5\u51e0\u6b21\uff0c\u8fd9\u4e9b\u95ee\u9898\u901a\u5e38\u662f\u7531\u4e8ecurl\u7684\u7248\u672c\u592a\u4f4e\uff0c\u6216\u8005\u7f51\u7edc\u4e0d\u7a33\u5b9a\u9020\u6210\u7684\u3002\n\n2. \u5728\u5f53\u524dshell\u4e2d\u521d\u59cb\u5316cargo\uff0c` source $HOME/.cargo/env ` \u3002 \n\n3. \u83b7\u53d6`delicate`\u7684\u6e90\u4ee3\u7801\u5e76\u7f16\u8bd1\u5b83\uff08\u8fd9\u662f\u4e00\u4e2a\u4f8b\u5b50\uff0c\u8bf7\u6839\u636e\u4f60\u7684\u9700\u8981\u83b7\u53d6\u76f8\u5e94\u7684Tag\u7248\u672c\uff09\u3002` git clone https://github.com/BinChengZhao/delicate.git ` \u3002\n\n4. `cd delicate/ ` \u3002\n\n5. ` cargo check ` \uff0c\u68c0\u67e5\u73af\u5883\u4f9d\u8d56\u6027\u7b49\u3002\n\n6. \u5f53\u9519\u8bef\uff1a\u6ca1\u6709\u627e\u5230\u94fe\u63a5\u5668`cc`\u65f6\uff1a\u89e3\u51b3\u65b9\u6848\uff1a` yum -y install gcc ` \u3002\n\n7. \u5f53` --- stderr\u7ebf\u7a0b'main'\u5728'Without `*` set in .env: NotPresent \"\u65f6\uff0c\u4f60\u9700\u8981\u8bbe\u7f6e\u73af\u5883\u53d8\u91cf\uff0c\u4f7f\u7528\u9879\u76ee\u7684template.env\"\u3002\n\n8. ` cp template.env .env ` \u7136\u540e\u5f00\u59cb\u4fee\u6539\u914d\u7f6e\u3002\n\n9. \u901a\u8fc7\u540e\u7528`cargo build --release`\u7f16\u8bd1\u53ef\u6267\u884c\u6587\u4ef6\u3002\n\n10. \u542f\u52a8delicate-scheduler\uff1a ` nohup target/release/delicate-scheduler >> scheduler.log 2>&1 &` \u5728\u90e8\u7f72\u670d\u52a1\u5668\u7684\u673a\u5668\u4e0a\u3002\n\n11. \u542f\u52a8delicate-executor\u3002` nohup target/release/delicate-executor >> executor.log 2>&1 & ` \u5728\u6267\u884c\u4efb\u52a1\u7684\u673a\u5668\u4e0a\u3002\n\n12. \u5173\u4e8e\u524d\u7aef\u8d44\u6e90\u7684\u90e8\u7f72\uff0c\u8bf7\u53c2\u8003[README.md](./delicate-web/README.md)\u3002\n\n13. `delicate-scheduler`\u548c`delicate-web`\u9700\u8981\u5728\u540c\u4e00\u4e2a\u57df\u4e0b\uff08\u5982`api. delicate.com`\u548c`web. delicate.com`\uff09\uff0c\u4ee5\u907f\u514d\u8de8\u57df\u95ee\u9898\uff0c`delicate-scheduler`\u548c`delicate-web`\u90fd\u53ef\u4ee5\u901a\u8fc7\u53cd\u5411\u4ee3\u7406\u90e8\u7f72\u4e3a\u96c6\u7fa4\u7248\u672c\u3002\n\n\n## Quick start\n[\u5feb\u901f\u5f00\u59cb](./doc/src/quick_start_zh_cn.md)\n\n## documentation\n\nSee [reference](./doc/src/reference.md) for more information.\n\n\n## To Do List\n- [] I18n.\n- [] \u6743\u9650\u7ba1\u7406\u3002\n- [] \u591a\u79cd\u767b\u5f55\u534f\u8bae\uff0cLDAP CAS.\n- [] \u673a\u5668\u8d44\u6e90\u9762\u677f\uff0c\u5728\u7ebf\u67e5\u770b\u8fdb\u7a0b\u3001\u5185\u5b58\u3001cpu\u7b49\u3002\n- [] \u6570\u636e\u5e93\u540e\u7aef\u652f\u6301Postgres\u3002\n- [] \u4f7f\u7528RPC\u7684 \"scheduler & executor \"\u901a\u4fe1\uff0c\u4f46\u76ee\u524d\u5b58\u5728\u4f9d\u8d56\u6027\u95ee\u9898\uff08RPC\u6846\u67b6\uff08\"tonic \uff5c tarpc\"\uff09\u90fd\u4f9d\u8d56tokio 1\uff0c\u76ee\u524dactix-web\u7a33\u5b9a\u72483\uff0c\u4e0d\u652f\u6301\u4e0etokio 1\u96c6\u6210\uff09\u3002\n- [] \u652f\u6301\u4efb\u52a1\u6d41\u3002\n- [] \u52a8\u6001\u6267\u884c\u5668\u8d1f\u8f7d\u8c03\u6574\uff0c\u8d44\u6e90\u7ec4\u6839\u636e\u673a\u5668\u6307\u6807\u8c03\u6574\u4efb\u52a1\u6267\u884c\u8282\u70b9\u7684\u4efb\u52a1\u8d1f\u8f7d\u3002\n\n\n## Roadmap \n\n\u67e5\u770b\u66f4\u591a\u8def\u7ebf\u56fe\u8be6\u60c5 [delicate Roadmap](./doc/src/Roadmap.md) .\n\n## Contributing\n\n:balloon: \u611f\u8c22\u4f60\u5bf9\u6539\u8fdb\u9879\u76ee\u7684\u5e2e\u52a9! \u6211\u4eec\u975e\u5e38\u9ad8\u5174\u80fd\u6709\u4f60\u7684\u53c2\u4e0e! \u8fd9\u91cc\u6709\u4e00\u4e2a\u8d21\u732e\u6307\u5357\uff0c\u4ee5\u5e2e\u52a9\u4f60\u53c2\u4e0e\u5230Delicate\n\u9879\u76ee.\n\n[Rust-guide](./CONTRIBUTING.md)\n[Js-guide](./delicate-web/CONTRIBUTING.md)\n\n\n## \u611f\u8c22\n\u6211\u4eec\u8981\u611f\u8c22\u6574\u4e2a\u793e\u533a\u548c\u4ee3\u7801\u8d21\u732e\u8005\u3002\u7279\u522b\u662f\uff0c\u611f\u8c22\u8fc7\u53bb\u4e24\u4e2a\u6708\u7684\u4ee3\u7801\u8d21\u732e\u8005:\n[Walker-os](https://github.com/Walker-os)\n\n\n\u611f\u8c22\u7528\u6237\u62a5\u544a\u6587\u6863\u4e2d\u7684\u62fc\u5199\u9519\u8bef, \u8fd9\u975e\u5e38\u611f\u8c22\u5927\u5bb6\u3002\n\u611f\u8c22\u7528\u6237\u52a0\u5165\u6211\u4eec\uff0c\u63d0\u4f9b\u53cd\u9988\uff0c\u8ba8\u8bba\u529f\u80fd\uff0c\u5e76\u83b7\u5f97\u5e2e\u52a9!\n\n# Stargazers over time\n\n[![Stargazers over time](https://starchart.cc/BinChengZhao/delicate.svg)](https://starchart.cc/BinChengZhao/delicate)\n\n\n## License\n\nLicensed under either of\n\n * MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)\n\n#### Contribution\n\nUnless you explicitly state otherwise, any contribution intentionally submitted\nfor inclusion in the work by you, as defined in the Apache-2.0 license, shall be\ndual licensed as above, without any additional terms or conditions.\n"}]